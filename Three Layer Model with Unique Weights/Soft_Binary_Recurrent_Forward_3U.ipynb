{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87",
      "metadata": {
        "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87"
      },
      "source": [
        "# Soft Binary Neural Network with Recurrent Crossbar Recycling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508058d8-e23a-4c29-aad7-c2b233d621c9",
      "metadata": {
        "id": "508058d8-e23a-4c29-aad7-c2b233d621c9"
      },
      "source": [
        "## Imports and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f",
      "metadata": {
        "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d406d54c-db27-4536-a8c1-f46437f6fb71",
      "metadata": {
        "id": "d406d54c-db27-4536-a8c1-f46437f6fb71"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, num_epochs, element):\n",
        "    epochs = range(len(history[list(history.keys())[0]]))\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
        "    ax1.plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
        "    ax1.set_xlabel(\"Epochs\", fontsize=14)\n",
        "    ax1.set_ylabel(\"Loss\", fontsize=14, color=\"blue\")\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
        "    ax1.legend(loc=\"upper left\")\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(epochs, history[\"train_accuracy\"], label=\"Train Accuracy\", color=\"green\")\n",
        "    ax2.plot(epochs, history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"orange\")\n",
        "    ax2.set_ylabel(\"Accuracy (%)\", fontsize=14, color=\"green\")\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=\"green\")\n",
        "    ax2.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.title(f\"Training and Validation Metrics for {element}\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7c658023-75df-4754-a617-a8ba6d08d068",
      "metadata": {
        "id": "7c658023-75df-4754-a617-a8ba6d08d068"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, class_names=None):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e",
      "metadata": {
        "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e"
      },
      "source": [
        "### MNIST Handwritten Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d3bbad17-7067-4f06-8755-012646ca9567",
      "metadata": {
        "id": "d3bbad17-7067-4f06-8755-012646ca9567"
      },
      "outputs": [],
      "source": [
        "class BinarizeAndAddNoiseTransform:\n",
        "    def __init__(self, threshold_max, threshold_min, noise_std):\n",
        "        self.threshold_max = threshold_max\n",
        "        self.threshold_min = threshold_min\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = transforms.ToTensor()(img).to(device)\n",
        "        thresh = torch.rand(1, device=device) * (self.threshold_max - self.threshold_min) + self.threshold_min\n",
        "        img = (img > thresh).float()\n",
        "        img = img[:,4:-4, 4:-4]\n",
        "        noise = torch.randn(img.size(), device=device) * self.noise_std\n",
        "        noisy_img = img + noise\n",
        "        return noisy_img\n",
        "\n",
        "binary_noise_transform = transforms.Compose([\n",
        "    BinarizeAndAddNoiseTransform(0.4, 0.6, 0.05)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=binary_noise_transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=binary_noise_transform)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd",
      "metadata": {
        "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd"
      },
      "outputs": [],
      "source": [
        "# Get a subset of the dataset\n",
        "train_in, train_lab = next(iter(train_loader))\n",
        "val_in, val_lab = next(iter(test_loader))\n",
        "\n",
        "# Move data to the appropriate device\n",
        "train_in, train_lab = train_in.to(device), train_lab.to(device)\n",
        "val_in, val_lab = val_in.to(device), val_lab.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
        "outputId": "6a605bdf-85b4-4a77-f0a1-0c6f41a46c61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(15, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(train_in[i].cpu().squeeze(), cmap='gray')\n",
        "    ax.set_title(f\"Label: {train_lab[i].item()}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "train_in.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a",
      "metadata": {
        "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a"
      },
      "source": [
        "## Custom Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a",
      "metadata": {
        "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def tensor_stats(tensor, name=\"Tensor\"):\n",
        "    tensor = tensor.to(device)\n",
        "    mean_magnitude = tensor.abs().mean().item()\n",
        "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
        "    def __init__(self, scaling, G_ON, G_OFF, V_INV, R_INV, V_1, V_0, zeta, initial_factor, crossbar=(64,64),\n",
        "                 input_size=400, encoding_size=3, output_size=10, data_in=40, bin_active=True,\n",
        "                 monitor_volts=False, monitor_grads=True, monitor_latents=False, dropout=0.01, alpha = 0.9,\n",
        "                 int_lr=0.01, int_norm=True, temperature_1 = 0.4, temperature_2 = 30,monitor_annealing=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w = nn.Parameter(initial_factor * torch.empty(crossbar, device=device))\n",
        "        nn.init.xavier_uniform_(self.w)\n",
        "        self.w.date = self.w.data * initial_factor\n",
        "\n",
        "        self.G_ON, self.G_OFF = torch.tensor(G_ON, device=device)*scaling, torch.tensor(G_OFF, device=device)*scaling\n",
        "        self.V_INV, self.R_INV = torch.tensor(V_INV, device=device), torch.tensor(R_INV, device=device)\n",
        "        self.V_1, self.V_0 = torch.tensor(V_1, device=device), torch.tensor(V_0, device=device)\n",
        "\n",
        "        self.crossbar_in, self.crossbar_out = crossbar\n",
        "        self.encoding, self.data_in, self.output_size = encoding_size, data_in, output_size\n",
        "        self.r_passes = input_size // data_in\n",
        "        self.second_size = self.crossbar_out - self.encoding*self.r_passes\n",
        "        self.out1size = self.encoding * self.r_passes\n",
        "\n",
        "        self.first_bias = (crossbar[0] - data_in) % encoding_size\n",
        "        self.second_bias = (crossbar[0])%(self.r_passes*encoding_size)\n",
        "        self.final_bias = (crossbar[0])%(self.second_size)\n",
        "\n",
        "        self.feed_repeats = (crossbar[0] - data_in)//encoding_size\n",
        "        self.second_repeats = (crossbar[0])//(self.r_passes*encoding_size)\n",
        "        self.final_repeats = (crossbar[0])//(self.second_size)\n",
        "\n",
        "        self.zeta, self.int_lr = torch.tensor(zeta, device=device), torch.tensor(int_lr, device=device)\n",
        "        self.bin_active, self.int_norm = bin_active, int_norm\n",
        "        self.monitor_volts, self.monitor_grads, self.monitor_latents = monitor_volts, monitor_grads, monitor_latents\n",
        "        self.monitor_annealing = monitor_annealing\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.temperature_1 = temperature_1\n",
        "        self.temperature_2 = temperature_2\n",
        "        self.device = device\n",
        "\n",
        "        self.velocity = torch.zeros(crossbar, device = device)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def INV_AMP(self, x, R_INV):\n",
        "        return -self.V_INV * torch.tanh(R_INV * x / self.V_INV)\n",
        "\n",
        "    def SOFT_BIN(self, x):\n",
        "        if self.bin_active: return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
        "        else: return self.G_ON * x * self.zeta * 0.4\n",
        "\n",
        "    def PREPROCESS(self, img):\n",
        "        return (self.V_1 - self.V_0) * img.to(device) + self.V_0\n",
        "\n",
        "    def ANNEALER(self):\n",
        "        prob = torch.exp(torch.tensor(-1.0, device=self.device) / self.temperature_1)\n",
        "        prob = torch.clamp(prob, min=1e-3, max=1)\n",
        "\n",
        "        rand_vals = torch.rand((64, 64), device=self.device)\n",
        "        annealed_mask = torch.where(rand_vals < prob, -1, torch.where(rand_vals < 2 * prob, 0, 1))\n",
        "\n",
        "        return annealed_mask\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
        "        img = self.PREPROCESS(img.view(img.size(0), -1))\n",
        "        bias = self.PREPROCESS(((-1) ** torch.arange(self.first_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias2 = self.PREPROCESS(((-1) ** torch.arange(self.second_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias3 = self.PREPROCESS(((-1) ** torch.arange(self.final_bias, device=device)).repeat(img.shape[0], 1))\n",
        "\n",
        "        # RRAM Soft Binarization\n",
        "        g = self.SOFT_BIN(self.w)\n",
        "        if self.monitor_latents: tensor_stats(self.w, \"Latent Weights:\")\n",
        "\n",
        "        # Recurrent Encoding Layer\n",
        "        feedback = torch.zeros((img.shape[0], self.encoding*self.feed_repeats), device=device)\n",
        "        out1 = torch.zeros((img.shape[0], self.out1size), device = device)\n",
        "\n",
        "        for r_pass in range(self.r_passes):\n",
        "            ind_s, ind_f = self.crossbar_out - (r_pass+1)*self.encoding, self.crossbar_out - (r_pass)*self.encoding\n",
        "            ind_a, ind_b = self.out1size - (r_pass+1)*self.encoding, self.out1size - (r_pass)*self.encoding\n",
        "\n",
        "            x = torch.cat((feedback, bias, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
        "            x = F.linear(x, g[ind_s:ind_f, : ], bias=None)\n",
        "\n",
        "            out1[:, ind_a:ind_b] = self.INV_AMP(x, self.R_INV)\n",
        "            if self.monitor_volts: tensor_stats(feedback, f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
        "\n",
        "            feedback = out1[:, ind_a:ind_b].repeat(1,self.feed_repeats)\n",
        "\n",
        "        # Feature Extraction layer\n",
        "        ind_p, ind_q = self.output_size, self.output_size + self.second_size\n",
        "        x = torch.cat((bias2, out1.repeat(1,self.second_repeats)), dim = 1)\n",
        "\n",
        "        x = F.linear(x, g[ind_p:ind_q, :], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Voltages after Second Layer\")\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Classification Layer\n",
        "        x = torch.cat((bias3, x.repeat(1,self.final_repeats)), dim = 1)\n",
        "        x = F.linear(x, g[:self.output_size, : ], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Last Layer\")\n",
        "\n",
        "        return x\n",
        "\n",
        "    def backprop(self, ext_lr):\n",
        "        with torch.no_grad():\n",
        "            if self.w.grad is not None:\n",
        "                grad = self.w.grad.detach().to(device)\n",
        "                for i in range(grad.shape[0]):\n",
        "                    if self.int_norm:\n",
        "                        grad[i] = self.int_lr * grad[i] / (torch.norm(grad[i]) + 1e-20)\n",
        "                    grad[i] = grad[i]\n",
        "                grad = grad + self.alpha*self.velocity\n",
        "                if self.monitor_grads: tensor_stats(ext_lr*grad, \"Gradients\")\n",
        "                self.w -= grad * ext_lr\n",
        "                self.velocity = grad\n",
        "                self.w.grad.zero_()\n",
        "\n",
        "    def anneal(self, inputs, labels, decay1, decay2):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.forward(inputs)\n",
        "            old_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "            old_w = self.w.data.clone()\n",
        "\n",
        "            self.w.data = self.w.data * self.ANNEALER()\n",
        "            outputs = self.forward(inputs)\n",
        "            new_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "\n",
        "            acceptance_prob = torch.exp(torch.tensor(-(new_loss - old_loss) / self.temperature_2, device=self.device))\n",
        "            if self.monitor_annealing: print(\"Old & New Losses\", old_loss, new_loss,\"Probab:\", acceptance_prob)\n",
        "            if new_loss < old_loss or torch.rand(1, device=self.device) < acceptance_prob:\n",
        "                if self.monitor_annealing: print(\"Annealed weights accepted\")\n",
        "            else:\n",
        "                self.w.data = old_w\n",
        "\n",
        "            self.temperature_1 *= decay1\n",
        "            self.temperature_2 *= decay2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845d51da-8368-4c97-89a2-9fc1374f408b",
      "metadata": {
        "id": "845d51da-8368-4c97-89a2-9fc1374f408b"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00",
      "metadata": {
        "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00"
      },
      "outputs": [],
      "source": [
        "params_RRAM = {\n",
        "    \"scaling\": 2,\n",
        "    \"G_ON\": 6e-5,\n",
        "    \"G_OFF\": 2.88e-6,\n",
        "    \"V_INV\": 1.2,\n",
        "    \"R_INV\": 2000.0,\n",
        "    \"V_1\": 0.1,\n",
        "    \"V_0\": -0.1,\n",
        "    \"zeta\": 10.0,\n",
        "    \"initial_factor\": 0.01,\n",
        "    \"crossbar\": (64, 64),\n",
        "    \"input_size\": 400,\n",
        "    \"encoding_size\": 3,\n",
        "    \"output_size\": 10,\n",
        "    \"data_in\": 40,\n",
        "    \"bin_active\": True,\n",
        "    \"monitor_volts\": False,\n",
        "    \"monitor_grads\": False,\n",
        "    \"monitor_latents\": False,\n",
        "    \"dropout\": 0.05,\n",
        "    \"int_lr\": 0.01,\n",
        "    \"int_norm\": True,\n",
        "    \"ext_lr\": 200,\n",
        "    \"epochs\": 1000,\n",
        "    \"temperature_1\": 0.3,\n",
        "    \"temperature_2\": 20,\n",
        "    \"monitor_annealing\": False,\n",
        "    \"decay1\" : 0.99,\n",
        "    \"decay2\" : 0.9,\n",
        "    \"anneal_per_epoch\" : True,\n",
        "    \"anneal_per_batch\" : False,\n",
        "    \"early_stop_wait\": 21,\n",
        "    \"fine_tune_wait\": 7,\n",
        "    \"temperature_wait\": 3,\n",
        "    \"T_boost\": 500,\n",
        "    \"alpha\": 0.01\n",
        "}\n",
        "\n",
        "training_params = [\"noise_std\", \"batch_size\", \"lr\", \"epochs\",\"ext_lr\", \"decay1\", \"decay2\", \"anneal_per_epoch\",\n",
        "                   \"anneal_per_batch\", \"fine_tune_wait\", \"early_stop_wait\",\"temperature_wait\", \"T_boost\"]\n",
        "model_params = {k: v for k, v in params_RRAM.items() if k not in training_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
      "metadata": {
        "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
      "metadata": {
        "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
        "outputId": "d6ef34ae-673b-4e61-ec54-0e73399a90fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Bits Flipped : tensor(146.1207, device='cuda:0')\n",
            "Batchwise Acceptance tensor(0.6065, device='cuda:0')\n",
            "Epochwise Acceptance tensor(0.0067, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Bits Flipped :\", 64*64*torch.exp(torch.tensor(-1.0, device=device) / model_RRAM.temperature_1))\n",
        "print(\"Batchwise Acceptance\", torch.exp(torch.tensor(-(10) / model_RRAM.temperature_2, device=device)))\n",
        "print(\"Epochwise Acceptance\", torch.exp(torch.tensor(-(100) / model_RRAM.temperature_2, device=device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241d1155-be9e-4a7a-9a74-a1d608188350",
      "metadata": {
        "id": "241d1155-be9e-4a7a-9a74-a1d608188350"
      },
      "source": [
        "## Training:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792",
      "metadata": {
        "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792"
      },
      "source": [
        "### Training to a subset of Dataset First\n",
        "\n",
        "This is just to see if the model is backpropagating before putting in into the full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "efd13def-9751-4e0e-89bf-666a98444d02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd13def-9751-4e0e-89bf-666a98444d02",
        "outputId": "4b02ddec-6985-4dcd-84c8-53a691be5fa8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LR: 8.0000, Train Loss: 2.3005, Train Accuracy: 8.90%, Temperatures:(0.15, 10.00)\n",
            "Epoch 2, LR: 40.0000, Train Loss: 2.2877, Train Accuracy: 12.10%, Temperatures:(0.07, 5.00)\n",
            "Epoch 3, LR: 200.0000, Train Loss: 2.3111, Train Accuracy: 12.20%, Temperatures:(0.04, 2.50)\n",
            "Epoch 4, LR: 200.0000, Train Loss: 2.3020, Train Accuracy: 12.10%, Temperatures:(0.02, 1.25)\n",
            "Epoch 5, LR: 200.0000, Train Loss: 2.3262, Train Accuracy: 8.80%, Temperatures:(0.01, 0.62)\n",
            "Epoch 6, LR: 200.0000, Train Loss: 2.3035, Train Accuracy: 17.80%, Temperatures:(0.00, 0.31)\n",
            "Epoch 7, LR: 200.0000, Train Loss: 2.2918, Train Accuracy: 15.60%, Temperatures:(0.00, 0.16)\n",
            "Epoch 8, LR: 200.0000, Train Loss: 2.2861, Train Accuracy: 13.60%, Temperatures:(0.00, 0.08)\n",
            "Epoch 9, LR: 200.0000, Train Loss: 2.2817, Train Accuracy: 14.60%, Temperatures:(0.00, 0.04)\n",
            "Epoch 10, LR: 200.0000, Train Loss: 2.2579, Train Accuracy: 17.40%, Temperatures:(0.00, 0.02)\n",
            "Epoch 11, LR: 200.0000, Train Loss: 2.2776, Train Accuracy: 17.30%, Temperatures:(0.00, 0.01)\n",
            "Epoch 12, LR: 200.0000, Train Loss: 2.2293, Train Accuracy: 23.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 13, LR: 200.0000, Train Loss: 2.2186, Train Accuracy: 21.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 14, LR: 200.0000, Train Loss: 2.1750, Train Accuracy: 21.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 15, LR: 200.0000, Train Loss: 2.1943, Train Accuracy: 23.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 16, LR: 200.0000, Train Loss: 2.1851, Train Accuracy: 17.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 17, LR: 200.0000, Train Loss: 2.1176, Train Accuracy: 34.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 18, LR: 200.0000, Train Loss: 2.1230, Train Accuracy: 27.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 19, LR: 200.0000, Train Loss: 2.0778, Train Accuracy: 32.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 20, LR: 200.0000, Train Loss: 2.0756, Train Accuracy: 32.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 21, LR: 200.0000, Train Loss: 2.0417, Train Accuracy: 32.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 22, LR: 200.0000, Train Loss: 2.0254, Train Accuracy: 36.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 23, LR: 200.0000, Train Loss: 2.0163, Train Accuracy: 38.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 24, LR: 200.0000, Train Loss: 1.9876, Train Accuracy: 38.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 25, LR: 200.0000, Train Loss: 1.9777, Train Accuracy: 36.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 26, LR: 200.0000, Train Loss: 1.9615, Train Accuracy: 41.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 27, LR: 200.0000, Train Loss: 1.9576, Train Accuracy: 43.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 28, LR: 200.0000, Train Loss: 1.9402, Train Accuracy: 40.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 29, LR: 200.0000, Train Loss: 1.9349, Train Accuracy: 41.50%, Temperatures:(0.00, 0.00)\n",
            "Epoch 30, LR: 200.0000, Train Loss: 1.9257, Train Accuracy: 44.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 31, LR: 200.0000, Train Loss: 1.9066, Train Accuracy: 44.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 32, LR: 200.0000, Train Loss: 1.8917, Train Accuracy: 47.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 33, LR: 200.0000, Train Loss: 1.8900, Train Accuracy: 41.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 34, LR: 200.0000, Train Loss: 1.8686, Train Accuracy: 48.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 35, LR: 200.0000, Train Loss: 1.8592, Train Accuracy: 48.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 36, LR: 200.0000, Train Loss: 1.8533, Train Accuracy: 48.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 37, LR: 200.0000, Train Loss: 1.8509, Train Accuracy: 46.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 38, LR: 200.0000, Train Loss: 1.8459, Train Accuracy: 45.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 39, LR: 200.0000, Train Loss: 1.8325, Train Accuracy: 47.50%, Temperatures:(0.00, 0.00)\n",
            "Epoch 40, LR: 200.0000, Train Loss: 1.8244, Train Accuracy: 49.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 41, LR: 200.0000, Train Loss: 1.8128, Train Accuracy: 49.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 42, LR: 200.0000, Train Loss: 1.8090, Train Accuracy: 48.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 43, LR: 200.0000, Train Loss: 1.8032, Train Accuracy: 47.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 44, LR: 200.0000, Train Loss: 1.7960, Train Accuracy: 48.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 45, LR: 200.0000, Train Loss: 1.7899, Train Accuracy: 48.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 46, LR: 200.0000, Train Loss: 1.7849, Train Accuracy: 51.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 47, LR: 200.0000, Train Loss: 1.7900, Train Accuracy: 48.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 48, LR: 200.0000, Train Loss: 1.7823, Train Accuracy: 54.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 49, LR: 200.0000, Train Loss: 1.7899, Train Accuracy: 48.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 50, LR: 200.0000, Train Loss: 1.7926, Train Accuracy: 53.10%, Temperatures:(0.00, 0.00)\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "lr = params_RRAM[\"ext_lr\"] / 25  # Initial learning rate\n",
        "num_epochs = 50\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 1:\n",
        "        lr *= 5\n",
        "    elif epoch == 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train()\n",
        "    outputs = model_RRAM(train_in)\n",
        "    loss = criterion(outputs, train_lab)\n",
        "    loss.backward()\n",
        "    model_RRAM.backprop(lr)\n",
        "    model_RRAM.anneal(train_in, train_lab,0.5, 0.5)\n",
        "\n",
        "    _, train_preds = torch.max(outputs, dim=1)\n",
        "    train_accuracy = (train_preds == train_lab).float().mean().item() * 100\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {loss.item():.4f}, \"\n",
        "          f\"Train Accuracy: {train_accuracy:.2f}%, Temperatures:({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if epoch % 50 == 0 and epoch != 0:\n",
        "        lr /= 2\n",
        "\n",
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614",
      "metadata": {
        "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614"
      },
      "source": [
        "### Loading Past Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
        "outputId": "6c634a1f-7a43-4dd3-c309-323bb519f035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Validation Loss: 2.076066\n",
            "\n",
            " Parameters for Best Loss Model: {'scaling': 3, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 1.2, 'R_INV': 2400.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 500, 'epochs': 1000, 'temperature_1': 0.3, 'temperature_2': 25, 'monitor_annealing': False, 'decay1': 0.99, 'decay2': 0.95, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 500, 'alpha': 0.1}\n",
            "\n",
            " Best Validation Accuracy: 30.18\n",
            "\n",
            " Parameters for Best Accuracy Model: {'scaling': 3, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 1.2, 'R_INV': 2400.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 500, 'epochs': 1000, 'temperature_1': 0.3, 'temperature_2': 25, 'monitor_annealing': False, 'decay1': 0.99, 'decay2': 0.95, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 500, 'alpha': 0.1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-121-09f9da36490d>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
            "<ipython-input-121-09f9da36490d>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Load best validation loss model\n",
        "    with open(\"Best_Val_Loss.txt\", 'r') as f:\n",
        "        global_best_val_loss = float(f.read())\n",
        "    with open(\"Best_Params_Loss.txt\", 'r') as f:\n",
        "        params_best_loss = ast.literal_eval(f.read())\n",
        "\n",
        "    model_best_loss = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
        "\n",
        "    print(\"\\n Best Validation Loss:\", global_best_val_loss)\n",
        "    print(\"\\n Parameters for Best Loss Model:\", params_best_loss)\n",
        "\n",
        "    checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
        "    model_best_loss.load_state_dict(checkpoint_loss)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best loss model:\", e)\n",
        "    global_best_val_loss = float('inf')\n",
        "    print(\"No Saved Model for Best Loss\")\n",
        "\n",
        "try:\n",
        "    # Load best validation accuracy model\n",
        "    with open(\"Best_Val_Acc.txt\", 'r') as f:\n",
        "        global_best_val_acc = float(f.read())\n",
        "    with open(\"Best_Params_Acc.txt\", 'r') as f:\n",
        "        params_best_acc = ast.literal_eval(f.read())\n",
        "\n",
        "    model_best_acc = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
        "\n",
        "    print(\"\\n Best Validation Accuracy:\", global_best_val_acc)\n",
        "    print(\"\\n Parameters for Best Accuracy Model:\", params_best_acc)\n",
        "\n",
        "    checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n",
        "    model_best_acc.load_state_dict(checkpoint_acc)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best accuracy model:\", e)\n",
        "    global_best_val_acc = 0.0\n",
        "    print(\"No Saved Model for Best Accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "786757d6-3ef8-4327-900a-94924d5a1b57",
      "metadata": {
        "id": "786757d6-3ef8-4327-900a-94924d5a1b57"
      },
      "outputs": [],
      "source": [
        "history_RRAM = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_accuracy\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_accuracy\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013",
      "metadata": {
        "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013"
      },
      "source": [
        "### Complete Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
        "outputId": "23bc9f36-bab7-4898-d4ee-dce0788677ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LR: 8.0000, Train Loss: 2.2120, Train Acc: 20.80%, Val Loss: 2.1311, Val Acc: 24.69%, Temperatures: (0.30, 20.00)\n",
            "Epoch 2, LR: 40.0000, Train Loss: 2.0297, Train Acc: 22.61%, Val Loss: 1.9400, Val Acc: 24.26%, Temperatures: (0.30, 18.00)\n",
            "Model saved with best validation loss: 1.939970\n",
            "Epoch 3, LR: 200.0000, Train Loss: 1.8877, Train Acc: 34.72%, Val Loss: 1.8228, Val Acc: 36.37%, Temperatures: (0.29, 16.20)\n",
            "Model saved with best validation loss: 1.822831\n",
            "Model saved with best validation accuracy: 36.370000\n",
            "Epoch 4, LR: 200.0000, Train Loss: 1.8288, Train Acc: 36.62%, Val Loss: 1.8135, Val Acc: 35.93%, Temperatures: (0.29, 14.58)\n",
            "Model saved with best validation loss: 1.813488\n",
            "Epoch 5, LR: 200.0000, Train Loss: 1.8470, Train Acc: 35.27%, Val Loss: 1.8124, Val Acc: 39.91%, Temperatures: (0.29, 13.12)\n",
            "Model saved with best validation loss: 1.812388\n",
            "Model saved with best validation accuracy: 39.910000\n"
          ]
        }
      ],
      "source": [
        "lr = params_RRAM[\"ext_lr\"] / 25\n",
        "num_epochs = params_RRAM[\"epochs\"]\n",
        "patience_stop, patience_lr, patience_T = params_RRAM[\"early_stop_wait\"], params_RRAM[\"fine_tune_wait\"], params_RRAM[\"temperature_wait\"]\n",
        "wait_lr, wait_stop = 0, 0\n",
        "cur_best_val_loss, cur_best_val_acc = float('inf'), 0\n",
        "temp_boosted = False\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 0:\n",
        "        lr = lr\n",
        "    elif epoch <= 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train().to(device)\n",
        "    train_loss, train_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model_RRAM(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        model_RRAM.backprop(lr)\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        if params_RRAM[\"anneal_per_batch\"]:\n",
        "            model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    train_loss /= total_samples\n",
        "    train_accuracy = 100 * train_correct / total_samples\n",
        "\n",
        "    model_RRAM.eval()\n",
        "    val_loss, val_correct, total_test_samples = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_RRAM(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_test_samples += inputs.size(0)\n",
        "\n",
        "    val_loss /= total_test_samples\n",
        "    val_accuracy = 100 * val_correct / total_test_samples\n",
        "\n",
        "    history_RRAM[\"train_loss\"].append(train_loss)\n",
        "    history_RRAM[\"train_accuracy\"].append(train_accuracy)\n",
        "    history_RRAM[\"val_loss\"].append(val_loss)\n",
        "    history_RRAM[\"val_accuracy\"].append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Temperatures: ({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if val_loss < global_best_val_loss:\n",
        "        global_best_val_loss = val_loss\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_loss.pth\")\n",
        "        with open(\"Best_Val_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_loss:.6f}\")\n",
        "        with open(\"Best_Params_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation loss: {val_loss:.6f}\")\n",
        "\n",
        "    if val_accuracy > global_best_val_acc:\n",
        "        global_best_val_acc = val_accuracy\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_acc.pth\")\n",
        "        with open(\"Best_Val_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_accuracy:.6f}\")\n",
        "        with open(\"Best_Params_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation accuracy: {val_accuracy:.6f}\")\n",
        "\n",
        "    if params_RRAM[\"anneal_per_epoch\"]:\n",
        "        model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    if wait_lr >= patience_lr and epoch > 3:\n",
        "        lr /= 5\n",
        "        wait_lr = 0\n",
        "        print(f\"No improvement for {patience_lr} epochs. Reducing LR to {lr:.4f}\")\n",
        "\n",
        "    if wait_lr >= patience_T and not temp_boosted:\n",
        "        model_RRAM.temperature_2 *= params_RRAM[\"T_boost\"]\n",
        "        temp_boosted = True\n",
        "        print(f\"Training plateau detected. Temporarily increasing temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "    if val_loss < cur_best_val_loss - 0.001 or val_accuracy > cur_best_val_acc + 0.1:\n",
        "        if temp_boosted:\n",
        "            model_RRAM.temperature_2 /= params_RRAM[\"T_boost\"]\n",
        "            temp_boosted = False\n",
        "            print(f\"Training improved. Restoring temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "        cur_best_val_loss = min(cur_best_val_loss, val_loss)\n",
        "        cur_best_val_acc = max(cur_best_val_acc, val_accuracy)\n",
        "        wait_stop = 0\n",
        "        wait_lr = 0\n",
        "    else:\n",
        "        wait_stop += 1\n",
        "        wait_lr += 1\n",
        "\n",
        "    if wait_stop >= patience_stop and epoch > 6:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b",
      "metadata": {
        "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b"
      },
      "outputs": [],
      "source": [
        "plot_history(history_RRAM, num_epochs, \"RRAM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d430e62-7d42-4210-8696-64d49d843f91",
      "metadata": {
        "id": "3d430e62-7d42-4210-8696-64d49d843f91"
      },
      "outputs": [],
      "source": [
        "# model_RRAM.load_state_dict(model_best_acc.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69",
      "metadata": {
        "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb",
      "metadata": {
        "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb"
      },
      "source": [
        "### Current Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51271c7c-25b1-4702-9db1-9ae4b805843c",
      "metadata": {
        "id": "51271c7c-25b1-4702-9db1-9ae4b805843c"
      },
      "outputs": [],
      "source": [
        "print(0 + (model_RRAM.w > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d477c9e-5678-4d07-a5ac-48f01480c916",
      "metadata": {
        "id": "9d477c9e-5678-4d07-a5ac-48f01480c916"
      },
      "outputs": [],
      "source": [
        "cm = test(model_RRAM, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7941df-4678-4955-8a0f-f38b43f6b197",
      "metadata": {
        "id": "ed7941df-4678-4955-8a0f-f38b43f6b197"
      },
      "source": [
        "## Best Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867574d7-3627-49ff-a430-1d658fa4d655",
      "metadata": {
        "id": "867574d7-3627-49ff-a430-1d658fa4d655"
      },
      "outputs": [],
      "source": [
        "0+1*(model_best.w>0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78",
      "metadata": {
        "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78"
      },
      "outputs": [],
      "source": [
        "cm = test(model_best, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce",
      "metadata": {
        "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce"
      },
      "source": [
        "## PWL Generation\n",
        "\n",
        "Let's assume that we will program the two crossbars with seperate PWLs. That is, during programming, we will cut the Inverting Amplifier stages with a pass transistor and connect the programming lines with a pass transistor. First array has 16 Top PWLs and 8 Bottom PWLs. Second array has 8 Top PWLs and 4 Bottom PWLs. And then once the programming switch is toggled to inference mode, only the 16 Top PWLs are to be changed. Let's also generate a PWL for that too.\n",
        "\n",
        "In the code below, we will first maintain tuples for each PWL that holds what the voltage should be. And then we will write a function that will take there and space pulses of the given voltage that are 100us apart from other and have an ON duration of 100us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64",
      "metadata": {
        "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [list() for i in range(16)]\n",
        "BL_FC1 = [list() for i in range(8)]\n",
        "WL_FC2 = [list() for i in range(8)]\n",
        "BL_FC2 = [list() for i in range(4)]\n",
        "Mode = []\n",
        "Mode_B = []\n",
        "\n",
        "V_WRITE = 1.5\n",
        "V_READ = 0.1\n",
        "V_mode = 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c647afda-e1a7-47a7-b634-212ec5527be2",
      "metadata": {
        "id": "c647afda-e1a7-47a7-b634-212ec5527be2"
      },
      "source": [
        "#### Fully Connected Weights 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03334172-89f6-4d73-9461-6ac922bdb6ea",
      "metadata": {
        "id": "03334172-89f6-4d73-9461-6ac922bdb6ea"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w1>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49287afe-8437-40aa-8825-93f2cffe3a66",
      "metadata": {
        "id": "49287afe-8437-40aa-8825-93f2cffe3a66"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC1[ind_j].append(V_WRITE)\n",
        "        else: WL_FC1[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC1[ind_i].append(0)\n",
        "        else: BL_FC1[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be77131c-005d-4f06-8a70-f40d267eb67e",
      "metadata": {
        "id": "be77131c-005d-4f06-8a70-f40d267eb67e"
      },
      "source": [
        "#### Fully Connected Weights 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d",
      "metadata": {
        "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w2>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79",
      "metadata": {
        "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC2[ind_j].append(V_WRITE)\n",
        "        else: WL_FC2[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC2[ind_i].append(0)\n",
        "        else: BL_FC2[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a602368f-07a2-4beb-90e3-d782ca717fea",
      "metadata": {
        "id": "a602368f-07a2-4beb-90e3-d782ca717fea"
      },
      "source": [
        "#### Filling Out Programming Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11",
      "metadata": {
        "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [i + [0,0] for i in WL_FC1]\n",
        "BL_FC1 = [i + [0,0] for i in BL_FC1]\n",
        "while(len(WL_FC2[0]) < len(WL_FC1[0])):\n",
        "    WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "    BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "Mode.extend([V_mode]*(len(WL_FC1[0])-1) + [-V_mode])\n",
        "Mode_B.extend([-V_mode]*(len(WL_FC1[0])-1) + [V_mode])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f953198a-a107-428c-9624-3c712086e922",
      "metadata": {
        "id": "f953198a-a107-428c-9624-3c712086e922"
      },
      "outputs": [],
      "source": [
        "print(WL_FC1[0])\n",
        "print(BL_FC1[0])\n",
        "print(WL_FC2[0])\n",
        "print(BL_FC2[0])\n",
        "print(Mode)\n",
        "print(Mode_B)\n",
        "print(len(WL_FC1[0]), len(BL_FC1[0]), len(WL_FC2[0]), len(BL_FC2[0]), len(Mode), len(Mode_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92339f84-e8d6-4280-92af-e5215aa129a0",
      "metadata": {
        "id": "92339f84-e8d6-4280-92af-e5215aa129a0"
      },
      "source": [
        "### Inference: Loading the Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58",
      "metadata": {
        "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58"
      },
      "outputs": [],
      "source": [
        "val_inputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248",
      "metadata": {
        "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248"
      },
      "outputs": [],
      "source": [
        "V_1 = 0.1\n",
        "V_0 = -0.1\n",
        "include_testing = True\n",
        "include_every = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73",
      "metadata": {
        "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73"
      },
      "outputs": [],
      "source": [
        "if include_testing:\n",
        "    for i in val_inputs[::include_every]:\n",
        "        i = i.flatten()\n",
        "        for ind, j in enumerate(i):\n",
        "            WL_FC1[ind].append(V_1 if j==1 else V_0)\n",
        "        BL_FC1 = [i + [0,] for i in BL_FC1]\n",
        "        WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "        BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "        Mode = Mode + [-V_mode,]\n",
        "        Mode_B = Mode_B + [V_mode,]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c",
      "metadata": {
        "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c"
      },
      "source": [
        "### PWL Convertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98af5ff-8f34-4472-89fc-e308d98d4072",
      "metadata": {
        "id": "c98af5ff-8f34-4472-89fc-e308d98d4072"
      },
      "outputs": [],
      "source": [
        "def pwl(l):\n",
        "    t = 0\n",
        "    res = \"pwl(time, 0us, 0V\"\n",
        "    for i in l:\n",
        "        res += f\", {t+5}us, {i:.2f}V, {t+100}us, {i:.2f}V, {t+105}us, 0V, {t+200}us, 0V\"\n",
        "        t+=200\n",
        "    res += \")\"\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54850dbc-1317-44a2-9093-c5a4e048094c",
      "metadata": {
        "id": "54850dbc-1317-44a2-9093-c5a4e048094c"
      },
      "outputs": [],
      "source": [
        "pwl_data = []\n",
        "\n",
        "for ind, i in enumerate(WL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(WL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "pwl_data.append({\"Signal\": \"Mode\", \"Index\": \"\", \"PWL\": pwl(Mode)})\n",
        "pwl_data.append({\"Signal\": \"Mode_b\", \"Index\": \"\", \"PWL\": pwl(Mode_B)})\n",
        "\n",
        "pwl_data = pd.DataFrame(pwl_data)\n",
        "pwl_data.to_csv(\"pwl_data.csv\", index=False)\n",
        "pwl_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174",
      "metadata": {
        "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174"
      },
      "source": [
        "#### Testing Accuracy on 160 Images\n",
        "ADS isn't allowing PWLs longer than 160 Images, so let's check software accuracy for the same too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e",
      "metadata": {
        "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, val_inputs[::4], val_labels[::4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f",
      "metadata": {
        "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, train_inputs, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1079074f-8781-43af-b52e-fb3581ef8931",
      "metadata": {
        "id": "1079074f-8781-43af-b52e-fb3581ef8931"
      },
      "source": [
        "## Simulation Data from ADS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d523a2-f99f-46bb-93e0-fead2768da75",
      "metadata": {
        "id": "e0d523a2-f99f-46bb-93e0-fead2768da75"
      },
      "outputs": [],
      "source": [
        "simu = pd.read_csv(\"Testing_160_Images.csv\")\n",
        "simu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd96e845-0c19-470b-8910-6b45df78022c",
      "metadata": {
        "id": "fd96e845-0c19-470b-8910-6b45df78022c"
      },
      "outputs": [],
      "source": [
        "def remove_units(value):\n",
        "    return float(value.replace('E', 'e').split('V')[0].replace('sec', ''))\n",
        "\n",
        "simu['time'] = simu['time'].apply(remove_units)\n",
        "for col in ['A', 'X', 'V', 'T']:\n",
        "    simu[col] = simu[col].apply(remove_units)\n",
        "simu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223576d6-266c-49bd-aaca-ff3444617f09",
      "metadata": {
        "id": "223576d6-266c-49bd-aaca-ff3444617f09"
      },
      "source": [
        "We just need one sample every 0.1ms samples of these starting from 2.050ms to 33.850ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3",
      "metadata": {
        "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3"
      },
      "outputs": [],
      "source": [
        "t_stamps = np.arange(2.05e-3, 33.9e-3, 0.2e-3)\n",
        "t_stamps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700",
      "metadata": {
        "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700"
      },
      "outputs": [],
      "source": [
        "sampled = []\n",
        "window = 0.02e-3\n",
        "\n",
        "for t in t_stamps:\n",
        "    filtered = simu[(simu['time'] >= t - window) & (simu['time'] <= t + window)]\n",
        "\n",
        "    avg_A = filtered['A'].mean()\n",
        "    avg_X = filtered['X'].mean()\n",
        "    avg_V = filtered['V'].mean()\n",
        "    avg_T = filtered['T'].mean()\n",
        "\n",
        "    sampled.append({\n",
        "        'Image Index': t,\n",
        "        'A': avg_A,\n",
        "        'X': avg_X,\n",
        "        'V': avg_V,\n",
        "        'T': avg_T\n",
        "    })\n",
        "\n",
        "sampled = pd.DataFrame(sampled)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e",
      "metadata": {
        "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e"
      },
      "outputs": [],
      "source": [
        "def get_max_column(row):\n",
        "    return row[['A', 'X', 'V', 'T']].idxmax()\n",
        "sampled['Predicted Class'] = sampled.apply(get_max_column, axis=1)\n",
        "sampled.to_csv(\"Sampled_Results.csv\", index=False)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1143c06-5631-4c79-9965-0cb937929706",
      "metadata": {
        "id": "d1143c06-5631-4c79-9965-0cb937929706"
      },
      "outputs": [],
      "source": [
        "ground_truth = ['A']*40 + ['X']*40 + ['V']*40 + ['T']*40\n",
        "correct_predictions = sampled['Predicted Class'] == ground_truth\n",
        "accuracy = correct_predictions.sum() / len(ground_truth)\n",
        "print(accuracy*100,end=\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918b4552-b0d3-4768-bfe7-9b874959d42c",
      "metadata": {
        "id": "918b4552-b0d3-4768-bfe7-9b874959d42c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 3.5))\n",
        "\n",
        "plt.scatter(sampled.index, sampled['A'], color='red', label='A_pred', s=30, marker='o')  # Red dots for A\n",
        "plt.scatter(sampled.index, sampled['X'], color='blue', label='X_pred', s=30, marker='o')  # Blue dots for X\n",
        "plt.scatter(sampled.index, sampled['T'], color='green', label='T_pred', s=30, marker='o')  # Green dots for T\n",
        "plt.scatter(sampled.index, sampled['V'], color='orange', label='V_pred', s=30, marker='o')  # Orange dots for V\n",
        "\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Predicted Voltages (V)')\n",
        "plt.legend()\n",
        "\n",
        "plt.axvline(x=40, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=80, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=120, color='gray', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.text(20, plt.ylim()[1]*(-0.8), 'A', fontsize=15, color='black', ha='center')\n",
        "plt.text(60, plt.ylim()[1]*0.8, 'X', fontsize=15, color='black', ha='center')\n",
        "plt.text(100, plt.ylim()[1]*0.8, 'V', fontsize=15, color='black', ha='center')\n",
        "plt.text(140, plt.ylim()[1]*(-0.8), 'T', fontsize=15, color='black', ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8",
      "metadata": {
        "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}