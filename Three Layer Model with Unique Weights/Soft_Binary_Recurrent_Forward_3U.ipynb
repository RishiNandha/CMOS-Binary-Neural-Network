{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87",
      "metadata": {
        "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87"
      },
      "source": [
        "# Soft Binary Neural Network with Recurrent Crossbar Recycling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508058d8-e23a-4c29-aad7-c2b233d621c9",
      "metadata": {
        "id": "508058d8-e23a-4c29-aad7-c2b233d621c9"
      },
      "source": [
        "## Imports and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f",
      "metadata": {
        "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d406d54c-db27-4536-a8c1-f46437f6fb71",
      "metadata": {
        "id": "d406d54c-db27-4536-a8c1-f46437f6fb71"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, num_epochs, element):\n",
        "    epochs = range(len(history[list(history.keys())[0]]))\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
        "    ax1.plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
        "    ax1.set_xlabel(\"Epochs\", fontsize=14)\n",
        "    ax1.set_ylabel(\"Loss\", fontsize=14, color=\"blue\")\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
        "    ax1.legend(loc=\"upper left\")\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(epochs, history[\"train_accuracy\"], label=\"Train Accuracy\", color=\"green\")\n",
        "    ax2.plot(epochs, history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"orange\")\n",
        "    ax2.set_ylabel(\"Accuracy (%)\", fontsize=14, color=\"green\")\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=\"green\")\n",
        "    ax2.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.title(f\"Training and Validation Metrics for {element}\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c658023-75df-4754-a617-a8ba6d08d068",
      "metadata": {
        "id": "7c658023-75df-4754-a617-a8ba6d08d068"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, class_names=None):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e",
      "metadata": {
        "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e"
      },
      "source": [
        "### MNIST Handwritten Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d3bbad17-7067-4f06-8755-012646ca9567",
      "metadata": {
        "id": "d3bbad17-7067-4f06-8755-012646ca9567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e5ab2e-f86d-4b9a-c285-64f14efd7cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.30MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.39MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.06MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class BinarizeAndAddNoiseTransform:\n",
        "    def __init__(self, threshold_max, threshold_min, noise_std):\n",
        "        self.threshold_max = threshold_max\n",
        "        self.threshold_min = threshold_min\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = transforms.ToTensor()(img).to(device)\n",
        "        thresh = torch.rand(1, device=device) * (self.threshold_max - self.threshold_min) + self.threshold_min\n",
        "        img = (img > thresh).float()\n",
        "        img = img[:,4:-4, 4:-4]\n",
        "        noise = torch.randn(img.size(), device=device) * self.noise_std\n",
        "        noisy_img = img + noise\n",
        "        return noisy_img\n",
        "\n",
        "binary_noise_transform = transforms.Compose([\n",
        "    BinarizeAndAddNoiseTransform(0.45, 0.5, 0.05)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=binary_noise_transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=1000, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=binary_noise_transform)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd",
      "metadata": {
        "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd"
      },
      "outputs": [],
      "source": [
        "# Get a subset of the dataset\n",
        "train_in, train_lab = next(iter(train_loader))\n",
        "val_in, val_lab = next(iter(test_loader))\n",
        "\n",
        "# Move data to the appropriate device\n",
        "train_in, train_lab = train_in.to(device), train_lab.to(device)\n",
        "val_in, val_lab = val_in.to(device), val_lab.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
        "outputId": "a2afdc4a-85b6-45bf-f40b-d28e4126c0a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(15, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(train_in[i].cpu().squeeze(), cmap='gray')\n",
        "    ax.set_title(f\"Label: {train_lab[i].item()}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "train_in.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a",
      "metadata": {
        "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a"
      },
      "source": [
        "## Custom Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a",
      "metadata": {
        "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def tensor_stats(tensor, name=\"Tensor\"):\n",
        "    tensor = tensor.to(device)\n",
        "    mean_magnitude = tensor.abs().mean().item()\n",
        "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
        "    def __init__(self, scaling, G_ON, G_OFF, V_INV, R_INV, V_1, V_0, zeta, initial_factor, crossbar=(64,64),\n",
        "                 input_size=400, encoding_size=3, output_size=10, data_in=40, bin_active=True,\n",
        "                 monitor_volts=False, monitor_grads=True, monitor_latents=False, dropout=0.01, alpha = 0.9,\n",
        "                 int_lr=0.01, int_norm=True, temperature_1 = 0.4, temperature_2 = 30,monitor_annealing=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w = nn.Parameter(initial_factor * torch.empty(crossbar, device=device))\n",
        "        nn.init.xavier_uniform_(self.w)\n",
        "        self.w.date = self.w.data * initial_factor\n",
        "\n",
        "        self.G_ON, self.G_OFF = torch.tensor(G_ON, device=device)*scaling, torch.tensor(G_OFF, device=device)*scaling\n",
        "        self.V_INV, self.R_INV = torch.tensor(V_INV, device=device), torch.tensor(R_INV, device=device)\n",
        "        self.V_1, self.V_0 = torch.tensor(V_1, device=device), torch.tensor(V_0, device=device)\n",
        "\n",
        "        self.crossbar_in, self.crossbar_out = crossbar\n",
        "        self.encoding, self.data_in, self.output_size = encoding_size, data_in, output_size\n",
        "        self.r_passes = input_size // data_in\n",
        "        self.second_size = self.crossbar_out - self.encoding*self.r_passes\n",
        "        self.out1size = self.encoding * self.r_passes\n",
        "\n",
        "        self.first_bias = (crossbar[0] - data_in) % encoding_size\n",
        "        self.second_bias = (crossbar[0])%(self.r_passes*encoding_size)\n",
        "        self.final_bias = (crossbar[0])%(self.second_size)\n",
        "\n",
        "        self.feed_repeats = (crossbar[0] - data_in)//encoding_size\n",
        "        self.second_repeats = (crossbar[0])//(self.r_passes*encoding_size)\n",
        "        self.final_repeats = (crossbar[0])//(self.second_size)\n",
        "\n",
        "        self.zeta, self.int_lr = torch.tensor(zeta, device=device), torch.tensor(int_lr, device=device)\n",
        "        self.bin_active, self.int_norm = bin_active, int_norm\n",
        "        self.monitor_volts, self.monitor_grads, self.monitor_latents = monitor_volts, monitor_grads, monitor_latents\n",
        "        self.monitor_annealing = monitor_annealing\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.temperature_1 = temperature_1\n",
        "        self.temperature_2 = temperature_2\n",
        "        self.device = device\n",
        "\n",
        "        self.velocity = torch.zeros(crossbar, device = device)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def INV_AMP(self, x, R_INV):\n",
        "        return -self.V_INV * torch.tanh(R_INV * x / self.V_INV)\n",
        "\n",
        "    def SOFT_BIN(self, x):\n",
        "        if self.bin_active: return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
        "        else: return self.G_ON * x * self.zeta * 0.4\n",
        "\n",
        "    def PREPROCESS(self, img):\n",
        "        return (self.V_1 - self.V_0) * img.to(device) + self.V_0\n",
        "\n",
        "    def ANNEALER(self):\n",
        "        prob = torch.exp(torch.tensor(-1.0, device=self.device) / self.temperature_1)\n",
        "        prob = torch.clamp(prob, min=1e-3, max=1)\n",
        "\n",
        "        rand_vals = torch.rand((64, 64), device=self.device)\n",
        "        annealed_mask = torch.where(rand_vals < prob, -1, torch.where(rand_vals < 2 * prob, 0, 1))\n",
        "\n",
        "        return annealed_mask\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
        "        img = self.PREPROCESS(img.view(img.size(0), -1))\n",
        "        bias = self.PREPROCESS(((-1) ** torch.arange(self.first_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias2 = self.PREPROCESS(((-1) ** torch.arange(self.second_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias3 = self.PREPROCESS(((-1) ** torch.arange(self.final_bias, device=device)).repeat(img.shape[0], 1))\n",
        "\n",
        "        # RRAM Soft Binarization\n",
        "        g = self.SOFT_BIN(self.w)\n",
        "        if self.monitor_latents: tensor_stats(self.w, \"Latent Weights:\")\n",
        "\n",
        "        # Recurrent Encoding Layer\n",
        "        feedback = torch.zeros((img.shape[0], self.encoding*self.feed_repeats), device=device)\n",
        "        out1 = torch.zeros((img.shape[0], self.out1size), device = device)\n",
        "\n",
        "        for r_pass in range(self.r_passes):\n",
        "            ind_s, ind_f = self.crossbar_out - (r_pass+1)*self.encoding, self.crossbar_out - (r_pass)*self.encoding\n",
        "            ind_a, ind_b = self.out1size - (r_pass+1)*self.encoding, self.out1size - (r_pass)*self.encoding\n",
        "\n",
        "            x = torch.cat((feedback, bias, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
        "            x = F.linear(x, g[ind_s:ind_f, : ], bias=None)\n",
        "\n",
        "            out1[:, ind_a:ind_b] = self.INV_AMP(x, self.R_INV)\n",
        "            if self.monitor_volts: tensor_stats(feedback, f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
        "\n",
        "            feedback = out1[:, ind_a:ind_b].repeat(1,self.feed_repeats)\n",
        "\n",
        "        # Feature Extraction layer\n",
        "        ind_p, ind_q = self.output_size, self.output_size + self.second_size\n",
        "        x = torch.cat((bias2, out1.repeat(1,self.second_repeats)), dim = 1)\n",
        "\n",
        "        x = F.linear(x, g[ind_p:ind_q, :], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Voltages after Second Layer\")\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Classification Layer\n",
        "        x = torch.cat((bias3, x.repeat(1,self.final_repeats)), dim = 1)\n",
        "        x = F.linear(x, g[:self.output_size, : ], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Last Layer\")\n",
        "\n",
        "        return x\n",
        "\n",
        "    def backprop(self, ext_lr):\n",
        "        with torch.no_grad():\n",
        "            if self.w.grad is not None:\n",
        "                grad = self.w.grad.detach().to(device)\n",
        "                for i in range(grad.shape[0]):\n",
        "                    if self.int_norm:\n",
        "                        grad[i] = self.int_lr * grad[i] / (torch.norm(grad[i]) + 1e-20)\n",
        "                    grad[i] = grad[i]\n",
        "                grad = grad + self.alpha*self.velocity\n",
        "                if self.monitor_grads: tensor_stats(ext_lr*grad, \"Gradients\")\n",
        "                self.w -= grad * ext_lr\n",
        "                self.velocity = grad\n",
        "                self.w.grad.zero_()\n",
        "\n",
        "    def anneal(self, inputs, labels, decay1, decay2):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.forward(inputs)\n",
        "            old_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "            old_w = self.w.data.clone()\n",
        "\n",
        "            self.w.data = self.w.data * self.ANNEALER()\n",
        "            outputs = self.forward(inputs)\n",
        "            new_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "\n",
        "            acceptance_prob = torch.exp(torch.tensor(-(new_loss - old_loss) / self.temperature_2, device=self.device))\n",
        "            if self.monitor_annealing: print(\"Old & New Losses\", old_loss, new_loss,\"Probab:\", acceptance_prob)\n",
        "            if new_loss < old_loss or torch.rand(1, device=self.device) < acceptance_prob:\n",
        "                if self.monitor_annealing: print(\"Annealed weights accepted\")\n",
        "            else:\n",
        "                self.w.data = old_w\n",
        "            if self.temperature_1 > 0.001: self.temperature_1 *= decay1\n",
        "            if self.temperature_2 > 0.001: self.temperature_2 *= decay2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845d51da-8368-4c97-89a2-9fc1374f408b",
      "metadata": {
        "id": "845d51da-8368-4c97-89a2-9fc1374f408b"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00",
      "metadata": {
        "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00"
      },
      "outputs": [],
      "source": [
        "params_RRAM = {\n",
        "    \"scaling\": 2,\n",
        "    \"G_ON\": 6e-5,\n",
        "    \"G_OFF\": 2.88e-6,\n",
        "    \"V_INV\": 1.2,\n",
        "    \"R_INV\": 2500.0,\n",
        "    \"V_1\": 0.1,\n",
        "    \"V_0\": -0.1,\n",
        "    \"zeta\": 10.0,\n",
        "    \"initial_factor\": 0.01,\n",
        "    \"crossbar\": (64, 64),\n",
        "    \"input_size\": 400,\n",
        "    \"encoding_size\": 3,\n",
        "    \"output_size\": 10,\n",
        "    \"data_in\": 40,\n",
        "    \"bin_active\": True,\n",
        "    \"monitor_volts\": False,\n",
        "    \"monitor_grads\": False,\n",
        "    \"monitor_latents\": False,\n",
        "    \"dropout\": 0.05,\n",
        "    \"int_lr\": 0.01,\n",
        "    \"int_norm\": True,\n",
        "    \"ext_lr\": 100,\n",
        "    \"epochs\": 1000,\n",
        "    \"temperature_1\": 0.3,\n",
        "    \"temperature_2\": 0.25,\n",
        "    \"monitor_annealing\": False,\n",
        "    \"decay1\" : 0.999,\n",
        "    \"decay2\" : 0.1,\n",
        "    \"anneal_per_epoch\" : False,\n",
        "    \"anneal_per_batch\" : True,\n",
        "    \"early_stop_wait\": 21,\n",
        "    \"fine_tune_wait\": 7,\n",
        "    \"temperature_wait\": 3,\n",
        "    \"T_boost\": 1,\n",
        "    \"alpha\": 0.01\n",
        "}\n",
        "\n",
        "training_params = [\"noise_std\", \"batch_size\", \"lr\", \"epochs\",\"ext_lr\", \"decay1\", \"decay2\", \"anneal_per_epoch\",\n",
        "                   \"anneal_per_batch\", \"fine_tune_wait\", \"early_stop_wait\",\"temperature_wait\", \"T_boost\"]\n",
        "model_params = {k: v for k, v in params_RRAM.items() if k not in training_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
      "metadata": {
        "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
      "metadata": {
        "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
        "outputId": "6c26cc20-8fef-47b7-9441-4d1681d4495f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Bits Flipped : tensor(146.1207)\n",
            "Batchwise Acceptance tensor(4.2484e-18)\n",
            "Epochwise Acceptance tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Bits Flipped :\", 64*64*torch.exp(torch.tensor(-1.0, device=device) / model_RRAM.temperature_1))\n",
        "print(\"Batchwise Acceptance\", torch.exp(torch.tensor(-(10) / model_RRAM.temperature_2, device=device)))\n",
        "print(\"Epochwise Acceptance\", torch.exp(torch.tensor(-(100) / model_RRAM.temperature_2, device=device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241d1155-be9e-4a7a-9a74-a1d608188350",
      "metadata": {
        "id": "241d1155-be9e-4a7a-9a74-a1d608188350"
      },
      "source": [
        "## Training:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792",
      "metadata": {
        "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792"
      },
      "source": [
        "### Training to a subset of Dataset First\n",
        "\n",
        "This is just to see if the model is backpropagating before putting in into the full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "efd13def-9751-4e0e-89bf-666a98444d02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd13def-9751-4e0e-89bf-666a98444d02",
        "outputId": "df372244-1af7-414c-bc2d-2f7622d1fa8f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LR: 4.0000, Train Loss: 2.3071, Train Accuracy: 7.20%, Temperatures:(0.15, 0.12)\n",
            "Epoch 2, LR: 20.0000, Train Loss: 2.2959, Train Accuracy: 11.50%, Temperatures:(0.07, 0.06)\n",
            "Epoch 3, LR: 100.0000, Train Loss: 2.3245, Train Accuracy: 6.70%, Temperatures:(0.04, 0.03)\n",
            "Epoch 4, LR: 100.0000, Train Loss: 2.3012, Train Accuracy: 12.30%, Temperatures:(0.02, 0.02)\n",
            "Epoch 5, LR: 100.0000, Train Loss: 2.4981, Train Accuracy: 8.30%, Temperatures:(0.01, 0.01)\n",
            "Epoch 6, LR: 100.0000, Train Loss: 2.2988, Train Accuracy: 12.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 7, LR: 100.0000, Train Loss: 2.3315, Train Accuracy: 12.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 8, LR: 100.0000, Train Loss: 2.2846, Train Accuracy: 12.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 9, LR: 100.0000, Train Loss: 2.2703, Train Accuracy: 15.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 10, LR: 100.0000, Train Loss: 2.2546, Train Accuracy: 14.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 11, LR: 100.0000, Train Loss: 2.3156, Train Accuracy: 14.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 12, LR: 100.0000, Train Loss: 2.2466, Train Accuracy: 23.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 13, LR: 100.0000, Train Loss: 2.2570, Train Accuracy: 14.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 14, LR: 100.0000, Train Loss: 2.2240, Train Accuracy: 16.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 15, LR: 100.0000, Train Loss: 2.2198, Train Accuracy: 16.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 16, LR: 100.0000, Train Loss: 2.2115, Train Accuracy: 16.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 17, LR: 100.0000, Train Loss: 2.2127, Train Accuracy: 18.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 18, LR: 100.0000, Train Loss: 2.1692, Train Accuracy: 20.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 19, LR: 100.0000, Train Loss: 2.1912, Train Accuracy: 25.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 20, LR: 100.0000, Train Loss: 2.1454, Train Accuracy: 30.90%, Temperatures:(0.00, 0.00)\n",
            "Epoch 21, LR: 100.0000, Train Loss: 2.0965, Train Accuracy: 26.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 22, LR: 100.0000, Train Loss: 2.0905, Train Accuracy: 29.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 23, LR: 100.0000, Train Loss: 2.0776, Train Accuracy: 28.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 24, LR: 100.0000, Train Loss: 2.0619, Train Accuracy: 28.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 25, LR: 100.0000, Train Loss: 2.0434, Train Accuracy: 33.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 26, LR: 100.0000, Train Loss: 2.0271, Train Accuracy: 30.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 27, LR: 100.0000, Train Loss: 2.0115, Train Accuracy: 36.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 28, LR: 100.0000, Train Loss: 2.0766, Train Accuracy: 30.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 29, LR: 100.0000, Train Loss: 1.9853, Train Accuracy: 30.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 30, LR: 100.0000, Train Loss: 1.9739, Train Accuracy: 36.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 31, LR: 100.0000, Train Loss: 1.9549, Train Accuracy: 32.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 32, LR: 100.0000, Train Loss: 1.9641, Train Accuracy: 30.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 33, LR: 100.0000, Train Loss: 1.9388, Train Accuracy: 36.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 34, LR: 100.0000, Train Loss: 1.9450, Train Accuracy: 34.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 35, LR: 100.0000, Train Loss: 1.9319, Train Accuracy: 38.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 36, LR: 100.0000, Train Loss: 1.9297, Train Accuracy: 37.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 37, LR: 100.0000, Train Loss: 1.9024, Train Accuracy: 38.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 38, LR: 100.0000, Train Loss: 1.8995, Train Accuracy: 37.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 39, LR: 100.0000, Train Loss: 1.9186, Train Accuracy: 33.80%, Temperatures:(0.00, 0.00)\n",
            "Epoch 40, LR: 100.0000, Train Loss: 1.9011, Train Accuracy: 40.10%, Temperatures:(0.00, 0.00)\n",
            "Epoch 41, LR: 100.0000, Train Loss: 1.8943, Train Accuracy: 34.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 42, LR: 100.0000, Train Loss: 1.8886, Train Accuracy: 39.50%, Temperatures:(0.00, 0.00)\n",
            "Epoch 43, LR: 100.0000, Train Loss: 1.8894, Train Accuracy: 35.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 44, LR: 100.0000, Train Loss: 1.8848, Train Accuracy: 39.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 45, LR: 100.0000, Train Loss: 1.8765, Train Accuracy: 38.40%, Temperatures:(0.00, 0.00)\n",
            "Epoch 46, LR: 100.0000, Train Loss: 1.8878, Train Accuracy: 39.70%, Temperatures:(0.00, 0.00)\n",
            "Epoch 47, LR: 100.0000, Train Loss: 1.8841, Train Accuracy: 38.00%, Temperatures:(0.00, 0.00)\n",
            "Epoch 48, LR: 100.0000, Train Loss: 1.8853, Train Accuracy: 37.60%, Temperatures:(0.00, 0.00)\n",
            "Epoch 49, LR: 100.0000, Train Loss: 1.8830, Train Accuracy: 35.30%, Temperatures:(0.00, 0.00)\n",
            "Epoch 50, LR: 100.0000, Train Loss: 1.8871, Train Accuracy: 39.20%, Temperatures:(0.00, 0.00)\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "lr = params_RRAM[\"ext_lr\"] / 25  # Initial learning rate\n",
        "num_epochs = 50\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 1:\n",
        "        lr *= 5\n",
        "    elif epoch == 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train()\n",
        "    outputs = model_RRAM(train_in)\n",
        "    loss = criterion(outputs, train_lab)\n",
        "    loss.backward()\n",
        "    model_RRAM.backprop(lr)\n",
        "    model_RRAM.anneal(train_in, train_lab,0.5, 0.5)\n",
        "\n",
        "    _, train_preds = torch.max(outputs, dim=1)\n",
        "    train_accuracy = (train_preds == train_lab).float().mean().item() * 100\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {loss.item():.4f}, \"\n",
        "          f\"Train Accuracy: {train_accuracy:.2f}%, Temperatures:({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if epoch % 50 == 0 and epoch != 0:\n",
        "        lr /= 2\n",
        "\n",
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614",
      "metadata": {
        "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614"
      },
      "source": [
        "### Loading Past Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
        "outputId": "af597e57-260a-4683-cbb6-0ddc2431db49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Validation Loss: 1.760358\n",
            "\n",
            " Parameters for Best Loss Model: {'scaling': 2, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 1.2, 'R_INV': 2500.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 100, 'epochs': 1000, 'temperature_1': 0.3, 'temperature_2': 0.25, 'monitor_annealing': False, 'decay1': 0.999, 'decay2': 0.1, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 1, 'alpha': 0.01}\n",
            "\n",
            " Best Validation Accuracy: 45.35\n",
            "\n",
            " Parameters for Best Accuracy Model: {'scaling': 2, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 1.2, 'R_INV': 2500.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 100, 'epochs': 1000, 'temperature_1': 0.3, 'temperature_2': 0.25, 'monitor_annealing': False, 'decay1': 0.999, 'decay2': 0.1, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 1, 'alpha': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-09f9da36490d>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
            "<ipython-input-20-09f9da36490d>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Load best validation loss model\n",
        "    with open(\"Best_Val_Loss.txt\", 'r') as f:\n",
        "        global_best_val_loss = float(f.read())\n",
        "    with open(\"Best_Params_Loss.txt\", 'r') as f:\n",
        "        params_best_loss = ast.literal_eval(f.read())\n",
        "\n",
        "    model_best_loss = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
        "\n",
        "    print(\"\\n Best Validation Loss:\", global_best_val_loss)\n",
        "    print(\"\\n Parameters for Best Loss Model:\", params_best_loss)\n",
        "\n",
        "    checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
        "    model_best_loss.load_state_dict(checkpoint_loss)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best loss model:\", e)\n",
        "    global_best_val_loss = float('inf')\n",
        "    print(\"No Saved Model for Best Loss\")\n",
        "\n",
        "try:\n",
        "    # Load best validation accuracy model\n",
        "    with open(\"Best_Val_Acc.txt\", 'r') as f:\n",
        "        global_best_val_acc = float(f.read())\n",
        "    with open(\"Best_Params_Acc.txt\", 'r') as f:\n",
        "        params_best_acc = ast.literal_eval(f.read())\n",
        "\n",
        "    model_best_acc = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
        "\n",
        "    print(\"\\n Best Validation Accuracy:\", global_best_val_acc)\n",
        "    print(\"\\n Parameters for Best Accuracy Model:\", params_best_acc)\n",
        "\n",
        "    checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n",
        "    model_best_acc.load_state_dict(checkpoint_acc)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best accuracy model:\", e)\n",
        "    global_best_val_acc = 0.0\n",
        "    print(\"No Saved Model for Best Accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "786757d6-3ef8-4327-900a-94924d5a1b57",
      "metadata": {
        "id": "786757d6-3ef8-4327-900a-94924d5a1b57"
      },
      "outputs": [],
      "source": [
        "history_RRAM = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_accuracy\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_accuracy\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013",
      "metadata": {
        "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013"
      },
      "source": [
        "### Complete Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
        "outputId": "17ba97a1-4f89-414a-da07-ecc46e02133b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LR: 4.0000, Train Loss: 2.2611, Train Acc: 14.47%, Val Loss: 2.2495, Val Acc: 20.71%, Temperatures: (0.28, 0.00)\n",
            "Epoch 2, LR: 20.0000, Train Loss: 2.2143, Train Acc: 15.96%, Val Loss: 2.1114, Val Acc: 16.90%, Temperatures: (0.27, 0.00)\n",
            "Epoch 3, LR: 100.0000, Train Loss: 2.1036, Train Acc: 20.75%, Val Loss: 1.9473, Val Acc: 35.48%, Temperatures: (0.25, 0.00)\n",
            "Epoch 4, LR: 100.0000, Train Loss: 1.8759, Train Acc: 36.62%, Val Loss: 1.8160, Val Acc: 44.08%, Temperatures: (0.24, 0.00)\n",
            "Epoch 5, LR: 100.0000, Train Loss: 1.7968, Train Acc: 44.96%, Val Loss: 1.7517, Val Acc: 49.61%, Temperatures: (0.22, 0.00)\n",
            "Model saved with best validation loss: 1.751723\n",
            "Model saved with best validation accuracy: 49.610000\n"
          ]
        }
      ],
      "source": [
        "lr = params_RRAM[\"ext_lr\"] / 25\n",
        "num_epochs = params_RRAM[\"epochs\"]\n",
        "patience_stop, patience_lr, patience_T = params_RRAM[\"early_stop_wait\"], params_RRAM[\"fine_tune_wait\"], params_RRAM[\"temperature_wait\"]\n",
        "wait_lr, wait_stop = 0, 0\n",
        "cur_best_val_loss, cur_best_val_acc = float('inf'), 0\n",
        "temp_boosted = False\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 0:\n",
        "        lr = lr\n",
        "    elif epoch <= 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train().to(device)\n",
        "    train_loss, train_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model_RRAM(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        model_RRAM.backprop(lr)\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        if params_RRAM[\"anneal_per_batch\"]:\n",
        "            model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    train_loss /= total_samples\n",
        "    train_accuracy = 100 * train_correct / total_samples\n",
        "\n",
        "    model_RRAM.eval()\n",
        "    val_loss, val_correct, total_test_samples = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_RRAM(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_test_samples += inputs.size(0)\n",
        "\n",
        "    val_loss /= total_test_samples\n",
        "    val_accuracy = 100 * val_correct / total_test_samples\n",
        "\n",
        "    history_RRAM[\"train_loss\"].append(train_loss)\n",
        "    history_RRAM[\"train_accuracy\"].append(train_accuracy)\n",
        "    history_RRAM[\"val_loss\"].append(val_loss)\n",
        "    history_RRAM[\"val_accuracy\"].append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Temperatures: ({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if val_loss < global_best_val_loss:\n",
        "        global_best_val_loss = val_loss\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_loss.pth\")\n",
        "        with open(\"Best_Val_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_loss:.6f}\")\n",
        "        with open(\"Best_Params_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation loss: {val_loss:.6f}\")\n",
        "\n",
        "    if val_accuracy > global_best_val_acc:\n",
        "        global_best_val_acc = val_accuracy\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_acc.pth\")\n",
        "        with open(\"Best_Val_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_accuracy:.6f}\")\n",
        "        with open(\"Best_Params_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation accuracy: {val_accuracy:.6f}\")\n",
        "\n",
        "    if params_RRAM[\"anneal_per_epoch\"]:\n",
        "        model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    if wait_lr >= patience_lr and epoch > 3:\n",
        "        lr /= 5\n",
        "        wait_lr = 0\n",
        "        print(f\"No improvement for {patience_lr} epochs. Reducing LR to {lr:.4f}\")\n",
        "\n",
        "    if wait_lr >= patience_T and not temp_boosted:\n",
        "        model_RRAM.temperature_2 *= params_RRAM[\"T_boost\"]\n",
        "        temp_boosted = True\n",
        "        print(f\"Training plateau detected. Temporarily increasing temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "    if val_loss < cur_best_val_loss - 0.001 or val_accuracy > cur_best_val_acc + 0.1:\n",
        "        if temp_boosted:\n",
        "            model_RRAM.temperature_2 /= params_RRAM[\"T_boost\"]\n",
        "            temp_boosted = False\n",
        "            print(f\"Training improved. Restoring temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "        cur_best_val_loss = min(cur_best_val_loss, val_loss)\n",
        "        cur_best_val_acc = max(cur_best_val_acc, val_accuracy)\n",
        "        wait_stop = 0\n",
        "        wait_lr = 0\n",
        "    else:\n",
        "        wait_stop += 1\n",
        "        wait_lr += 1\n",
        "\n",
        "    if wait_stop >= patience_stop and epoch > 6:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b",
      "metadata": {
        "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b"
      },
      "outputs": [],
      "source": [
        "plot_history(history_RRAM, num_epochs, \"RRAM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d430e62-7d42-4210-8696-64d49d843f91",
      "metadata": {
        "id": "3d430e62-7d42-4210-8696-64d49d843f91"
      },
      "outputs": [],
      "source": [
        "# model_RRAM.load_state_dict(model_best_acc.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69",
      "metadata": {
        "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb",
      "metadata": {
        "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb"
      },
      "source": [
        "### Current Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51271c7c-25b1-4702-9db1-9ae4b805843c",
      "metadata": {
        "id": "51271c7c-25b1-4702-9db1-9ae4b805843c"
      },
      "outputs": [],
      "source": [
        "print(0 + (model_RRAM.w > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d477c9e-5678-4d07-a5ac-48f01480c916",
      "metadata": {
        "id": "9d477c9e-5678-4d07-a5ac-48f01480c916"
      },
      "outputs": [],
      "source": [
        "cm = test(model_RRAM, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7941df-4678-4955-8a0f-f38b43f6b197",
      "metadata": {
        "id": "ed7941df-4678-4955-8a0f-f38b43f6b197"
      },
      "source": [
        "## Best Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867574d7-3627-49ff-a430-1d658fa4d655",
      "metadata": {
        "id": "867574d7-3627-49ff-a430-1d658fa4d655"
      },
      "outputs": [],
      "source": [
        "0+1*(model_best.w>0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78",
      "metadata": {
        "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78"
      },
      "outputs": [],
      "source": [
        "cm = test(model_best, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce",
      "metadata": {
        "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce"
      },
      "source": [
        "## PWL Generation\n",
        "\n",
        "Let's assume that we will program the two crossbars with seperate PWLs. That is, during programming, we will cut the Inverting Amplifier stages with a pass transistor and connect the programming lines with a pass transistor. First array has 16 Top PWLs and 8 Bottom PWLs. Second array has 8 Top PWLs and 4 Bottom PWLs. And then once the programming switch is toggled to inference mode, only the 16 Top PWLs are to be changed. Let's also generate a PWL for that too.\n",
        "\n",
        "In the code below, we will first maintain tuples for each PWL that holds what the voltage should be. And then we will write a function that will take there and space pulses of the given voltage that are 100us apart from other and have an ON duration of 100us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64",
      "metadata": {
        "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [list() for i in range(16)]\n",
        "BL_FC1 = [list() for i in range(8)]\n",
        "WL_FC2 = [list() for i in range(8)]\n",
        "BL_FC2 = [list() for i in range(4)]\n",
        "Mode = []\n",
        "Mode_B = []\n",
        "\n",
        "V_WRITE = 1.5\n",
        "V_READ = 0.1\n",
        "V_mode = 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c647afda-e1a7-47a7-b634-212ec5527be2",
      "metadata": {
        "id": "c647afda-e1a7-47a7-b634-212ec5527be2"
      },
      "source": [
        "#### Fully Connected Weights 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03334172-89f6-4d73-9461-6ac922bdb6ea",
      "metadata": {
        "id": "03334172-89f6-4d73-9461-6ac922bdb6ea"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w1>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49287afe-8437-40aa-8825-93f2cffe3a66",
      "metadata": {
        "id": "49287afe-8437-40aa-8825-93f2cffe3a66"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC1[ind_j].append(V_WRITE)\n",
        "        else: WL_FC1[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC1[ind_i].append(0)\n",
        "        else: BL_FC1[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be77131c-005d-4f06-8a70-f40d267eb67e",
      "metadata": {
        "id": "be77131c-005d-4f06-8a70-f40d267eb67e"
      },
      "source": [
        "#### Fully Connected Weights 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d",
      "metadata": {
        "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w2>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79",
      "metadata": {
        "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC2[ind_j].append(V_WRITE)\n",
        "        else: WL_FC2[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC2[ind_i].append(0)\n",
        "        else: BL_FC2[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a602368f-07a2-4beb-90e3-d782ca717fea",
      "metadata": {
        "id": "a602368f-07a2-4beb-90e3-d782ca717fea"
      },
      "source": [
        "#### Filling Out Programming Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11",
      "metadata": {
        "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [i + [0,0] for i in WL_FC1]\n",
        "BL_FC1 = [i + [0,0] for i in BL_FC1]\n",
        "while(len(WL_FC2[0]) < len(WL_FC1[0])):\n",
        "    WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "    BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "Mode.extend([V_mode]*(len(WL_FC1[0])-1) + [-V_mode])\n",
        "Mode_B.extend([-V_mode]*(len(WL_FC1[0])-1) + [V_mode])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f953198a-a107-428c-9624-3c712086e922",
      "metadata": {
        "id": "f953198a-a107-428c-9624-3c712086e922"
      },
      "outputs": [],
      "source": [
        "print(WL_FC1[0])\n",
        "print(BL_FC1[0])\n",
        "print(WL_FC2[0])\n",
        "print(BL_FC2[0])\n",
        "print(Mode)\n",
        "print(Mode_B)\n",
        "print(len(WL_FC1[0]), len(BL_FC1[0]), len(WL_FC2[0]), len(BL_FC2[0]), len(Mode), len(Mode_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92339f84-e8d6-4280-92af-e5215aa129a0",
      "metadata": {
        "id": "92339f84-e8d6-4280-92af-e5215aa129a0"
      },
      "source": [
        "### Inference: Loading the Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58",
      "metadata": {
        "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58"
      },
      "outputs": [],
      "source": [
        "val_inputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248",
      "metadata": {
        "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248"
      },
      "outputs": [],
      "source": [
        "V_1 = 0.1\n",
        "V_0 = -0.1\n",
        "include_testing = True\n",
        "include_every = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73",
      "metadata": {
        "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73"
      },
      "outputs": [],
      "source": [
        "if include_testing:\n",
        "    for i in val_inputs[::include_every]:\n",
        "        i = i.flatten()\n",
        "        for ind, j in enumerate(i):\n",
        "            WL_FC1[ind].append(V_1 if j==1 else V_0)\n",
        "        BL_FC1 = [i + [0,] for i in BL_FC1]\n",
        "        WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "        BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "        Mode = Mode + [-V_mode,]\n",
        "        Mode_B = Mode_B + [V_mode,]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c",
      "metadata": {
        "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c"
      },
      "source": [
        "### PWL Convertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98af5ff-8f34-4472-89fc-e308d98d4072",
      "metadata": {
        "id": "c98af5ff-8f34-4472-89fc-e308d98d4072"
      },
      "outputs": [],
      "source": [
        "def pwl(l):\n",
        "    t = 0\n",
        "    res = \"pwl(time, 0us, 0V\"\n",
        "    for i in l:\n",
        "        res += f\", {t+5}us, {i:.2f}V, {t+100}us, {i:.2f}V, {t+105}us, 0V, {t+200}us, 0V\"\n",
        "        t+=200\n",
        "    res += \")\"\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54850dbc-1317-44a2-9093-c5a4e048094c",
      "metadata": {
        "id": "54850dbc-1317-44a2-9093-c5a4e048094c"
      },
      "outputs": [],
      "source": [
        "pwl_data = []\n",
        "\n",
        "for ind, i in enumerate(WL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(WL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "pwl_data.append({\"Signal\": \"Mode\", \"Index\": \"\", \"PWL\": pwl(Mode)})\n",
        "pwl_data.append({\"Signal\": \"Mode_b\", \"Index\": \"\", \"PWL\": pwl(Mode_B)})\n",
        "\n",
        "pwl_data = pd.DataFrame(pwl_data)\n",
        "pwl_data.to_csv(\"pwl_data.csv\", index=False)\n",
        "pwl_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174",
      "metadata": {
        "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174"
      },
      "source": [
        "#### Testing Accuracy on 160 Images\n",
        "ADS isn't allowing PWLs longer than 160 Images, so let's check software accuracy for the same too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e",
      "metadata": {
        "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, val_inputs[::4], val_labels[::4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f",
      "metadata": {
        "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, train_inputs, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1079074f-8781-43af-b52e-fb3581ef8931",
      "metadata": {
        "id": "1079074f-8781-43af-b52e-fb3581ef8931"
      },
      "source": [
        "## Simulation Data from ADS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d523a2-f99f-46bb-93e0-fead2768da75",
      "metadata": {
        "id": "e0d523a2-f99f-46bb-93e0-fead2768da75"
      },
      "outputs": [],
      "source": [
        "simu = pd.read_csv(\"Testing_160_Images.csv\")\n",
        "simu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd96e845-0c19-470b-8910-6b45df78022c",
      "metadata": {
        "id": "fd96e845-0c19-470b-8910-6b45df78022c"
      },
      "outputs": [],
      "source": [
        "def remove_units(value):\n",
        "    return float(value.replace('E', 'e').split('V')[0].replace('sec', ''))\n",
        "\n",
        "simu['time'] = simu['time'].apply(remove_units)\n",
        "for col in ['A', 'X', 'V', 'T']:\n",
        "    simu[col] = simu[col].apply(remove_units)\n",
        "simu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223576d6-266c-49bd-aaca-ff3444617f09",
      "metadata": {
        "id": "223576d6-266c-49bd-aaca-ff3444617f09"
      },
      "source": [
        "We just need one sample every 0.1ms samples of these starting from 2.050ms to 33.850ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3",
      "metadata": {
        "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3"
      },
      "outputs": [],
      "source": [
        "t_stamps = np.arange(2.05e-3, 33.9e-3, 0.2e-3)\n",
        "t_stamps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700",
      "metadata": {
        "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700"
      },
      "outputs": [],
      "source": [
        "sampled = []\n",
        "window = 0.02e-3\n",
        "\n",
        "for t in t_stamps:\n",
        "    filtered = simu[(simu['time'] >= t - window) & (simu['time'] <= t + window)]\n",
        "\n",
        "    avg_A = filtered['A'].mean()\n",
        "    avg_X = filtered['X'].mean()\n",
        "    avg_V = filtered['V'].mean()\n",
        "    avg_T = filtered['T'].mean()\n",
        "\n",
        "    sampled.append({\n",
        "        'Image Index': t,\n",
        "        'A': avg_A,\n",
        "        'X': avg_X,\n",
        "        'V': avg_V,\n",
        "        'T': avg_T\n",
        "    })\n",
        "\n",
        "sampled = pd.DataFrame(sampled)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e",
      "metadata": {
        "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e"
      },
      "outputs": [],
      "source": [
        "def get_max_column(row):\n",
        "    return row[['A', 'X', 'V', 'T']].idxmax()\n",
        "sampled['Predicted Class'] = sampled.apply(get_max_column, axis=1)\n",
        "sampled.to_csv(\"Sampled_Results.csv\", index=False)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1143c06-5631-4c79-9965-0cb937929706",
      "metadata": {
        "id": "d1143c06-5631-4c79-9965-0cb937929706"
      },
      "outputs": [],
      "source": [
        "ground_truth = ['A']*40 + ['X']*40 + ['V']*40 + ['T']*40\n",
        "correct_predictions = sampled['Predicted Class'] == ground_truth\n",
        "accuracy = correct_predictions.sum() / len(ground_truth)\n",
        "print(accuracy*100,end=\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918b4552-b0d3-4768-bfe7-9b874959d42c",
      "metadata": {
        "id": "918b4552-b0d3-4768-bfe7-9b874959d42c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 3.5))\n",
        "\n",
        "plt.scatter(sampled.index, sampled['A'], color='red', label='A_pred', s=30, marker='o')  # Red dots for A\n",
        "plt.scatter(sampled.index, sampled['X'], color='blue', label='X_pred', s=30, marker='o')  # Blue dots for X\n",
        "plt.scatter(sampled.index, sampled['T'], color='green', label='T_pred', s=30, marker='o')  # Green dots for T\n",
        "plt.scatter(sampled.index, sampled['V'], color='orange', label='V_pred', s=30, marker='o')  # Orange dots for V\n",
        "\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Predicted Voltages (V)')\n",
        "plt.legend()\n",
        "\n",
        "plt.axvline(x=40, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=80, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=120, color='gray', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.text(20, plt.ylim()[1]*(-0.8), 'A', fontsize=15, color='black', ha='center')\n",
        "plt.text(60, plt.ylim()[1]*0.8, 'X', fontsize=15, color='black', ha='center')\n",
        "plt.text(100, plt.ylim()[1]*0.8, 'V', fontsize=15, color='black', ha='center')\n",
        "plt.text(140, plt.ylim()[1]*(-0.8), 'T', fontsize=15, color='black', ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8",
      "metadata": {
        "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}