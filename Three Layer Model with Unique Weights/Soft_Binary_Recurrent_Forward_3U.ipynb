{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87",
      "metadata": {
        "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87"
      },
      "source": [
        "# Soft Binary Neural Network with Recurrent Crossbar Recycling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508058d8-e23a-4c29-aad7-c2b233d621c9",
      "metadata": {
        "id": "508058d8-e23a-4c29-aad7-c2b233d621c9"
      },
      "source": [
        "## Imports and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f",
      "metadata": {
        "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d406d54c-db27-4536-a8c1-f46437f6fb71",
      "metadata": {
        "id": "d406d54c-db27-4536-a8c1-f46437f6fb71"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, num_epochs, element):\n",
        "    epochs = range(len(history[list(history.keys())[0]]))\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
        "    ax1.plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
        "    ax1.set_xlabel(\"Epochs\", fontsize=14)\n",
        "    ax1.set_ylabel(\"Loss\", fontsize=14, color=\"blue\")\n",
        "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
        "    ax1.legend(loc=\"upper left\")\n",
        "    ax1.grid(True)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(epochs, history[\"train_accuracy\"], label=\"Train Accuracy\", color=\"green\")\n",
        "    ax2.plot(epochs, history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"orange\")\n",
        "    ax2.set_ylabel(\"Accuracy (%)\", fontsize=14, color=\"green\")\n",
        "    ax2.tick_params(axis=\"y\", labelcolor=\"green\")\n",
        "    ax2.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.title(f\"Training and Validation Metrics for {element}\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c658023-75df-4754-a617-a8ba6d08d068",
      "metadata": {
        "id": "7c658023-75df-4754-a617-a8ba6d08d068"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, class_names=None):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e",
      "metadata": {
        "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e"
      },
      "source": [
        "### MNIST Handwritten Digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d3bbad17-7067-4f06-8755-012646ca9567",
      "metadata": {
        "id": "d3bbad17-7067-4f06-8755-012646ca9567"
      },
      "outputs": [],
      "source": [
        "class BinarizeAndAddNoiseTransform:\n",
        "    def __init__(self, threshold_max, threshold_min, noise_std):\n",
        "        self.threshold_max = threshold_max\n",
        "        self.threshold_min = threshold_min\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = transforms.ToTensor()(img).to(device)\n",
        "        thresh = torch.rand(1, device=device) * (self.threshold_max - self.threshold_min) + self.threshold_min\n",
        "        img = (img > thresh).float()\n",
        "        img = img[:,4:-4, 4:-4]\n",
        "        noise = torch.randn(img.size(), device=device) * self.noise_std\n",
        "        noisy_img = img + noise\n",
        "        return noisy_img\n",
        "\n",
        "binary_noise_transform = transforms.Compose([\n",
        "    BinarizeAndAddNoiseTransform(0.45, 0.5, 0.05)\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=binary_noise_transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=10000, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=binary_noise_transform)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd",
      "metadata": {
        "id": "bc40653e-ebac-4013-9ecb-27dfe1370edd"
      },
      "outputs": [],
      "source": [
        "# Get a subset of the dataset\n",
        "train_in, train_lab = next(iter(train_loader))\n",
        "val_in, val_lab = next(iter(test_loader))\n",
        "\n",
        "# Move data to the appropriate device\n",
        "train_in, train_lab = train_in.to(device), train_lab.to(device)\n",
        "val_in, val_lab = val_in.to(device), val_lab.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "d76599e3-3d87-4d1d-bd5f-41ca0adab18f",
        "outputId": "43660cd7-a976-4be5-b6d3-1c3725389b90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(15, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(train_in[i].cpu().squeeze(), cmap='gray')\n",
        "    ax.set_title(f\"Label: {train_lab[i].item()}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "train_in.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a",
      "metadata": {
        "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a"
      },
      "source": [
        "## Custom Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a",
      "metadata": {
        "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def tensor_stats(tensor, name=\"Tensor\"):\n",
        "    tensor = tensor.to(device)\n",
        "    mean_magnitude = tensor.abs().mean().item()\n",
        "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
        "    def __init__(self, scaling, G_ON, G_OFF, V_INV, R_INV, V_1, V_0, zeta, initial_factor, crossbar=(64,64),\n",
        "                 input_size=400, encoding_size=3, output_size=10, data_in=40, bin_active=True,\n",
        "                 monitor_volts=False, monitor_grads=True, monitor_latents=False, dropout=0.01, alpha = 0.9,\n",
        "                 int_lr=0.01, int_norm=True, temperature_1 = 0.4, temperature_2 = 30,monitor_annealing=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w = nn.Parameter(initial_factor * torch.empty(crossbar, device=device))\n",
        "        nn.init.xavier_uniform_(self.w)\n",
        "        self.w.date = self.w.data * initial_factor\n",
        "\n",
        "        self.G_ON, self.G_OFF = torch.tensor(G_ON, device=device)*scaling, torch.tensor(G_OFF, device=device)*scaling\n",
        "        self.V_INV, self.R_INV = torch.tensor(V_INV, device=device), torch.tensor(R_INV, device=device)\n",
        "        self.V_1, self.V_0 = torch.tensor(V_1, device=device), torch.tensor(V_0, device=device)\n",
        "\n",
        "        self.crossbar_in, self.crossbar_out = crossbar\n",
        "        self.encoding, self.data_in, self.output_size = encoding_size, data_in, output_size\n",
        "        self.r_passes = input_size // data_in\n",
        "        self.second_size = self.crossbar_out - self.encoding*self.r_passes\n",
        "        self.out1size = self.encoding * self.r_passes\n",
        "\n",
        "        self.first_bias = (crossbar[0] - data_in) % encoding_size\n",
        "        self.second_bias = (crossbar[0])%(self.r_passes*encoding_size)\n",
        "        self.final_bias = (crossbar[0])%(self.second_size)\n",
        "\n",
        "        self.feed_repeats = (crossbar[0] - data_in)//encoding_size\n",
        "        self.second_repeats = (crossbar[0])//(self.r_passes*encoding_size)\n",
        "        self.final_repeats = (crossbar[0])//(self.second_size)\n",
        "\n",
        "        self.zeta, self.int_lr = torch.tensor(zeta, device=device), torch.tensor(int_lr, device=device)\n",
        "        self.bin_active, self.int_norm = bin_active, int_norm\n",
        "        self.monitor_volts, self.monitor_grads, self.monitor_latents = monitor_volts, monitor_grads, monitor_latents\n",
        "        self.monitor_annealing = monitor_annealing\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.temperature_1 = temperature_1\n",
        "        self.temperature_2 = temperature_2\n",
        "        self.device = device\n",
        "\n",
        "        self.velocity = torch.zeros(crossbar, device = device)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def INV_AMP(self, x, R_INV):\n",
        "        return -self.V_INV * torch.tanh(R_INV * x / self.V_INV)\n",
        "\n",
        "    def SOFT_BIN(self, x):\n",
        "        if self.bin_active: return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
        "        else: return self.G_ON * x * self.zeta * 0.4\n",
        "\n",
        "    def PREPROCESS(self, img):\n",
        "        return (self.V_1 - self.V_0) * img.to(device) + self.V_0\n",
        "\n",
        "    def ANNEALER(self):\n",
        "        prob = torch.exp(torch.tensor(-1.0, device=self.device) / self.temperature_1)\n",
        "        prob = torch.clamp(prob, min=1e-3, max=1)\n",
        "\n",
        "        rand_vals = torch.rand((64, 64), device=self.device)\n",
        "        annealed_mask = torch.where(rand_vals < prob, -1, torch.where(rand_vals < 2 * prob, 0, 1))\n",
        "\n",
        "        return annealed_mask\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
        "        img = self.PREPROCESS(img.view(img.size(0), -1))\n",
        "        bias = self.PREPROCESS(((-1) ** torch.arange(self.first_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias2 = self.PREPROCESS(((-1) ** torch.arange(self.second_bias, device=device)).repeat(img.shape[0], 1))\n",
        "        bias3 = self.PREPROCESS(((-1) ** torch.arange(self.final_bias, device=device)).repeat(img.shape[0], 1))\n",
        "\n",
        "        # RRAM Soft Binarization\n",
        "        g = self.SOFT_BIN(self.w)\n",
        "        if self.monitor_latents: tensor_stats(self.w, \"Latent Weights:\")\n",
        "\n",
        "        # Recurrent Encoding Layer\n",
        "        feedback = torch.zeros((img.shape[0], self.encoding*self.feed_repeats), device=device)\n",
        "        out1 = torch.zeros((img.shape[0], self.out1size), device = device)\n",
        "\n",
        "        for r_pass in range(self.r_passes):\n",
        "            ind_s, ind_f = self.crossbar_out - (r_pass+1)*self.encoding, self.crossbar_out - (r_pass)*self.encoding\n",
        "            ind_a, ind_b = self.out1size - (r_pass+1)*self.encoding, self.out1size - (r_pass)*self.encoding\n",
        "\n",
        "            x = torch.cat((feedback, bias, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
        "            x = F.linear(x, g[ind_s:ind_f, : ], bias=None)\n",
        "\n",
        "            out1[:, ind_a:ind_b] = self.INV_AMP(x, self.R_INV)\n",
        "            if self.monitor_volts: tensor_stats(feedback, f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
        "\n",
        "            feedback = out1[:, ind_a:ind_b].repeat(1,self.feed_repeats)\n",
        "\n",
        "        # Feature Extraction layer\n",
        "        ind_p, ind_q = self.output_size, self.output_size + self.second_size\n",
        "        x = torch.cat((bias2, out1.repeat(1,self.second_repeats)), dim = 1)\n",
        "\n",
        "        x = F.linear(x, g[ind_p:ind_q, :], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Voltages after Second Layer\")\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Classification Layer\n",
        "        x = torch.cat((bias3, x.repeat(1,self.final_repeats)), dim = 1)\n",
        "        x = F.linear(x, g[:self.output_size, : ], bias=None)\n",
        "        x = self.INV_AMP(x, self.R_INV)\n",
        "        if self.monitor_volts: tensor_stats(x, f\"Last Layer\")\n",
        "\n",
        "        return x\n",
        "\n",
        "    def backprop(self, ext_lr):\n",
        "        with torch.no_grad():\n",
        "            if self.w.grad is not None:\n",
        "                grad = self.w.grad.detach().to(device)\n",
        "                for i in range(grad.shape[0]):\n",
        "                    if self.int_norm:\n",
        "                        grad[i] = self.int_lr * grad[i] / (torch.norm(grad[i]) + 1e-20)\n",
        "                    grad[i] = grad[i]\n",
        "                grad = grad + self.alpha*self.velocity\n",
        "                if self.monitor_grads: tensor_stats(ext_lr*grad, \"Gradients\")\n",
        "                self.w -= grad * ext_lr\n",
        "                self.velocity = grad\n",
        "                self.w.grad.zero_()\n",
        "\n",
        "    def anneal(self, inputs, labels, decay1, decay2):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.forward(inputs)\n",
        "            old_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "            old_w = self.w.data.clone()\n",
        "\n",
        "            self.w.data = self.w.data * self.ANNEALER()\n",
        "            outputs = self.forward(inputs)\n",
        "            new_loss = criterion(outputs, labels).item() * inputs.size(0)\n",
        "\n",
        "            acceptance_prob = torch.exp(torch.tensor(-(new_loss - old_loss) / self.temperature_2, device=self.device))\n",
        "            if self.monitor_annealing: print(\"Old & New Losses\", old_loss, new_loss,\"Probab:\", acceptance_prob)\n",
        "            if new_loss < old_loss or torch.rand(1, device=self.device) < acceptance_prob:\n",
        "                if self.monitor_annealing: print(\"Annealed weights accepted\")\n",
        "            else:\n",
        "                self.w.data = old_w\n",
        "            if self.temperature_1 > 0.001: self.temperature_1 *= decay1\n",
        "            if self.temperature_2 > 0.001: self.temperature_2 *= decay2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845d51da-8368-4c97-89a2-9fc1374f408b",
      "metadata": {
        "id": "845d51da-8368-4c97-89a2-9fc1374f408b"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00",
      "metadata": {
        "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00"
      },
      "outputs": [],
      "source": [
        "params_RRAM = {\n",
        "    \"scaling\": 1,\n",
        "    \"G_ON\": 6e-5,\n",
        "    \"G_OFF\": 2.88e-6,\n",
        "    \"V_INV\": 0.8,\n",
        "    \"R_INV\": 2000.0,\n",
        "    \"V_1\": 0.1,\n",
        "    \"V_0\": -0.1,\n",
        "    \"zeta\": 10.0,\n",
        "    \"initial_factor\": 0.01,\n",
        "    \"crossbar\": (64, 64),\n",
        "    \"input_size\": 400,\n",
        "    \"encoding_size\": 3,\n",
        "    \"output_size\": 10,\n",
        "    \"data_in\": 40,\n",
        "    \"bin_active\": True,\n",
        "    \"monitor_volts\": False,\n",
        "    \"monitor_grads\": False,\n",
        "    \"monitor_latents\": False,\n",
        "    \"dropout\": 0.05,\n",
        "    \"int_lr\": 0.01,\n",
        "    \"int_norm\": True,\n",
        "    \"ext_lr\": 100,\n",
        "    \"epochs\": 1000,\n",
        "    \"temperature_1\": 0.2,\n",
        "    \"temperature_2\": 0.1,\n",
        "    \"monitor_annealing\": False,\n",
        "    \"decay1\" : 0.99,\n",
        "    \"decay2\" : 0.9,\n",
        "    \"anneal_per_epoch\" : False,\n",
        "    \"anneal_per_batch\" : True,\n",
        "    \"early_stop_wait\": 21,\n",
        "    \"fine_tune_wait\": 7,\n",
        "    \"temperature_wait\": 3,\n",
        "    \"T_boost\": 1,\n",
        "    \"alpha\": 0.01\n",
        "}\n",
        "\n",
        "training_params = [\"noise_std\", \"batch_size\", \"lr\", \"epochs\",\"ext_lr\", \"decay1\", \"decay2\", \"anneal_per_epoch\",\n",
        "                   \"anneal_per_batch\", \"fine_tune_wait\", \"early_stop_wait\",\"temperature_wait\", \"T_boost\"]\n",
        "model_params = {k: v for k, v in params_RRAM.items() if k not in training_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
      "metadata": {
        "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97dcb81c-7778-45d3-87ee-e6669632d2a0",
        "outputId": "3e284381-fc79-4e87-bb65-169517ce01ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Bits Flipped : tensor(27.5986, device='cuda:0')\n",
            "Batchwise Acceptance tensor(3.7835e-44, device='cuda:0')\n",
            "Epochwise Acceptance tensor(0., device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Bits Flipped :\", 64*64*torch.exp(torch.tensor(-1.0, device=device) / model_RRAM.temperature_1))\n",
        "print(\"Batchwise Acceptance\", torch.exp(torch.tensor(-(10) / model_RRAM.temperature_2, device=device)))\n",
        "print(\"Epochwise Acceptance\", torch.exp(torch.tensor(-(100) / model_RRAM.temperature_2, device=device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241d1155-be9e-4a7a-9a74-a1d608188350",
      "metadata": {
        "id": "241d1155-be9e-4a7a-9a74-a1d608188350"
      },
      "source": [
        "## Training:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792",
      "metadata": {
        "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792"
      },
      "source": [
        "### Training to a subset of Dataset First\n",
        "\n",
        "This is just to see if the model is backpropagating before putting in into the full training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "efd13def-9751-4e0e-89bf-666a98444d02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd13def-9751-4e0e-89bf-666a98444d02",
        "outputId": "174150af-b944-4909-f5ac-8486f9a9f945",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, LR: 4.0000, Train Loss: 2.3047, Train Accuracy: 10.11%, Temperatures:(0.10, 0.05)\n",
            "Epoch 2, LR: 20.0000, Train Loss: 2.3022, Train Accuracy: 9.98%, Temperatures:(0.05, 0.03)\n",
            "Epoch 3, LR: 100.0000, Train Loss: 2.2954, Train Accuracy: 10.12%, Temperatures:(0.03, 0.01)\n",
            "Epoch 4, LR: 100.0000, Train Loss: 2.3048, Train Accuracy: 10.68%, Temperatures:(0.01, 0.01)\n",
            "Epoch 5, LR: 100.0000, Train Loss: 2.2982, Train Accuracy: 10.87%, Temperatures:(0.01, 0.00)\n",
            "Epoch 6, LR: 100.0000, Train Loss: 2.2407, Train Accuracy: 19.78%, Temperatures:(0.00, 0.00)\n",
            "Epoch 7, LR: 100.0000, Train Loss: 2.2188, Train Accuracy: 15.86%, Temperatures:(0.00, 0.00)\n",
            "Epoch 8, LR: 100.0000, Train Loss: 2.1903, Train Accuracy: 31.55%, Temperatures:(0.00, 0.00)\n",
            "Epoch 9, LR: 100.0000, Train Loss: 2.1545, Train Accuracy: 19.12%, Temperatures:(0.00, 0.00)\n",
            "Epoch 10, LR: 100.0000, Train Loss: 2.1462, Train Accuracy: 30.87%, Temperatures:(0.00, 0.00)\n",
            "Epoch 11, LR: 100.0000, Train Loss: 2.1283, Train Accuracy: 25.88%, Temperatures:(0.00, 0.00)\n",
            "Epoch 12, LR: 100.0000, Train Loss: 2.1218, Train Accuracy: 32.34%, Temperatures:(0.00, 0.00)\n",
            "Epoch 13, LR: 100.0000, Train Loss: 2.1087, Train Accuracy: 22.47%, Temperatures:(0.00, 0.00)\n",
            "Epoch 14, LR: 100.0000, Train Loss: 2.1021, Train Accuracy: 23.49%, Temperatures:(0.00, 0.00)\n",
            "Epoch 15, LR: 100.0000, Train Loss: 2.0967, Train Accuracy: 25.53%, Temperatures:(0.00, 0.00)\n",
            "Epoch 16, LR: 100.0000, Train Loss: 2.0793, Train Accuracy: 23.54%, Temperatures:(0.00, 0.00)\n",
            "Epoch 17, LR: 100.0000, Train Loss: 2.0671, Train Accuracy: 29.32%, Temperatures:(0.00, 0.00)\n",
            "Epoch 18, LR: 100.0000, Train Loss: 2.0561, Train Accuracy: 26.67%, Temperatures:(0.00, 0.00)\n",
            "Epoch 19, LR: 100.0000, Train Loss: 2.0533, Train Accuracy: 19.14%, Temperatures:(0.00, 0.00)\n",
            "Epoch 20, LR: 100.0000, Train Loss: 2.0453, Train Accuracy: 24.97%, Temperatures:(0.00, 0.00)\n",
            "Epoch 21, LR: 100.0000, Train Loss: 2.0393, Train Accuracy: 27.89%, Temperatures:(0.00, 0.00)\n",
            "Epoch 22, LR: 100.0000, Train Loss: 2.0339, Train Accuracy: 28.46%, Temperatures:(0.00, 0.00)\n",
            "Epoch 23, LR: 100.0000, Train Loss: 2.0308, Train Accuracy: 26.62%, Temperatures:(0.00, 0.00)\n",
            "Epoch 24, LR: 100.0000, Train Loss: 2.0275, Train Accuracy: 27.21%, Temperatures:(0.00, 0.00)\n",
            "Epoch 25, LR: 100.0000, Train Loss: 2.0261, Train Accuracy: 25.81%, Temperatures:(0.00, 0.00)\n",
            "Epoch 26, LR: 100.0000, Train Loss: 2.0234, Train Accuracy: 27.41%, Temperatures:(0.00, 0.00)\n",
            "Epoch 27, LR: 100.0000, Train Loss: 2.0212, Train Accuracy: 26.50%, Temperatures:(0.00, 0.00)\n",
            "Epoch 28, LR: 100.0000, Train Loss: 2.0198, Train Accuracy: 28.23%, Temperatures:(0.00, 0.00)\n",
            "Epoch 29, LR: 100.0000, Train Loss: 2.0191, Train Accuracy: 26.94%, Temperatures:(0.00, 0.00)\n",
            "Epoch 30, LR: 100.0000, Train Loss: 2.0176, Train Accuracy: 28.55%, Temperatures:(0.00, 0.00)\n",
            "Epoch 31, LR: 100.0000, Train Loss: 2.0168, Train Accuracy: 27.56%, Temperatures:(0.00, 0.00)\n",
            "Epoch 32, LR: 100.0000, Train Loss: 2.0151, Train Accuracy: 28.58%, Temperatures:(0.00, 0.00)\n",
            "Epoch 33, LR: 100.0000, Train Loss: 2.0146, Train Accuracy: 28.05%, Temperatures:(0.00, 0.00)\n",
            "Epoch 34, LR: 100.0000, Train Loss: 2.0145, Train Accuracy: 29.20%, Temperatures:(0.00, 0.00)\n",
            "Epoch 35, LR: 100.0000, Train Loss: 2.0124, Train Accuracy: 26.74%, Temperatures:(0.00, 0.00)\n",
            "Epoch 36, LR: 100.0000, Train Loss: 2.0128, Train Accuracy: 30.29%, Temperatures:(0.00, 0.00)\n",
            "Epoch 37, LR: 100.0000, Train Loss: 2.0112, Train Accuracy: 29.74%, Temperatures:(0.00, 0.00)\n",
            "Epoch 38, LR: 100.0000, Train Loss: 2.0110, Train Accuracy: 30.11%, Temperatures:(0.00, 0.00)\n",
            "Epoch 39, LR: 100.0000, Train Loss: 2.0093, Train Accuracy: 30.13%, Temperatures:(0.00, 0.00)\n",
            "Epoch 40, LR: 100.0000, Train Loss: 2.0125, Train Accuracy: 32.86%, Temperatures:(0.00, 0.00)\n",
            "Epoch 41, LR: 100.0000, Train Loss: 2.0088, Train Accuracy: 29.77%, Temperatures:(0.00, 0.00)\n",
            "Epoch 42, LR: 100.0000, Train Loss: 2.0143, Train Accuracy: 32.62%, Temperatures:(0.00, 0.00)\n",
            "Epoch 43, LR: 100.0000, Train Loss: 2.0076, Train Accuracy: 30.55%, Temperatures:(0.00, 0.00)\n",
            "Epoch 44, LR: 100.0000, Train Loss: 2.0112, Train Accuracy: 32.17%, Temperatures:(0.00, 0.00)\n",
            "Epoch 45, LR: 100.0000, Train Loss: 2.0077, Train Accuracy: 32.38%, Temperatures:(0.00, 0.00)\n",
            "Epoch 46, LR: 100.0000, Train Loss: 2.0086, Train Accuracy: 33.35%, Temperatures:(0.00, 0.00)\n",
            "Epoch 47, LR: 100.0000, Train Loss: 2.0060, Train Accuracy: 32.45%, Temperatures:(0.00, 0.00)\n",
            "Epoch 48, LR: 100.0000, Train Loss: 2.0054, Train Accuracy: 33.03%, Temperatures:(0.00, 0.00)\n",
            "Epoch 49, LR: 100.0000, Train Loss: 2.0069, Train Accuracy: 31.39%, Temperatures:(0.00, 0.00)\n",
            "Epoch 50, LR: 100.0000, Train Loss: 2.0081, Train Accuracy: 33.24%, Temperatures:(0.00, 0.00)\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "lr = params_RRAM[\"ext_lr\"] / 25  # Initial learning rate\n",
        "num_epochs = 50\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 1:\n",
        "        lr *= 5\n",
        "    elif epoch == 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train()\n",
        "    outputs = model_RRAM(train_in)\n",
        "    loss = criterion(outputs, train_lab)\n",
        "    loss.backward()\n",
        "    model_RRAM.backprop(lr)\n",
        "    model_RRAM.anneal(train_in, train_lab,0.5, 0.5)\n",
        "\n",
        "    _, train_preds = torch.max(outputs, dim=1)\n",
        "    train_accuracy = (train_preds == train_lab).float().mean().item() * 100\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {loss.item():.4f}, \"\n",
        "          f\"Train Accuracy: {train_accuracy:.2f}%, Temperatures:({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if epoch % 50 == 0 and epoch != 0:\n",
        "        lr /= 2\n",
        "\n",
        "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614",
      "metadata": {
        "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614"
      },
      "source": [
        "### Loading Past Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
        "outputId": "8ce52309-8580-48d0-ecd3-960a9e5344fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Validation Loss: 2.01677\n",
            "\n",
            " Parameters for Best Loss Model: {'scaling': 1, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 0.8, 'R_INV': 2000.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 100, 'epochs': 1000, 'temperature_1': 0.2, 'temperature_2': 0.1, 'monitor_annealing': False, 'decay1': 0.99, 'decay2': 0.9, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 1, 'alpha': 0.01}\n",
            "\n",
            " Best Validation Accuracy: 37.65\n",
            "\n",
            " Parameters for Best Accuracy Model: {'scaling': 1, 'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 0.8, 'R_INV': 2000.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 10.0, 'initial_factor': 0.01, 'crossbar': (64, 64), 'input_size': 400, 'encoding_size': 3, 'output_size': 10, 'data_in': 40, 'bin_active': True, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.05, 'int_lr': 0.01, 'int_norm': True, 'ext_lr': 100, 'epochs': 1000, 'temperature_1': 0.2, 'temperature_2': 0.1, 'monitor_annealing': False, 'decay1': 0.99, 'decay2': 0.9, 'anneal_per_epoch': False, 'anneal_per_batch': True, 'early_stop_wait': 21, 'fine_tune_wait': 7, 'temperature_wait': 3, 'T_boost': 1, 'alpha': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-a2fc67dbe71f>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
            "<ipython-input-42-a2fc67dbe71f>:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Load best validation loss model\n",
        "    with open(\"Best_Val_Loss.txt\", 'r') as f:\n",
        "        global_best_val_loss = [float(f.read()),]\n",
        "    with open(\"Best_Params_Loss.txt\", 'r') as f:\n",
        "        params_best_loss = [ast.literal_eval(f.read()),]\n",
        "\n",
        "    model_best_loss = [SoftBinaryRecurrentForwardNetwork(**model_params).to(device),]\n",
        "\n",
        "    print(\"\\n Best Validation Loss:\", global_best_val_loss[0])\n",
        "    print(\"\\n Parameters for Best Loss Model:\", params_best_loss[0])\n",
        "\n",
        "    checkpoint_loss = torch.load(\"Best_model_loss.pth\")\n",
        "    model_best_loss[0].load_state_dict(checkpoint_loss)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best loss model:\", e)\n",
        "    global_best_val_loss = [float('inf'),]\n",
        "    params_best_loss = [None,]\n",
        "    model_best_loss = [None,]\n",
        "    print(\"No Saved Model for Best Loss\")\n",
        "\n",
        "try:\n",
        "    # Load best validation accuracy model\n",
        "    with open(\"Best_Val_Acc.txt\", 'r') as f:\n",
        "        global_best_val_acc = [float(f.read()),]\n",
        "    with open(\"Best_Params_Acc.txt\", 'r') as f:\n",
        "        params_best_acc = [ast.literal_eval(f.read()),]\n",
        "\n",
        "    model_best_acc = [SoftBinaryRecurrentForwardNetwork(**model_params).to(device),]\n",
        "\n",
        "    print(\"\\n Best Validation Accuracy:\", global_best_val_acc[0])\n",
        "    print(\"\\n Parameters for Best Accuracy Model:\", params_best_acc[0])\n",
        "\n",
        "    checkpoint_acc = torch.load(\"Best_model_acc.pth\")\n",
        "    model_best_acc[0].load_state_dict(checkpoint_acc)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading best accuracy model:\", e)\n",
        "    global_best_val_loss = [0.0,]\n",
        "    params_best_loss = [None,]\n",
        "    model_best_loss = [None,]\n",
        "    print(\"No Saved Model for Best Accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "786757d6-3ef8-4327-900a-94924d5a1b57",
      "metadata": {
        "id": "786757d6-3ef8-4327-900a-94924d5a1b57"
      },
      "outputs": [],
      "source": [
        "history_RRAM = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_accuracy\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_accuracy\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013",
      "metadata": {
        "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013"
      },
      "source": [
        "### Complete Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
        "outputId": "6aba0453-274c-4995-f50a-d781d0eda46a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-047ef483c232>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_RRAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr = params_RRAM[\"ext_lr\"] / 25\n",
        "num_epochs = params_RRAM[\"epochs\"]\n",
        "patience_stop, patience_lr, patience_T = params_RRAM[\"early_stop_wait\"], params_RRAM[\"fine_tune_wait\"], params_RRAM[\"temperature_wait\"]\n",
        "wait_lr, wait_stop = 0, 0\n",
        "cur_best_val_loss, cur_best_val_acc = float('inf'), 0\n",
        "temp_boosted = False\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if epoch == 0:\n",
        "        lr = lr\n",
        "    elif epoch <= 2:\n",
        "        lr *= 5\n",
        "\n",
        "    model_RRAM.train().to(device)\n",
        "    train_loss, train_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model_RRAM(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        model_RRAM.backprop(lr)\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        if params_RRAM[\"anneal_per_batch\"]:\n",
        "            model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    train_loss /= total_samples\n",
        "    train_accuracy = 100 * train_correct / total_samples\n",
        "\n",
        "    model_RRAM.eval()\n",
        "    val_loss, val_correct, total_test_samples = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model_RRAM(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total_test_samples += inputs.size(0)\n",
        "\n",
        "    val_loss /= total_test_samples\n",
        "    val_accuracy = 100 * val_correct / total_test_samples\n",
        "\n",
        "    history_RRAM[\"train_loss\"].append(train_loss)\n",
        "    history_RRAM[\"train_accuracy\"].append(train_accuracy)\n",
        "    history_RRAM[\"val_loss\"].append(val_loss)\n",
        "    history_RRAM[\"val_accuracy\"].append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, Temperatures: ({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\")\n",
        "\n",
        "    if val_loss < global_best_val_loss[0]:\n",
        "        global_best_val_loss[0] = val_loss\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_loss.pth\")\n",
        "        with open(\"Best_Val_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_loss:.6f}\")\n",
        "        with open(\"Best_Params_Loss.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation loss: {val_loss:.6f}\")\n",
        "\n",
        "    if val_accuracy > global_best_val_acc[0]:\n",
        "        global_best_val_acc[0] = val_accuracy\n",
        "        torch.save(model_RRAM.state_dict(), \"Best_model_acc.pth\")\n",
        "        with open(\"Best_Val_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{val_accuracy:.6f}\")\n",
        "        with open(\"Best_Params_Acc.txt\", \"w\") as f:\n",
        "            f.write(f\"{params_RRAM}\")\n",
        "        print(f\"Model saved with best validation accuracy: {val_accuracy:.6f}\")\n",
        "\n",
        "    if params_RRAM[\"anneal_per_epoch\"]:\n",
        "        model_RRAM.anneal(inputs, labels, params_RRAM[\"decay1\"], params_RRAM[\"decay2\"])\n",
        "\n",
        "    if wait_lr >= patience_lr and epoch > 3:\n",
        "        lr /= 5\n",
        "        wait_lr = 0\n",
        "        print(f\"No improvement for {patience_lr} epochs. Reducing LR to {lr:.4f}\")\n",
        "\n",
        "    if wait_lr >= patience_T and not temp_boosted:\n",
        "        model_RRAM.temperature_2 *= params_RRAM[\"T_boost\"]\n",
        "        temp_boosted = True\n",
        "        print(f\"Training plateau detected. Temporarily increasing temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "    if val_loss < cur_best_val_loss - 0.001 or val_accuracy > cur_best_val_acc + 0.1:\n",
        "        if temp_boosted:\n",
        "            model_RRAM.temperature_2 /= params_RRAM[\"T_boost\"]\n",
        "            temp_boosted = False\n",
        "            print(f\"Training improved. Restoring temperature_2 to {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "        cur_best_val_loss = min(cur_best_val_loss, val_loss)\n",
        "        cur_best_val_acc = max(cur_best_val_acc, val_accuracy)\n",
        "        wait_stop = 0\n",
        "        wait_lr = 0\n",
        "    else:\n",
        "        wait_stop += 1\n",
        "        wait_lr += 1\n",
        "\n",
        "    if wait_stop >= patience_stop and epoch > 6:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b",
      "metadata": {
        "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b"
      },
      "outputs": [],
      "source": [
        "plot_history(history_RRAM, num_epochs, \"RRAM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated Hyperparameter Sweep"
      ],
      "metadata": {
        "id": "PcaD0nrGr-vP"
      },
      "id": "PcaD0nrGr-vP"
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key = \"8400044425ce1250223591fdf24be129b1a45849\", relogin=True)"
      ],
      "metadata": {
        "id": "AGScM7BgSMjA"
      },
      "id": "AGScM7BgSMjA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3d430e62-7d42-4210-8696-64d49d843f91",
      "metadata": {
        "id": "3d430e62-7d42-4210-8696-64d49d843f91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3486a529-35d0-4dab-d33d-872666d52f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "# train() takes no argument for hyperparameters per se, its given inside with wandb.config\n",
        "def train(train_loader,test_loader,device,criterion,global_best_val_acc,\n",
        "    global_best_val_loss,params_best_acc,params_best_loss,model_best_acc,model_best_loss,\n",
        "    project_name=\"Soft_Binary_Recurrent_Forward_3U\"):\n",
        "\n",
        "    try:\n",
        "        wandb.init(project=project_name, reinit=True)\n",
        "        params_RRAM = dict(wandb.config)\n",
        "\n",
        "        training_params = [\"noise_std\", \"batch_size\", \"lr\", \"epochs\", \"ext_lr\", \"decay1\", \"decay2\",\n",
        "            \"anneal_per_epoch\", \"anneal_per_batch\", \"fine_tune_wait\", \"early_stop_wait\",\n",
        "            \"temperature_wait\", \"T_boost\"]\n",
        "        model_params = {k: v for k, v in params_RRAM.items() if k not in training_params}\n",
        "        model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
        "\n",
        "        cur_best_val_loss,cur_best_val_acc = float('inf'), 0.0\n",
        "        patience_stop, patience_lr, patience_t = params_RRAM.get(\"early_stop_wait\", 20), params_RRAM.get(\"fine_tune_wait\", 10), params_RRAM.get(\"temperature_wait\", 5)\n",
        "        wait_stop, wait_lr, temp_boosted = 0,0,False\n",
        "\n",
        "        lr = params_RRAM[\"ext_lr\"] / 25 if \"ext_lr\" in params_RRAM else 0.01\n",
        "        num_epochs = params_RRAM.get(\"epochs\", 100)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch == 0:\n",
        "                pass\n",
        "            elif epoch <= 2:\n",
        "                lr *= 5\n",
        "\n",
        "            model_RRAM.train()\n",
        "            train_loss, train_correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model_RRAM(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                model_RRAM.backprop(lr)\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "                train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                total_samples += inputs.size(0)\n",
        "                if params_RRAM.get(\"anneal_per_batch\", False):\n",
        "                    model_RRAM.anneal(\n",
        "                        inputs,\n",
        "                        labels,\n",
        "                        params_RRAM.get(\"decay1\", 0.99),\n",
        "                        params_RRAM.get(\"decay2\", 0.9)\n",
        "                    )\n",
        "\n",
        "            train_loss /= total_samples\n",
        "            train_accuracy = 100.0 * train_correct / total_samples\n",
        "            model_RRAM.eval()\n",
        "            val_loss, val_correct, total_test_samples = 0.0, 0, 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in test_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model_RRAM(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                    total_test_samples += inputs.size(0)\n",
        "\n",
        "            val_loss /= total_test_samples\n",
        "            val_accuracy = 100.0 * val_correct / total_test_samples\n",
        "\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}/{num_epochs}, LR={lr:.4f}, \"\n",
        "                f\"Train Loss={train_loss:.4f}, Train Acc={train_accuracy:.2f}%, \"\n",
        "                f\"Val Loss={val_loss:.4f}, Val Acc={val_accuracy:.2f}%, \"\n",
        "                f\"Temps=({model_RRAM.temperature_1:.2f}, {model_RRAM.temperature_2:.2f})\"\n",
        "            )\n",
        "\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch+1,\n",
        "                \"train_loss\": train_loss,\n",
        "                \"train_accuracy\": train_accuracy,\n",
        "                \"val_loss\": val_loss,\n",
        "                \"val_accuracy\": val_accuracy,\n",
        "                \"cur_best_loss\": cur_best_val_loss,\n",
        "                \"cur_best_acc\": cur_best_val_acc,\n",
        "                \"lr\": lr\n",
        "            })\n",
        "\n",
        "            if val_loss < global_best_val_loss[0]:\n",
        "                global_best_val_loss[0] = val_loss\n",
        "                torch.save(model_RRAM.state_dict(), \"Best_model_loss.pth\")\n",
        "                with open(\"Best_Val_Loss.txt\", \"w\") as f:\n",
        "                    f.write(f\"{val_loss:.6f}\")\n",
        "                with open(\"Best_Params_Loss.txt\", \"w\") as f:\n",
        "                    f.write(str(params_RRAM))\n",
        "                print(f\"New best val loss: {val_loss:.6f}, model saved.\")\n",
        "\n",
        "            if val_accuracy > global_best_val_acc[0]:\n",
        "                global_best_val_acc[0] = val_accuracy\n",
        "                torch.save(model_RRAM.state_dict(), \"Best_model_acc.pth\")\n",
        "                with open(\"Best_Val_Acc.txt\", \"w\") as f:\n",
        "                    f.write(f\"{val_accuracy:.6f}\")\n",
        "                with open(\"Best_Params_Acc.txt\", \"w\") as f:\n",
        "                    f.write(str(params_RRAM))\n",
        "                print(f\"New best val accuracy: {val_accuracy:.6f}, model saved.\")\n",
        "\n",
        "            if params_RRAM.get(\"anneal_per_epoch\", False):\n",
        "                model_RRAM.anneal(\n",
        "                    inputs,\n",
        "                    labels,\n",
        "                    params_RRAM.get(\"decay1\", 0.99),\n",
        "                    params_RRAM.get(\"decay2\", 0.9)\n",
        "                )\n",
        "\n",
        "            if (val_loss < cur_best_val_loss - 0.001) or (val_accuracy > cur_best_val_acc + 0.1):\n",
        "                if temp_boosted:\n",
        "                    model_RRAM.temperature_2 /= params_RRAM.get(\"T_boost\", 1)\n",
        "                    temp_boosted = False\n",
        "                cur_best_val_loss = min(cur_best_val_loss, val_loss)\n",
        "                cur_best_val_acc = max(cur_best_val_acc, val_accuracy)\n",
        "                wait_stop = 0\n",
        "                wait_lr = 0\n",
        "            else:\n",
        "                wait_stop += 1\n",
        "                wait_lr += 1\n",
        "\n",
        "            if wait_lr >= patience_lr and epoch > 3:\n",
        "                lr /= 5\n",
        "                wait_lr = 0\n",
        "                print(f\"No improvement for {patience_lr} epochs. Lowering LR -> {lr:.4f}\")\n",
        "\n",
        "            if wait_lr >= patience_T and not temp_boosted:\n",
        "                model_RRAM.temperature_2 *= params_RRAM.get(\"T_boost\", 1)\n",
        "                temp_boosted = True\n",
        "                print(f\"Plateau -> boosting temperature_2 = {model_RRAM.temperature_2:.2f}\")\n",
        "\n",
        "            if wait_stop >= patience_stop and epoch > 6:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "        wandb.finish()\n",
        "    except Exception as e:\n",
        "        wandb.finish(exit_code=1)\n",
        "        raise e\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'name': 'RRAM_Sweep',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'scaling': {'values': [1,3]},\n",
        "        'G_ON': {'values': [6e-5]},\n",
        "        'G_OFF': {'values': [2.88e-6]},\n",
        "        'V_INV': {'values': [0.6, 1.65]},\n",
        "        'R_INV': {'values': [1000, 3000.0]},\n",
        "        'V_1': {'values': [0.1]},\n",
        "        'V_0': {'values': [-0.1]},\n",
        "        'zeta': {'values': [10.0, 100.0]},\n",
        "        'initial_factor': {'values': [0.01]},\n",
        "        'crossbar': {'values': [(64, 64)]},\n",
        "        'input_size': {'values': [400]},\n",
        "        'encoding_size': {'values': [3]},\n",
        "        'output_size': {'values': [10]},\n",
        "        'data_in': {'values': [40]},\n",
        "        'bin_active': {'values': [True]},\n",
        "        'monitor_volts': {'values': [False]},\n",
        "        'monitor_grads': {'values': [False]},\n",
        "        'monitor_latents': {'values': [False]},\n",
        "        'dropout': {'values': [0.05]},\n",
        "        'int_lr': {'values': [0.01]},\n",
        "        'int_norm': {'values': [True]},\n",
        "        'ext_lr': {'values': [500, 200, 80]},\n",
        "        'epochs': {'values': [1000]},\n",
        "        'temperature_1': {'values': [2, 0.2]},\n",
        "        'temperature_2': {'values': [1, 0.1]},\n",
        "        'monitor_annealing': {'values': [False]},\n",
        "        'decay1': {'values': [0.99]},\n",
        "        'decay2': {'values': [0.9]},\n",
        "        'anneal_per_epoch': {'values': [False]},\n",
        "        'anneal_per_batch': {'values': [True]},\n",
        "        'early_stop_wait': {'values': [9]},\n",
        "        'fine_tune_wait': {'values': [3]},\n",
        "        'temperature_wait': {'values': [6]},\n",
        "        'T_boost': {'values': [10]},\n",
        "        'alpha': {'values': [0.01, 0.1]}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "e4HWqIv9yPhW"
      },
      "id": "e4HWqIv9yPhW",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "# Give all other argument\n",
        "train_wrapper = partial(train, train_loader=train_loader, test_loader=test_loader, device=device,\n",
        "                        criterion=criterion, global_best_val_acc=global_best_val_acc,\n",
        "                        global_best_val_loss=global_best_val_loss, params_best_acc=params_best_acc,\n",
        "                        params_best_loss=params_best_loss, model_best_acc=model_best_acc,\n",
        "                        model_best_loss=model_best_loss)\n",
        "# manual_id = None\n",
        "manual_id = \"o87gqrfp\"\n",
        "sweep_id = manual_id if manual_id else wandb.sweep(sweep_config, project=\"Soft_Binary_Recurrent_Forward_3U\")\n",
        "print(f\"Sweep created with ID: {sweep_id}. Paste it in another agent to run parallely\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otPb0N3GyPrz",
        "outputId": "16342d32-4ad1-4bc4-d7f3-af0303b6a364"
      },
      "id": "otPb0N3GyPrz",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweep created with ID: o87gqrfp. Paste it in another agent to run parallely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, function=train_wrapper, count=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "ixQUYSlOOMjj",
        "outputId": "9e4dc355-72b9-4f7c-d0c8-66ce5280ba5e"
      },
      "id": "ixQUYSlOOMjj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8uuaulxw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tG_OFF: 2.88e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tG_ON: 6e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tR_INV: 1000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tT_boost: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tV_0: -0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tV_1: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tV_INV: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tanneal_per_batch: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tanneal_per_epoch: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbin_active: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcrossbar: [64, 64]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_in: 40\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay1: 0.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay2: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tearly_stop_wait: 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoding_size: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \text_lr: 500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfine_tune_wait: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_factor: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tint_lr: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tint_norm: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor_annealing: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor_grads: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor_latents: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmonitor_volts: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_size: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscaling: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemperature_1: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemperature_2: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemperature_wait: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tzeta: 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Soft_Binary_Recurrent_Forward_3U' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250204_140822-8uuaulxw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/runs/8uuaulxw' target=\"_blank\">glowing-sweep-3</a></strong> to <a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/sweeps/o87gqrfp' target=\"_blank\">https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/sweeps/o87gqrfp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U' target=\"_blank\">https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/sweeps/o87gqrfp' target=\"_blank\">https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/sweeps/o87gqrfp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/runs/8uuaulxw' target=\"_blank\">https://wandb.ai/rishi-n-afi/Soft_Binary_Recurrent_Forward_3U/runs/8uuaulxw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, LR=20.0000, Train Loss=2.2970, Train Acc=14.31%, Val Loss=2.2861, Val Acc=15.96%, Temps=(1.88, 0.05)\n",
            "Epoch 2/1000, LR=100.0000, Train Loss=2.2580, Train Acc=19.41%, Val Loss=2.2251, Val Acc=18.46%, Temps=(1.77, 0.03)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69",
      "metadata": {
        "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb",
      "metadata": {
        "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb"
      },
      "source": [
        "### Current Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51271c7c-25b1-4702-9db1-9ae4b805843c",
      "metadata": {
        "id": "51271c7c-25b1-4702-9db1-9ae4b805843c"
      },
      "outputs": [],
      "source": [
        "print(0 + (model_RRAM.w > 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d477c9e-5678-4d07-a5ac-48f01480c916",
      "metadata": {
        "id": "9d477c9e-5678-4d07-a5ac-48f01480c916"
      },
      "outputs": [],
      "source": [
        "cm = test(model_RRAM, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7941df-4678-4955-8a0f-f38b43f6b197",
      "metadata": {
        "id": "ed7941df-4678-4955-8a0f-f38b43f6b197"
      },
      "source": [
        "## Best Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867574d7-3627-49ff-a430-1d658fa4d655",
      "metadata": {
        "id": "867574d7-3627-49ff-a430-1d658fa4d655"
      },
      "outputs": [],
      "source": [
        "0+1*(model_best.w>0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78",
      "metadata": {
        "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78"
      },
      "outputs": [],
      "source": [
        "cm = test(model_best, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce",
      "metadata": {
        "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce"
      },
      "source": [
        "## PWL Generation\n",
        "\n",
        "Let's assume that we will program the two crossbars with seperate PWLs. That is, during programming, we will cut the Inverting Amplifier stages with a pass transistor and connect the programming lines with a pass transistor. First array has 16 Top PWLs and 8 Bottom PWLs. Second array has 8 Top PWLs and 4 Bottom PWLs. And then once the programming switch is toggled to inference mode, only the 16 Top PWLs are to be changed. Let's also generate a PWL for that too.\n",
        "\n",
        "In the code below, we will first maintain tuples for each PWL that holds what the voltage should be. And then we will write a function that will take there and space pulses of the given voltage that are 100us apart from other and have an ON duration of 100us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64",
      "metadata": {
        "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [list() for i in range(16)]\n",
        "BL_FC1 = [list() for i in range(8)]\n",
        "WL_FC2 = [list() for i in range(8)]\n",
        "BL_FC2 = [list() for i in range(4)]\n",
        "Mode = []\n",
        "Mode_B = []\n",
        "\n",
        "V_WRITE = 1.5\n",
        "V_READ = 0.1\n",
        "V_mode = 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c647afda-e1a7-47a7-b634-212ec5527be2",
      "metadata": {
        "id": "c647afda-e1a7-47a7-b634-212ec5527be2"
      },
      "source": [
        "#### Fully Connected Weights 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03334172-89f6-4d73-9461-6ac922bdb6ea",
      "metadata": {
        "id": "03334172-89f6-4d73-9461-6ac922bdb6ea"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w1>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49287afe-8437-40aa-8825-93f2cffe3a66",
      "metadata": {
        "id": "49287afe-8437-40aa-8825-93f2cffe3a66"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC1[ind_j].append(V_WRITE)\n",
        "        else: WL_FC1[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC1[ind_i].append(0)\n",
        "        else: BL_FC1[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be77131c-005d-4f06-8a70-f40d267eb67e",
      "metadata": {
        "id": "be77131c-005d-4f06-8a70-f40d267eb67e"
      },
      "source": [
        "#### Fully Connected Weights 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d",
      "metadata": {
        "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d"
      },
      "outputs": [],
      "source": [
        "target = (model_RRAM_best.w2>0).int()\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79",
      "metadata": {
        "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79"
      },
      "outputs": [],
      "source": [
        "for ind_i, i in enumerate(target):\n",
        "    for ind_j, j in enumerate(i):\n",
        "        if j==1: WL_FC2[ind_j].append(V_WRITE)\n",
        "        else: WL_FC2[ind_j].append(V_WRITE/3)\n",
        "    for ind_k in range(len(target)):\n",
        "        if ind_k==ind_i: BL_FC2[ind_i].append(0)\n",
        "        else: BL_FC2[ind_k].append(2*V_WRITE/3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a602368f-07a2-4beb-90e3-d782ca717fea",
      "metadata": {
        "id": "a602368f-07a2-4beb-90e3-d782ca717fea"
      },
      "source": [
        "#### Filling Out Programming Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11",
      "metadata": {
        "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11"
      },
      "outputs": [],
      "source": [
        "WL_FC1 = [i + [0,0] for i in WL_FC1]\n",
        "BL_FC1 = [i + [0,0] for i in BL_FC1]\n",
        "while(len(WL_FC2[0]) < len(WL_FC1[0])):\n",
        "    WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "    BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "Mode.extend([V_mode]*(len(WL_FC1[0])-1) + [-V_mode])\n",
        "Mode_B.extend([-V_mode]*(len(WL_FC1[0])-1) + [V_mode])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f953198a-a107-428c-9624-3c712086e922",
      "metadata": {
        "id": "f953198a-a107-428c-9624-3c712086e922"
      },
      "outputs": [],
      "source": [
        "print(WL_FC1[0])\n",
        "print(BL_FC1[0])\n",
        "print(WL_FC2[0])\n",
        "print(BL_FC2[0])\n",
        "print(Mode)\n",
        "print(Mode_B)\n",
        "print(len(WL_FC1[0]), len(BL_FC1[0]), len(WL_FC2[0]), len(BL_FC2[0]), len(Mode), len(Mode_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92339f84-e8d6-4280-92af-e5215aa129a0",
      "metadata": {
        "id": "92339f84-e8d6-4280-92af-e5215aa129a0"
      },
      "source": [
        "### Inference: Loading the Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58",
      "metadata": {
        "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58"
      },
      "outputs": [],
      "source": [
        "val_inputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248",
      "metadata": {
        "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248"
      },
      "outputs": [],
      "source": [
        "V_1 = 0.1\n",
        "V_0 = -0.1\n",
        "include_testing = True\n",
        "include_every = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73",
      "metadata": {
        "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73"
      },
      "outputs": [],
      "source": [
        "if include_testing:\n",
        "    for i in val_inputs[::include_every]:\n",
        "        i = i.flatten()\n",
        "        for ind, j in enumerate(i):\n",
        "            WL_FC1[ind].append(V_1 if j==1 else V_0)\n",
        "        BL_FC1 = [i + [0,] for i in BL_FC1]\n",
        "        WL_FC2 = [i + [0,] for i in WL_FC2]\n",
        "        BL_FC2 = [i + [0,] for i in BL_FC2]\n",
        "        Mode = Mode + [-V_mode,]\n",
        "        Mode_B = Mode_B + [V_mode,]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c",
      "metadata": {
        "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c"
      },
      "source": [
        "### PWL Convertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98af5ff-8f34-4472-89fc-e308d98d4072",
      "metadata": {
        "id": "c98af5ff-8f34-4472-89fc-e308d98d4072"
      },
      "outputs": [],
      "source": [
        "def pwl(l):\n",
        "    t = 0\n",
        "    res = \"pwl(time, 0us, 0V\"\n",
        "    for i in l:\n",
        "        res += f\", {t+5}us, {i:.2f}V, {t+100}us, {i:.2f}V, {t+105}us, 0V, {t+200}us, 0V\"\n",
        "        t+=200\n",
        "    res += \")\"\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54850dbc-1317-44a2-9093-c5a4e048094c",
      "metadata": {
        "id": "54850dbc-1317-44a2-9093-c5a4e048094c"
      },
      "outputs": [],
      "source": [
        "pwl_data = []\n",
        "\n",
        "for ind, i in enumerate(WL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC1):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(WL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"WL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "for ind, i in enumerate(BL_FC2):\n",
        "    pwl_data.append({\"Signal\": f\"BL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
        "pwl_data.append({\"Signal\": \"Mode\", \"Index\": \"\", \"PWL\": pwl(Mode)})\n",
        "pwl_data.append({\"Signal\": \"Mode_b\", \"Index\": \"\", \"PWL\": pwl(Mode_B)})\n",
        "\n",
        "pwl_data = pd.DataFrame(pwl_data)\n",
        "pwl_data.to_csv(\"pwl_data.csv\", index=False)\n",
        "pwl_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174",
      "metadata": {
        "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174"
      },
      "source": [
        "#### Testing Accuracy on 160 Images\n",
        "ADS isn't allowing PWLs longer than 160 Images, so let's check software accuracy for the same too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e",
      "metadata": {
        "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, val_inputs[::4], val_labels[::4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f",
      "metadata": {
        "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f"
      },
      "outputs": [],
      "source": [
        "test(model_RRAM_best, train_inputs, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1079074f-8781-43af-b52e-fb3581ef8931",
      "metadata": {
        "id": "1079074f-8781-43af-b52e-fb3581ef8931"
      },
      "source": [
        "## Simulation Data from ADS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d523a2-f99f-46bb-93e0-fead2768da75",
      "metadata": {
        "id": "e0d523a2-f99f-46bb-93e0-fead2768da75"
      },
      "outputs": [],
      "source": [
        "simu = pd.read_csv(\"Testing_160_Images.csv\")\n",
        "simu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd96e845-0c19-470b-8910-6b45df78022c",
      "metadata": {
        "id": "fd96e845-0c19-470b-8910-6b45df78022c"
      },
      "outputs": [],
      "source": [
        "def remove_units(value):\n",
        "    return float(value.replace('E', 'e').split('V')[0].replace('sec', ''))\n",
        "\n",
        "simu['time'] = simu['time'].apply(remove_units)\n",
        "for col in ['A', 'X', 'V', 'T']:\n",
        "    simu[col] = simu[col].apply(remove_units)\n",
        "simu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223576d6-266c-49bd-aaca-ff3444617f09",
      "metadata": {
        "id": "223576d6-266c-49bd-aaca-ff3444617f09"
      },
      "source": [
        "We just need one sample every 0.1ms samples of these starting from 2.050ms to 33.850ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3",
      "metadata": {
        "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3"
      },
      "outputs": [],
      "source": [
        "t_stamps = np.arange(2.05e-3, 33.9e-3, 0.2e-3)\n",
        "t_stamps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700",
      "metadata": {
        "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700"
      },
      "outputs": [],
      "source": [
        "sampled = []\n",
        "window = 0.02e-3\n",
        "\n",
        "for t in t_stamps:\n",
        "    filtered = simu[(simu['time'] >= t - window) & (simu['time'] <= t + window)]\n",
        "\n",
        "    avg_A = filtered['A'].mean()\n",
        "    avg_X = filtered['X'].mean()\n",
        "    avg_V = filtered['V'].mean()\n",
        "    avg_T = filtered['T'].mean()\n",
        "\n",
        "    sampled.append({\n",
        "        'Image Index': t,\n",
        "        'A': avg_A,\n",
        "        'X': avg_X,\n",
        "        'V': avg_V,\n",
        "        'T': avg_T\n",
        "    })\n",
        "\n",
        "sampled = pd.DataFrame(sampled)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e",
      "metadata": {
        "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e"
      },
      "outputs": [],
      "source": [
        "def get_max_column(row):\n",
        "    return row[['A', 'X', 'V', 'T']].idxmax()\n",
        "sampled['Predicted Class'] = sampled.apply(get_max_column, axis=1)\n",
        "sampled.to_csv(\"Sampled_Results.csv\", index=False)\n",
        "sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1143c06-5631-4c79-9965-0cb937929706",
      "metadata": {
        "id": "d1143c06-5631-4c79-9965-0cb937929706"
      },
      "outputs": [],
      "source": [
        "ground_truth = ['A']*40 + ['X']*40 + ['V']*40 + ['T']*40\n",
        "correct_predictions = sampled['Predicted Class'] == ground_truth\n",
        "accuracy = correct_predictions.sum() / len(ground_truth)\n",
        "print(accuracy*100,end=\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918b4552-b0d3-4768-bfe7-9b874959d42c",
      "metadata": {
        "id": "918b4552-b0d3-4768-bfe7-9b874959d42c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 3.5))\n",
        "\n",
        "plt.scatter(sampled.index, sampled['A'], color='red', label='A_pred', s=30, marker='o')  # Red dots for A\n",
        "plt.scatter(sampled.index, sampled['X'], color='blue', label='X_pred', s=30, marker='o')  # Blue dots for X\n",
        "plt.scatter(sampled.index, sampled['T'], color='green', label='T_pred', s=30, marker='o')  # Green dots for T\n",
        "plt.scatter(sampled.index, sampled['V'], color='orange', label='V_pred', s=30, marker='o')  # Orange dots for V\n",
        "\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Predicted Voltages (V)')\n",
        "plt.legend()\n",
        "\n",
        "plt.axvline(x=40, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=80, color='gray', linestyle='--', linewidth=2)\n",
        "plt.axvline(x=120, color='gray', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.text(20, plt.ylim()[1]*(-0.8), 'A', fontsize=15, color='black', ha='center')\n",
        "plt.text(60, plt.ylim()[1]*0.8, 'X', fontsize=15, color='black', ha='center')\n",
        "plt.text(100, plt.ylim()[1]*0.8, 'V', fontsize=15, color='black', ha='center')\n",
        "plt.text(140, plt.ylim()[1]*(-0.8), 'T', fontsize=15, color='black', ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8",
      "metadata": {
        "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}