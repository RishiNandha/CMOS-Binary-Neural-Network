{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87",
   "metadata": {},
   "source": [
    "# Soft Binary Neural Network with Recurrent Crossbar Recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508058d8-e23a-4c29-aad7-c2b233d621c9",
   "metadata": {},
   "source": [
    "## Imports and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torchinfo import summary\n",
    "import ast\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d406d54c-db27-4536-a8c1-f46437f6fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, num_epochs, element):\n",
    "    epochs = range(len(history[list(history.keys())[0]]))\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
    "    ax1.plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
    "    ax1.set_xlabel(\"Epochs\", fontsize=14)\n",
    "    ax1.set_ylabel(\"Loss\", fontsize=14, color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, history[\"train_accuracy\"], label=\"Train Accuracy\", color=\"green\")\n",
    "    ax2.plot(epochs, history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"orange\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\", fontsize=14, color=\"green\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"green\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.title(f\"Training and Validation Metrics for {element}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7c658023-75df-4754-a617-a8ba6d08d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, class_names=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = (total_correct / total_samples) * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e",
   "metadata": {},
   "source": [
    "### MNIST Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d3bbad17-7067-4f06-8755-012646ca9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeAndAddNoiseTransform:\n",
    "    def __init__(self, threshold=0.5, noise_std=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.ToTensor()(img).to(device)\n",
    "        img = (img > self.threshold).float()\n",
    "        noise = torch.randn(img.size(), device=device) * self.noise_std\n",
    "        noisy_img = img + noise\n",
    "        return noisy_img\n",
    "\n",
    "binary_noise_transform = transforms.Compose([\n",
    "    BinarizeAndAddNoiseTransform(threshold=0.5, noise_std=0.05)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=binary_noise_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=6000, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "999bc3b9-b0ba-43c1-906d-928bcd16b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a subset of the dataset\n",
    "train_in, train_lab = next(iter(train_loader))\n",
    "val_in, val_lab = next(iter(test_loader))\n",
    "\n",
    "# Move data to the appropriate device\n",
    "train_in, train_lab = train_in.to(device), train_lab.to(device)\n",
    "val_in, val_lab = val_in.to(device), val_lab.to(device)\n",
    "demo_ind = 1\n",
    "plt.imshow(train_in[demo_ind].cpu().squeeze(), cmap='gray')\n",
    "plt.title(f\"Label: {train_lab[demo_ind].item()}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a",
   "metadata": {},
   "source": [
    "## Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def tensor_stats(tensor, name=\"Tensor\"):\n",
    "    tensor = tensor.to(device)\n",
    "    mean_magnitude = tensor.abs().mean().item()\n",
    "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
    "\n",
    "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
    "    def __init__(self, G_ON, G_OFF, V_INV, R_INV_1, R_INV_2, V_1, V_0, zeta, initial_factor, monitor_latents = False,\n",
    "                 crossbar=(64,64), input_size=784, recurrence_size=32, output_size=10, int_norm=True, data_in = 28, \n",
    "                 bin_active=True, monitor_volts=False, monitor_grads =True, dropout=0.01, int_lr=100):\n",
    "        super(SoftBinaryRecurrentForwardNetwork, self).__init__()\n",
    "\n",
    "        # Crossbar Weights\n",
    "        self.w = nn.Parameter(torch.empty(crossbar, device=device))\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        self.w.data = initial_factor * self.w\n",
    "\n",
    "        # Circuit Parameters\n",
    "        self.G_ON = torch.tensor(G_ON, device=device)\n",
    "        self.G_OFF = torch.tensor(G_OFF, device=device)\n",
    "        self.V_INV = torch.tensor(V_INV, device=device)\n",
    "        self.R_INV_1 = torch.tensor(R_INV_1, device=device)\n",
    "        self.R_INV_2 = torch.tensor(R_INV_2, device=device) # Usually 3 or 4 times the first\n",
    "        self.V_1 = torch.tensor(V_1, device=device)\n",
    "        self.V_0 = torch.tensor(V_0, device=device)\n",
    "\n",
    "        # Architecture Parameters\n",
    "        self.crossbar_in = crossbar[0]\n",
    "        self.crossbar_out = crossbar[1]\n",
    "        \n",
    "        self.feedback = recurrence_size\n",
    "        self.data_in = data_in\n",
    "        self.first_bias = crossbar[0] - recurrence_size - data_in\n",
    "        self.r_passes = input_size // self.data_in\n",
    "        \n",
    "        self.second_layer = crossbar[1] - output_size - recurrence_size\n",
    "\n",
    "        self.final_bias = crossbar[0] - 2*self.second_layer\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Training Variables\n",
    "        self.zeta = torch.tensor(zeta, device=device)\n",
    "        self.monitor_volts = monitor_volts\n",
    "        self.monitor_grad = monitor_grads\n",
    "        self.monitor_latents = monitor_latents\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.int_lr = torch.tensor(int_lr, device=device)\n",
    "        self.int_norm = int_norm\n",
    "        self.bin_active = bin_active\n",
    "\n",
    "    def INV_AMP(self, x, R_INV):\n",
    "        return -self.V_INV * torch.tanh(R_INV * x / self.V_INV)\n",
    "\n",
    "    def SOFT_BIN(self, x):\n",
    "        if self.bin_active: return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
    "        else: return self.G_ON * x * self.zeta * 0.4\n",
    "\n",
    "    def PREPROCESS(self, img):\n",
    "        return (self.V_1 - self.V_0) * img.view(img.size(0), -1).to(device) + self.V_0\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
    "        img = self.PREPROCESS(img)\n",
    "\n",
    "        # RRAM Soft Binarization\n",
    "        g = self.SOFT_BIN(self.w)\n",
    "        if self.monitor_latents: tensor_stats(self.w, \"Latent Weights:\")\n",
    "\n",
    "        # Recurrent Encoding Layer\n",
    "        feedback = self.PREPROCESS(torch.zeros((img.shape[0], self.feedback), device=device))\n",
    "        bias = self.PREPROCESS(torch.ones((img.shape[0], self.first_bias), device=device))\n",
    "\n",
    "        for r_pass in range(self.r_passes):\n",
    "            x = torch.cat((feedback, bias, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
    "            x = F.linear(x, g[-self.feedback:, : ], bias=None)\n",
    "            x1 = self.INV_AMP(x, self.R_INV_1)\n",
    "            if self.monitor_volts: tensor_stats(x1, f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
    "            feedback = x1\n",
    "        \n",
    "        else:\n",
    "            x2 = self.INV_AMP(x, self.R_INV_2)\n",
    "            x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Feature Extraction Layer\n",
    "        x = F.linear(x, g[self.output_size : -self.feedback, : ], bias=None)\n",
    "        x1 = self.INV_AMP(x, self.R_INV_1)\n",
    "        x2 = self.INV_AMP(x, self.R_INV_2)\n",
    "        if self.monitor_volts: tensor_stats(x, f\"Voltages after h_layer {h_pass}\")\n",
    "        \n",
    "        bias2 = self.PREPROCESS(torch.ones((img.shape[0], self.final_bias), device=device))\n",
    "        x = torch.cat((bias2, x1, x2), dim=1)\n",
    "        \n",
    "        # Classification Layer\n",
    "        x = F.linear(x, g[ : self.output_size, : ], bias=None)\n",
    "        return x\n",
    "\n",
    "    def backprop(self, ext_lr):\n",
    "        with torch.no_grad():\n",
    "            if self.w.grad is not None:\n",
    "                grad = self.w.grad.to(device)\n",
    "                if self.int_norm:\n",
    "                    grad[-self.feedback:, :] = self.int_lr * grad[-self.feedback:, :] / (torch.norm(grad[-self.feedback:, :]) + 1e-20)\n",
    "                    grad[self.output_size:-self.feedback, :] = self.int_lr * grad[self.output_size:-self.feedback, :] / (torch.norm(grad[self.output_size:-self.feedback, :]) + 1e-20)\n",
    "                    grad[:self.output_size, :] = self.int_lr * grad[:self.output_size, :] / (torch.norm(grad[:self.output_size, :]) + 1e-20)\n",
    "                gred = ext_lr * grad\n",
    "                if self.monitor_grads:\n",
    "                    tensor_stats(grad[-self.feedback:, :], \"Layer 1 Gradients\")\n",
    "                    tensor_stats(grad[self.output_size:-self.feedback, :], \"Layer 2 Gradients\")\n",
    "                    tensor_stats(grad[:self.output_size, :], \"Layer 3 Gradients\")\n",
    "                self.w -= grad\n",
    "                self.w.grad.zero_()\n",
    "            if self.R_INV.grad is not None:\n",
    "                self.R_INV -= lr * self.R_INV.grad\n",
    "                self.R_INV.grad.zero_()\n",
    "            \n",
    "            if self.Scaling.grad is not None:\n",
    "                self.Scaling -= lr * model_RRAM.Scaling.grad\n",
    "                self.Scaling.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d51da-8368-4c97-89a2-9fc1374f408b",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RRAM = {\n",
    "    \"G_ON\": 6e-5,          # High conductance state\n",
    "    \"G_OFF\": 2.88e-6,        # Low conductance state\n",
    "    \"V_INV\": 0.6,            # Inverter voltage\n",
    "    \"R_INV_1\": 1e+3,         # Inverter resistance\n",
    "    \"R_INV_2\": 5e+3,\n",
    "    \"V_1\": 0.1,              # High input voltage\n",
    "    \"V_0\": -0.1,             # Low input voltage\n",
    "    \"zeta\": 1000,               # Sharpness parameter for soft binarization \n",
    "    \"initial_factor\": 0.1,   # Initial weight scaling factor\n",
    "    \"crossbar\": (64, 64),      # Crossbar size (rows, columns)\n",
    "    \"input_size\": 784,        # Input size\n",
    "    \"recurrence_size\": 32,    # Feedback size for recurrent connections\n",
    "    \"output_size\": 10,        # Output size\n",
    "    \"data_in\": 28,\n",
    "    \"bin_active\": False,\n",
    "    \"monitor_volts\": False,        # check post inverter voltages flag\n",
    "    \"monitor_grads\": False,        # check gradient values\n",
    "    \"monitor_latents\": False,\n",
    "    \"dropout\": 0.01,          # Dropout probability  \n",
    "    \"lr\": 0.001,            # Training LR\n",
    "    \"epochs\": 300,          # Training Epochs\n",
    "    \"int_lr\": 100,           # Internal LR\n",
    "    \"int_norm\": True         # Normalizing Gradient\n",
    "}\n",
    "\n",
    "model_params = {k: v for k, v in params_RRAM.items() if k not in [\"noise_std\", \"batch_size\", \"lr\", \"epochs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SoftBinaryRecurrentForwardNetwork        4,096\n",
       "├─Dropout: 1-1                           --\n",
       "=================================================================\n",
       "Total params: 4,096\n",
       "Trainable params: 4,096\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
    "summary(model_RRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614",
   "metadata": {},
   "source": [
    "### Loading Past Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.13\n",
      "Parameters: {'G_ON': 6e-05, 'G_OFF': 2.88e-06, 'V_INV': 0.6, 'R_INV_1': 1000.0, 'R_INV_2': 4000.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 100, 'initial_factor': 1, 'crossbar': (64, 64), 'input_size': 784, 'recurrence_size': 32, 'output_size': 10, 'data_in': 28, 'bin_active': False, 'monitor_volts': False, 'monitor_grads': False, 'monitor_latents': False, 'dropout': 0.01, 'lr': 1, 'epochs': 300, 'int_lr': 0.01, 'int_norm': True}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(f\"Best_Val_Accuracy.txt\", 'r') as f: val_best = float(f.read())\n",
    "    with open(f\"Best_Params.txt\", 'r') as f: params_best = ast.literal_eval(f.read())\n",
    "\n",
    "    model_best = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
    "\n",
    "    print(\"Accuracy:\", val_best)\n",
    "    print(\"Parameters:\", params_best)\n",
    "\n",
    "    checkpoint = torch.load(f\"Best_model.pth\")\n",
    "    model_best.load_state_dict(checkpoint)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    val_best = 0\n",
    "    print(\"No Saved Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d1155-be9e-4a7a-9a74-a1d608188350",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "75e71bbb-9193-4010-8f9e-70ef9154c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_RRAM = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0b7d2-7c19-4b3e-8856-76d2e9f32792",
   "metadata": {},
   "source": [
    "### Training to a subset of Dataset First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "97dc9fdf-797d-4588-9975-cfc699f216d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RRAM.monitor_grads = True\n",
    "model_RRAM.monitor_volts = False\n",
    "model_RRAM.monitor_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "efd13def-9751-4e0e-89bf-666a98444d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Weights: - Mean Magnitude: 1.08e-02, Max: 2.16e-02, Min: -2.16e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 1.60e-03, Max: 1.29e-02, Min: -1.31e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.99e-03, Max: 1.02e-02, Min: -9.31e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.52e-02, Min: -1.68e-02\n",
      "Latent Weights: - Mean Magnitude: 1.10e-02, Max: 2.94e-02, Min: -3.54e-02\n",
      "Epoch 1, LR: 0.0400, Train Loss: 2.3026, Train Accuracy: 10.20%, Val Loss: 2.3026, Val Accuracy: 10.84%\n",
      "Latent Weights: - Mean Magnitude: 1.10e-02, Max: 2.94e-02, Min: -3.54e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 1.38e-03, Max: 9.54e-03, Min: -1.09e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.84e-03, Max: 1.19e-02, Min: -1.19e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.69e-03, Max: 1.25e-02, Min: -1.28e-02\n",
      "Latent Weights: - Mean Magnitude: 1.11e-02, Max: 3.54e-02, Min: -3.35e-02\n",
      "Epoch 2, LR: 0.2000, Train Loss: 2.3026, Train Accuracy: 10.20%, Val Loss: 2.3024, Val Accuracy: 12.68%\n",
      "Latent Weights: - Mean Magnitude: 1.11e-02, Max: 3.54e-02, Min: -3.35e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 1.57e-03, Max: 1.07e-02, Min: -9.57e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 2.04e-03, Max: 7.82e-03, Min: -8.67e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.37e-02, Min: -1.54e-02\n",
      "Latent Weights: - Mean Magnitude: 1.13e-02, Max: 3.71e-02, Min: -4.04e-02\n",
      "Epoch 3, LR: 1.0000, Train Loss: 2.3025, Train Accuracy: 12.23%, Val Loss: 2.3026, Val Accuracy: 6.57%\n",
      "Latent Weights: - Mean Magnitude: 1.13e-02, Max: 3.71e-02, Min: -4.04e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 1.42e-03, Max: 1.11e-02, Min: -1.02e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.62e-03, Max: 1.29e-02, Min: -1.92e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.52e-03, Max: 1.42e-02, Min: -1.75e-02\n",
      "Latent Weights: - Mean Magnitude: 1.15e-02, Max: 4.15e-02, Min: -4.24e-02\n",
      "Epoch 4, LR: 1.0000, Train Loss: 2.3026, Train Accuracy: 7.38%, Val Loss: 2.3025, Val Accuracy: 14.38%\n",
      "Latent Weights: - Mean Magnitude: 1.15e-02, Max: 4.15e-02, Min: -4.24e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 1.34e-03, Max: 9.30e-03, Min: -9.66e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 1.40e-03, Max: 1.05e-02, Min: -1.04e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.14e-03, Max: 2.15e-02, Min: -2.96e-02\n",
      "Latent Weights: - Mean Magnitude: 1.17e-02, Max: 4.24e-02, Min: -5.12e-02\n",
      "Epoch 5, LR: 1.0000, Train Loss: 2.3025, Train Accuracy: 14.65%, Val Loss: 2.3026, Val Accuracy: 9.58%\n",
      "Latent Weights: - Mean Magnitude: 1.17e-02, Max: 4.24e-02, Min: -5.12e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 9.06e-04, Max: 1.17e-02, Min: -1.18e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.32e-03, Max: 1.04e-02, Min: -1.00e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.57e-03, Max: 1.25e-02, Min: -1.46e-02\n",
      "Latent Weights: - Mean Magnitude: 1.19e-02, Max: 4.73e-02, Min: -6.30e-02\n",
      "Epoch 6, LR: 1.0000, Train Loss: 2.3025, Train Accuracy: 10.20%, Val Loss: 2.3024, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.19e-02, Max: 4.73e-02, Min: -6.30e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 9.11e-04, Max: 1.37e-02, Min: -1.35e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.14e-03, Max: 1.10e-02, Min: -1.09e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.27e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 1.21e-02, Max: 5.91e-02, Min: -7.49e-02\n",
      "Epoch 7, LR: 1.0000, Train Loss: 2.3024, Train Accuracy: 11.50%, Val Loss: 2.3024, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.21e-02, Max: 5.91e-02, Min: -7.49e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 9.11e-04, Max: 1.37e-02, Min: -1.38e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.03e-04, Max: 9.57e-03, Min: -1.11e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.26e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 1.25e-02, Max: 6.84e-02, Min: -8.66e-02\n",
      "Epoch 8, LR: 1.0000, Train Loss: 2.3022, Train Accuracy: 11.50%, Val Loss: 2.3022, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.25e-02, Max: 6.84e-02, Min: -8.66e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 6.22e-04, Max: 4.60e-02, Min: -9.67e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 8.02e-04, Max: 1.75e-02, Min: -1.57e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.36e-02, Min: -1.23e-02\n",
      "Latent Weights: - Mean Magnitude: 1.28e-02, Max: 7.99e-02, Min: -9.81e-02\n",
      "Epoch 9, LR: 1.0000, Train Loss: 2.3021, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.28e-02, Max: 7.99e-02, Min: -9.81e-02\n",
      "Layer 1 Gradients - Mean Magnitude: 5.85e-04, Max: 2.99e-02, Min: -1.16e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.79e-04, Max: 4.42e-02, Min: -1.14e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.16e-03, Max: 2.57e-02, Min: -4.57e-02\n",
      "Latent Weights: - Mean Magnitude: 1.31e-02, Max: 1.21e-01, Min: -1.06e-01\n",
      "Epoch 10, LR: 1.0000, Train Loss: 2.3018, Train Accuracy: 11.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.31e-02, Max: 1.21e-01, Min: -1.06e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.15e-04, Max: 1.74e-02, Min: -1.74e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.16e-04, Max: 1.27e-02, Min: -1.25e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.17e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 1.35e-02, Max: 1.33e-01, Min: -1.17e-01\n",
      "Epoch 11, LR: 1.0000, Train Loss: 2.3019, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.35e-02, Max: 1.33e-01, Min: -1.17e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.70e-04, Max: 1.75e-02, Min: -1.75e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.95e-04, Max: 9.86e-03, Min: -1.12e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 1.40e-02, Max: 1.44e-01, Min: -1.29e-01\n",
      "Epoch 12, LR: 1.0000, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.40e-02, Max: 1.44e-01, Min: -1.29e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.08e-04, Max: 1.77e-02, Min: -1.69e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.30e-03, Max: 1.06e-02, Min: -9.44e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 1.45e-02, Max: 1.56e-01, Min: -1.40e-01\n",
      "Epoch 13, LR: 1.0000, Train Loss: 2.3015, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.45e-02, Max: 1.56e-01, Min: -1.40e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.07e-04, Max: 1.60e-02, Min: -1.60e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.18e-04, Max: 1.52e-02, Min: -1.37e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 1.50e-02, Max: 1.67e-01, Min: -1.52e-01\n",
      "Epoch 14, LR: 1.0000, Train Loss: 2.3014, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.50e-02, Max: 1.67e-01, Min: -1.52e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.31e-04, Max: 1.59e-02, Min: -1.59e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.93e-04, Max: 1.63e-02, Min: -1.12e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 1.56e-02, Max: 1.79e-01, Min: -1.63e-01\n",
      "Epoch 15, LR: 1.0000, Train Loss: 2.3013, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.56e-02, Max: 1.79e-01, Min: -1.63e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.05e-04, Max: 1.86e-02, Min: -1.76e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.57e-04, Max: 1.03e-02, Min: -1.10e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 1.62e-02, Max: 1.90e-01, Min: -1.74e-01\n",
      "Epoch 16, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.62e-02, Max: 1.90e-01, Min: -1.74e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.65e-04, Max: 1.88e-02, Min: -1.74e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.02e-04, Max: 1.35e-02, Min: -1.27e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.14e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 1.68e-02, Max: 2.02e-01, Min: -1.86e-01\n",
      "Epoch 17, LR: 1.0000, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.68e-02, Max: 2.02e-01, Min: -1.86e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.52e-04, Max: 1.54e-02, Min: -1.54e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.42e-04, Max: 2.00e-02, Min: -2.02e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.68e-03, Max: 1.14e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 1.73e-02, Max: 2.13e-01, Min: -1.97e-01\n",
      "Epoch 18, LR: 1.0000, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.73e-02, Max: 2.13e-01, Min: -1.97e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.31e-04, Max: 1.61e-02, Min: -1.61e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.54e-04, Max: 1.83e-02, Min: -1.70e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.71e-03, Max: 1.12e-02, Min: -1.12e-02\n",
      "Latent Weights: - Mean Magnitude: 1.79e-02, Max: 2.24e-01, Min: -2.08e-01\n",
      "Epoch 19, LR: 1.0000, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.79e-02, Max: 2.24e-01, Min: -2.08e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.72e-03, Max: 1.12e-02, Min: -1.12e-02\n",
      "Latent Weights: - Mean Magnitude: 1.83e-02, Max: 2.36e-01, Min: -2.20e-01\n",
      "Epoch 20, LR: 1.0000, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.83e-02, Max: 2.36e-01, Min: -2.20e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.73e-03, Max: 1.11e-02, Min: -1.11e-02\n",
      "Latent Weights: - Mean Magnitude: 1.87e-02, Max: 2.47e-01, Min: -2.31e-01\n",
      "Epoch 21, LR: 1.0000, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.87e-02, Max: 2.47e-01, Min: -2.31e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.74e-03, Max: 1.10e-02, Min: -1.10e-02\n",
      "Latent Weights: - Mean Magnitude: 1.90e-02, Max: 2.58e-01, Min: -2.42e-01\n",
      "Epoch 22, LR: 1.0000, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.90e-02, Max: 2.58e-01, Min: -2.42e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.75e-03, Max: 1.09e-02, Min: -1.09e-02\n",
      "Latent Weights: - Mean Magnitude: 1.94e-02, Max: 2.69e-01, Min: -2.53e-01\n",
      "Epoch 23, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.94e-02, Max: 2.69e-01, Min: -2.53e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.78e-03, Max: 1.07e-02, Min: -1.07e-02\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.79e-01, Min: -2.63e-01\n",
      "Epoch 24, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.79e-01, Min: -2.63e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.81e-03, Max: 1.04e-02, Min: -1.04e-02\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.90e-01, Min: -2.74e-01\n",
      "Epoch 25, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.90e-01, Min: -2.74e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.93e-03, Max: 9.36e-03, Min: -9.36e-03\n",
      "Latent Weights: - Mean Magnitude: 2.06e-02, Max: 2.99e-01, Min: -2.83e-01\n",
      "Epoch 26, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.06e-02, Max: 2.99e-01, Min: -2.83e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.77e-03, Max: 1.08e-02, Min: -1.08e-02\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.88e-01, Min: -2.72e-01\n",
      "Epoch 27, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.88e-01, Min: -2.72e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.84e-01\n",
      "Epoch 28, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.84e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.52e-03, Max: 1.26e-02, Min: -1.26e-02\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.87e-01, Min: -2.71e-01\n",
      "Epoch 29, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.87e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.43e-03, Max: 1.31e-02, Min: -1.31e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.84e-01\n",
      "Epoch 30, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.84e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.35e-03, Max: 1.36e-02, Min: -1.36e-02\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.87e-01, Min: -2.71e-01\n",
      "Epoch 31, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.87e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.29e-03, Max: 1.38e-02, Min: -1.38e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.85e-01\n",
      "Epoch 32, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.00e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.20e-03, Max: 1.40e-02, Min: -1.40e-02\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 33, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.14e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 34, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 35, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 36, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.70e-01\n",
      "Epoch 37, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.70e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 38, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 39, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 40, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 41, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 42, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.10e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 43, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 44, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.42e-02, Min: -1.42e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 45, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 46, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 47, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 48, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 49, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 50, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 51, LR: 1.0000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 52, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 53, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 54, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 55, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 56, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 57, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 58, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 59, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 60, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 61, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 62, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 63, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 64, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 65, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 66, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 67, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 68, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 69, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 70, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 71, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 72, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 73, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 74, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 75, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 76, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 77, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 78, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 79, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 80, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 81, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 82, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 83, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 84, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 85, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 86, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 87, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 88, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 89, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 90, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 91, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 92, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 93, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 94, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 95, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 96, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 97, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 98, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 99, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 100, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 101, LR: 0.5000, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 102, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 103, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 104, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 105, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 106, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 107, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 108, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 109, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 110, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 111, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 112, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 113, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 114, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 115, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 116, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 117, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 118, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 119, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 120, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 121, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 122, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 123, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 124, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 125, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 126, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 127, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 128, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 129, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 130, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 131, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 132, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 133, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 134, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 135, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Epoch 136, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 3.01e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.20e-04, Max: 1.70e-02, Min: -1.70e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.41e-04, Max: 1.32e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Epoch 137, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 2.86e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.55e-04, Max: 1.70e-02, Min: -1.70e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.60e-04, Max: 1.63e-02, Min: -1.91e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.46e-03, Max: 1.28e-02, Min: -1.28e-02\n",
      "Latent Weights: - Mean Magnitude: 2.07e-02, Max: 2.99e-01, Min: -2.83e-01\n",
      "Epoch 138, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.07e-02, Max: 2.99e-01, Min: -2.83e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.10e-04, Max: 1.66e-02, Min: -1.66e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 4.97e-04, Max: 2.94e-02, Min: -3.69e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.91e-03, Max: 9.07e-03, Min: -9.07e-03\n",
      "Latent Weights: - Mean Magnitude: 2.04e-02, Max: 2.92e-01, Min: -2.76e-01\n",
      "Epoch 139, LR: 0.2500, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.04e-02, Max: 2.92e-01, Min: -2.76e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.73e-04, Max: 1.22e-02, Min: -1.22e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.63e-04, Max: 1.40e-02, Min: -1.43e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.92e-03, Max: 1.01e-02, Min: -1.01e-02\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 2.98e-01, Min: -2.82e-01\n",
      "Epoch 140, LR: 0.2500, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.05e-02, Max: 2.98e-01, Min: -2.82e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.86e-03, Max: 8.88e-03, Min: -8.88e-03\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.91e-01, Min: -2.75e-01\n",
      "Epoch 141, LR: 0.2500, Train Loss: 2.3028, Train Accuracy: 10.78%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.02e-02, Max: 2.91e-01, Min: -2.75e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.88e-03, Max: 8.88e-03, Min: -8.88e-03\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 2.83e-01, Min: -2.67e-01\n",
      "Epoch 142, LR: 0.2500, Train Loss: 2.3027, Train Accuracy: 10.78%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 2.83e-01, Min: -2.67e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.35e-04, Max: 1.75e-02, Min: -1.75e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.41e-04, Max: 1.32e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.90e-03, Max: 8.89e-03, Min: -8.89e-03\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.76e-01, Min: -2.60e-01\n",
      "Epoch 143, LR: 0.2500, Train Loss: 2.3026, Train Accuracy: 10.78%, Val Loss: 2.3060, Val Accuracy: 8.92%\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.76e-01, Min: -2.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.03e-04, Max: 1.67e-02, Min: -1.67e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.82e-04, Max: 1.35e-02, Min: -1.78e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 1.95e-02, Max: 2.64e-01, Min: -2.48e-01\n",
      "Epoch 144, LR: 0.2500, Train Loss: 2.3068, Train Accuracy: 9.50%, Val Loss: 2.3053, Val Accuracy: 8.92%\n",
      "Latent Weights: - Mean Magnitude: 1.95e-02, Max: 2.64e-01, Min: -2.48e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.08e-04, Max: 1.70e-02, Min: -1.70e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.90e-04, Max: 1.31e-02, Min: -1.33e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.19e-02, Min: -1.19e-02\n",
      "Latent Weights: - Mean Magnitude: 1.92e-02, Max: 2.52e-01, Min: -2.36e-01\n",
      "Epoch 145, LR: 0.2500, Train Loss: 2.3059, Train Accuracy: 9.48%, Val Loss: 2.3047, Val Accuracy: 8.92%\n",
      "Latent Weights: - Mean Magnitude: 1.92e-02, Max: 2.52e-01, Min: -2.36e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.16e-04, Max: 1.91e-02, Min: -1.68e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.81e-04, Max: 1.32e-02, Min: -1.29e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 1.91e-02, Max: 2.40e-01, Min: -2.25e-01\n",
      "Epoch 146, LR: 0.2500, Train Loss: 2.3052, Train Accuracy: 9.52%, Val Loss: 2.3042, Val Accuracy: 8.92%\n",
      "Latent Weights: - Mean Magnitude: 1.91e-02, Max: 2.40e-01, Min: -2.25e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.40e-04, Max: 1.77e-02, Min: -1.77e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.19e-04, Max: 1.32e-02, Min: -1.36e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.64e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.45e-01, Min: -2.23e-01\n",
      "Epoch 147, LR: 0.2500, Train Loss: 2.3046, Train Accuracy: 9.52%, Val Loss: 2.3037, Val Accuracy: 8.92%\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.45e-01, Min: -2.23e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.44e-04, Max: 9.42e-03, Min: -9.42e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 7.30e-04, Max: 1.31e-02, Min: -1.49e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 1.87e-02, Max: 2.57e-01, Min: -2.35e-01\n",
      "Epoch 148, LR: 0.2500, Train Loss: 2.3039, Train Accuracy: 9.52%, Val Loss: 2.3043, Val Accuracy: 8.69%\n",
      "Latent Weights: - Mean Magnitude: 1.87e-02, Max: 2.57e-01, Min: -2.35e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.21e-03, Max: 9.86e-03, Min: -9.84e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 1.49e-03, Max: 7.36e-03, Min: -7.42e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.05e-03, Max: 2.12e-02, Min: -2.36e-02\n",
      "Latent Weights: - Mean Magnitude: 1.88e-02, Max: 2.41e-01, Min: -2.30e-01\n",
      "Epoch 149, LR: 0.2500, Train Loss: 2.3043, Train Accuracy: 9.15%, Val Loss: 2.3008, Val Accuracy: 14.81%\n",
      "Latent Weights: - Mean Magnitude: 1.88e-02, Max: 2.41e-01, Min: -2.30e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.29e-03, Max: 8.25e-03, Min: -1.17e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.60e-03, Max: 9.03e-03, Min: -9.01e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 1.97e-03, Max: 2.43e-02, Min: -2.10e-02\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.46e-01, Min: -2.34e-01\n",
      "Epoch 150, LR: 0.2500, Train Loss: 2.3012, Train Accuracy: 15.17%, Val Loss: 2.3028, Val Accuracy: 9.55%\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.46e-01, Min: -2.34e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.41e-03, Max: 8.87e-03, Min: -9.47e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 2.10e-03, Max: 6.63e-03, Min: -6.19e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.90e-03, Max: 1.03e-02, Min: -9.89e-03\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.55e-01, Min: -2.43e-01\n",
      "Epoch 151, LR: 0.2500, Train Loss: 2.3031, Train Accuracy: 9.35%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.89e-02, Max: 2.55e-01, Min: -2.43e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 8.78e-04, Max: 1.53e-02, Min: -1.59e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.44e-04, Max: 1.26e-02, Min: -1.25e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.15e-03, Max: 2.69e-02, Min: -3.08e-02\n",
      "Latent Weights: - Mean Magnitude: 1.91e-02, Max: 2.85e-01, Min: -2.36e-01\n",
      "Epoch 152, LR: 0.1250, Train Loss: 2.3019, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.91e-02, Max: 2.85e-01, Min: -2.36e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.37e-04, Max: 1.13e-02, Min: -1.13e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.56e-04, Max: 1.40e-02, Min: -1.36e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.69e-03, Max: 1.10e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 1.93e-02, Max: 2.74e-01, Min: -2.30e-01\n",
      "Epoch 153, LR: 0.1250, Train Loss: 2.3019, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.93e-02, Max: 2.74e-01, Min: -2.30e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.03e-03, Max: 2.13e-02, Min: -1.14e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.89e-04, Max: 1.86e-02, Min: -1.18e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.72e-03, Max: 1.28e-02, Min: -1.31e-02\n",
      "Latent Weights: - Mean Magnitude: 1.96e-02, Max: 2.71e-01, Min: -2.41e-01\n",
      "Epoch 154, LR: 0.1250, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3003, Val Accuracy: 11.65%\n",
      "Latent Weights: - Mean Magnitude: 1.96e-02, Max: 2.71e-01, Min: -2.41e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.16e-03, Max: 9.58e-03, Min: -1.01e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.99e-03, Max: 7.68e-03, Min: -7.68e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.47e-03, Max: 1.22e-02, Min: -1.24e-02\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.80e-01, Min: -2.52e-01\n",
      "Epoch 155, LR: 0.1250, Train Loss: 2.2995, Train Accuracy: 11.98%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 1.98e-02, Max: 2.80e-01, Min: -2.52e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.48e-03, Max: 1.15e-02, Min: -1.10e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.33e-03, Max: 8.09e-03, Min: -8.74e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.25e-03, Max: 1.68e-02, Min: -2.36e-02\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 2.86e-01, Min: -2.46e-01\n",
      "Epoch 156, LR: 0.1250, Train Loss: 2.3017, Train Accuracy: 11.68%, Val Loss: 2.3020, Val Accuracy: 11.37%\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 2.86e-01, Min: -2.46e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.08e-03, Max: 1.12e-02, Min: -1.46e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.06e-03, Max: 1.13e-02, Min: -1.10e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.68e-03, Max: 1.15e-02, Min: -1.23e-02\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 2.97e-01, Min: -2.55e-01\n",
      "Epoch 157, LR: 0.1250, Train Loss: 2.3017, Train Accuracy: 11.53%, Val Loss: 2.2990, Val Accuracy: 12.68%\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 2.97e-01, Min: -2.55e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.06e-03, Max: 1.13e-02, Min: -1.12e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.59e-04, Max: 1.07e-02, Min: -1.06e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.35e-03, Max: 1.11e-02, Min: -1.11e-02\n",
      "Latent Weights: - Mean Magnitude: 2.04e-02, Max: 2.99e-01, Min: -2.63e-01\n",
      "Epoch 158, LR: 0.1250, Train Loss: 2.2984, Train Accuracy: 12.88%, Val Loss: 2.3030, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.04e-02, Max: 2.99e-01, Min: -2.63e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.18e-03, Max: 1.55e-02, Min: -1.16e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.46e-04, Max: 1.35e-02, Min: -1.40e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.55e-03, Max: 2.01e-02, Min: -1.62e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 3.10e-01, Min: -2.74e-01\n",
      "Epoch 159, LR: 0.1250, Train Loss: 2.3032, Train Accuracy: 9.38%, Val Loss: 2.3051, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 3.10e-01, Min: -2.74e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.79e-04, Max: 1.61e-02, Min: -1.61e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.08e-04, Max: 1.34e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.61e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 2.99e-01, Min: -2.62e-01\n",
      "Epoch 160, LR: 0.1250, Train Loss: 2.3057, Train Accuracy: 9.37%, Val Loss: 2.3043, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 2.99e-01, Min: -2.62e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.42e-04, Max: 1.46e-02, Min: -1.46e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.64e-04, Max: 1.28e-02, Min: -1.31e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.60e-03, Max: 1.20e-02, Min: -1.20e-02\n",
      "Latent Weights: - Mean Magnitude: 2.00e-02, Max: 3.11e-01, Min: -2.50e-01\n",
      "Epoch 161, LR: 0.1250, Train Loss: 2.3047, Train Accuracy: 9.37%, Val Loss: 2.3036, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.00e-02, Max: 3.11e-01, Min: -2.50e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.05e-04, Max: 1.39e-02, Min: -1.39e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.66e-04, Max: 1.19e-02, Min: -1.17e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.61e-03, Max: 1.22e-02, Min: -1.20e-02\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 3.23e-01, Min: -2.38e-01\n",
      "Epoch 162, LR: 0.1250, Train Loss: 2.3038, Train Accuracy: 9.38%, Val Loss: 2.3030, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 3.23e-01, Min: -2.38e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.23e-04, Max: 1.55e-02, Min: -1.56e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.09e-03, Max: 9.33e-03, Min: -9.23e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.59e-03, Max: 1.21e-02, Min: -1.26e-02\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 3.35e-01, Min: -2.26e-01\n",
      "Epoch 163, LR: 0.1250, Train Loss: 2.3031, Train Accuracy: 9.33%, Val Loss: 2.3027, Val Accuracy: 11.16%\n",
      "Latent Weights: - Mean Magnitude: 1.99e-02, Max: 3.35e-01, Min: -2.26e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.65e-04, Max: 1.29e-02, Min: -1.83e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.01e-03, Max: 1.53e-02, Min: -9.83e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.61e-03, Max: 1.40e-02, Min: -1.26e-02\n",
      "Latent Weights: - Mean Magnitude: 2.00e-02, Max: 3.47e-01, Min: -2.14e-01\n",
      "Epoch 164, LR: 0.1250, Train Loss: 2.3025, Train Accuracy: 10.97%, Val Loss: 2.3023, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.00e-02, Max: 3.47e-01, Min: -2.14e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.23e-04, Max: 2.66e-02, Min: -1.11e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.54e-04, Max: 1.52e-02, Min: -1.39e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.57e-03, Max: 1.79e-02, Min: -1.19e-02\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 3.59e-01, Min: -2.03e-01\n",
      "Epoch 165, LR: 0.1250, Train Loss: 2.3021, Train Accuracy: 11.50%, Val Loss: 2.3022, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.01e-02, Max: 3.59e-01, Min: -2.03e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.85e-04, Max: 1.29e-02, Min: -1.29e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.72e-04, Max: 1.72e-02, Min: -1.48e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.58e-03, Max: 1.21e-02, Min: -1.21e-02\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 3.71e-01, Min: -2.15e-01\n",
      "Epoch 166, LR: 0.1250, Train Loss: 2.3020, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.03e-02, Max: 3.71e-01, Min: -2.15e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.55e-04, Max: 1.22e-02, Min: -1.22e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.04e-04, Max: 1.28e-02, Min: -1.33e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.61e-03, Max: 1.21e-02, Min: -1.21e-02\n",
      "Latent Weights: - Mean Magnitude: 2.06e-02, Max: 3.83e-01, Min: -2.27e-01\n",
      "Epoch 167, LR: 0.1250, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3025, Val Accuracy: 12.74%\n",
      "Latent Weights: - Mean Magnitude: 2.06e-02, Max: 3.83e-01, Min: -2.27e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.02e-03, Max: 1.20e-02, Min: -1.20e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.96e-04, Max: 1.25e-02, Min: -1.24e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.59e-03, Max: 1.27e-02, Min: -1.59e-02\n",
      "Latent Weights: - Mean Magnitude: 2.07e-02, Max: 3.71e-01, Min: -2.19e-01\n",
      "Epoch 168, LR: 0.1250, Train Loss: 2.3025, Train Accuracy: 12.52%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.07e-02, Max: 3.71e-01, Min: -2.19e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 8.82e-04, Max: 1.67e-02, Min: -1.57e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.43e-04, Max: 2.14e-02, Min: -1.83e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.76e-03, Max: 1.09e-02, Min: -1.83e-02\n",
      "Latent Weights: - Mean Magnitude: 2.12e-02, Max: 3.82e-01, Min: -2.29e-01\n",
      "Epoch 169, LR: 0.1250, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.12e-02, Max: 3.82e-01, Min: -2.29e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.19e-03, Max: 7.99e-03, Min: -8.82e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 1.15e-03, Max: 1.60e-02, Min: -9.04e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 1.96e-03, Max: 1.69e-02, Min: -2.23e-02\n",
      "Latent Weights: - Mean Magnitude: 2.14e-02, Max: 3.87e-01, Min: -2.34e-01\n",
      "Epoch 170, LR: 0.1250, Train Loss: 2.3013, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.14e-02, Max: 3.87e-01, Min: -2.34e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.85e-04, Max: 1.28e-02, Min: -1.29e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.92e-04, Max: 1.34e-02, Min: -1.35e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.64e-03, Max: 1.80e-02, Min: -1.95e-02\n",
      "Latent Weights: - Mean Magnitude: 2.17e-02, Max: 3.97e-01, Min: -2.44e-01\n",
      "Epoch 171, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.17e-02, Max: 3.97e-01, Min: -2.44e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.68e-04, Max: 1.08e-02, Min: -1.08e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.80e-04, Max: 1.28e-02, Min: -1.29e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.44e-03, Max: 2.33e-02, Min: -2.11e-02\n",
      "Latent Weights: - Mean Magnitude: 2.20e-02, Max: 4.07e-01, Min: -2.54e-01\n",
      "Epoch 172, LR: 0.1250, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3015, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.20e-02, Max: 4.07e-01, Min: -2.54e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.14e-03, Max: 1.18e-02, Min: -1.47e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.86e-04, Max: 2.78e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.01e-03, Max: 2.57e-02, Min: -3.71e-02\n",
      "Latent Weights: - Mean Magnitude: 2.23e-02, Max: 4.13e-01, Min: -2.60e-01\n",
      "Epoch 173, LR: 0.1250, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.23e-02, Max: 4.13e-01, Min: -2.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.11e-04, Max: 1.57e-02, Min: -1.46e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.87e-04, Max: 1.58e-02, Min: -2.01e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 2.27e-02, Max: 4.24e-01, Min: -2.72e-01\n",
      "Epoch 174, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.27e-02, Max: 4.24e-01, Min: -2.72e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.40e-04, Max: 1.69e-02, Min: -1.69e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.94e-04, Max: 1.62e-02, Min: -1.77e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.68e-03, Max: 1.21e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 2.30e-02, Max: 4.36e-01, Min: -2.83e-01\n",
      "Epoch 175, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3045, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.30e-02, Max: 4.36e-01, Min: -2.83e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.24e-03, Max: 1.01e-02, Min: -1.02e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.50e-04, Max: 1.13e-02, Min: -1.53e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.45e-03, Max: 1.30e-02, Min: -2.52e-02\n",
      "Latent Weights: - Mean Magnitude: 2.30e-02, Max: 4.27e-01, Min: -2.74e-01\n",
      "Epoch 176, LR: 0.1250, Train Loss: 2.3051, Train Accuracy: 9.37%, Val Loss: 2.3043, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.30e-02, Max: 4.27e-01, Min: -2.74e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.34e-03, Max: 8.08e-03, Min: -8.08e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 9.47e-04, Max: 1.63e-02, Min: -1.37e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.49e-03, Max: 1.74e-02, Min: -2.46e-02\n",
      "Latent Weights: - Mean Magnitude: 2.29e-02, Max: 4.16e-01, Min: -2.64e-01\n",
      "Epoch 177, LR: 0.1250, Train Loss: 2.3050, Train Accuracy: 9.38%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.29e-02, Max: 4.16e-01, Min: -2.64e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.37e-03, Max: 1.02e-02, Min: -1.03e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.58e-04, Max: 1.46e-02, Min: -1.45e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.24e-03, Max: 1.70e-02, Min: -2.49e-02\n",
      "Latent Weights: - Mean Magnitude: 2.32e-02, Max: 4.24e-01, Min: -2.71e-01\n",
      "Epoch 178, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.32e-02, Max: 4.24e-01, Min: -2.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.01e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.68e-04, Max: 1.37e-02, Min: -1.47e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.71e-03, Max: 1.12e-02, Min: -1.12e-02\n",
      "Latent Weights: - Mean Magnitude: 2.35e-02, Max: 4.35e-01, Min: -2.83e-01\n",
      "Epoch 179, LR: 0.1250, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.2942, Val Accuracy: 16.51%\n",
      "Latent Weights: - Mean Magnitude: 2.35e-02, Max: 4.35e-01, Min: -2.83e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.41e-03, Max: 1.22e-02, Min: -1.29e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.29e-03, Max: 1.30e-02, Min: -1.29e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.51e-03, Max: 1.41e-02, Min: -1.48e-02\n",
      "Latent Weights: - Mean Magnitude: 2.38e-02, Max: 4.48e-01, Min: -2.96e-01\n",
      "Epoch 180, LR: 0.1250, Train Loss: 2.2947, Train Accuracy: 15.08%, Val Loss: 2.3043, Val Accuracy: 10.27%\n",
      "Latent Weights: - Mean Magnitude: 2.38e-02, Max: 4.48e-01, Min: -2.96e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.17e-03, Max: 1.08e-02, Min: -1.10e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.21e-03, Max: 2.65e-02, Min: -2.08e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.47e-03, Max: 1.80e-02, Min: -2.03e-02\n",
      "Latent Weights: - Mean Magnitude: 2.37e-02, Max: 4.38e-01, Min: -2.85e-01\n",
      "Epoch 181, LR: 0.1250, Train Loss: 2.3046, Train Accuracy: 9.15%, Val Loss: 2.3024, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.37e-02, Max: 4.38e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.06e-04, Max: 1.12e-02, Min: -1.12e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.03e-03, Max: 1.05e-02, Min: -1.06e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.57e-03, Max: 1.18e-02, Min: -2.52e-02\n",
      "Latent Weights: - Mean Magnitude: 2.39e-02, Max: 4.27e-01, Min: -2.90e-01\n",
      "Epoch 182, LR: 0.1250, Train Loss: 2.3025, Train Accuracy: 11.38%, Val Loss: 2.3015, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.39e-02, Max: 4.27e-01, Min: -2.90e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.61e-04, Max: 2.43e-02, Min: -2.41e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.94e-04, Max: 1.27e-02, Min: -1.26e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.73e-03, Max: 1.92e-02, Min: -2.01e-02\n",
      "Latent Weights: - Mean Magnitude: 2.40e-02, Max: 4.29e-01, Min: -2.97e-01\n",
      "Epoch 183, LR: 0.1250, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3028, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.40e-02, Max: 4.29e-01, Min: -2.97e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.31e-04, Max: 1.23e-02, Min: -1.21e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.93e-04, Max: 1.20e-02, Min: -1.23e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.63e-03, Max: 1.20e-02, Min: -1.21e-02\n",
      "Latent Weights: - Mean Magnitude: 2.40e-02, Max: 4.41e-01, Min: -2.85e-01\n",
      "Epoch 184, LR: 0.1250, Train Loss: 2.3029, Train Accuracy: 9.52%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.40e-02, Max: 4.41e-01, Min: -2.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.29e-03, Max: 8.15e-03, Min: -8.18e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 5.84e-04, Max: 8.53e-03, Min: -7.73e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.71e-03, Max: 1.28e-02, Min: -1.31e-02\n",
      "Latent Weights: - Mean Magnitude: 2.43e-02, Max: 4.52e-01, Min: -2.96e-01\n",
      "Epoch 185, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3039, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.43e-02, Max: 4.52e-01, Min: -2.96e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.00e-03, Max: 1.19e-02, Min: -1.19e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.26e-04, Max: 1.27e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.63e-03, Max: 1.17e-02, Min: -1.26e-02\n",
      "Latent Weights: - Mean Magnitude: 2.42e-02, Max: 4.40e-01, Min: -3.08e-01\n",
      "Epoch 186, LR: 0.1250, Train Loss: 2.3044, Train Accuracy: 9.37%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.42e-02, Max: 4.40e-01, Min: -3.08e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.15e-03, Max: 1.03e-02, Min: -1.04e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.26e-04, Max: 2.91e-02, Min: -1.10e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.23e-03, Max: 2.62e-02, Min: -3.74e-02\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.49e-01, Min: -3.01e-01\n",
      "Epoch 187, LR: 0.1250, Train Loss: 2.3013, Train Accuracy: 11.50%, Val Loss: 2.3036, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.49e-01, Min: -3.01e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.93e-04, Max: 1.70e-02, Min: -1.70e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.98e-04, Max: 1.28e-02, Min: -1.35e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.64e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.37e-01, Min: -2.89e-01\n",
      "Epoch 188, LR: 0.1250, Train Loss: 2.3040, Train Accuracy: 9.37%, Val Loss: 2.3030, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.37e-01, Min: -2.89e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.08e-04, Max: 1.28e-02, Min: -1.28e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.11e-04, Max: 1.25e-02, Min: -1.26e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.25e-01, Min: -2.80e-01\n",
      "Epoch 189, LR: 0.1250, Train Loss: 2.3032, Train Accuracy: 9.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.45e-02, Max: 4.25e-01, Min: -2.80e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.70e-04, Max: 1.75e-02, Min: -1.75e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.88e-04, Max: 1.55e-02, Min: -1.40e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.18e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 2.47e-02, Max: 4.14e-01, Min: -2.92e-01\n",
      "Epoch 190, LR: 0.1250, Train Loss: 2.3020, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.20%\n",
      "Latent Weights: - Mean Magnitude: 2.47e-02, Max: 4.14e-01, Min: -2.92e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.24e-04, Max: 1.77e-02, Min: -1.77e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.39e-03, Max: 1.18e-02, Min: -1.17e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.51e-03, Max: 1.39e-02, Min: -2.09e-02\n",
      "Latent Weights: - Mean Magnitude: 2.49e-02, Max: 4.21e-01, Min: -2.98e-01\n",
      "Epoch 191, LR: 0.1250, Train Loss: 2.3015, Train Accuracy: 11.37%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.49e-02, Max: 4.21e-01, Min: -2.98e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.88e-04, Max: 1.29e-02, Min: -1.29e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.14e-04, Max: 1.03e-02, Min: -1.04e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.76e-03, Max: 1.11e-02, Min: -1.11e-02\n",
      "Latent Weights: - Mean Magnitude: 2.51e-02, Max: 4.32e-01, Min: -3.09e-01\n",
      "Epoch 192, LR: 0.1250, Train Loss: 2.3012, Train Accuracy: 11.50%, Val Loss: 2.3118, Val Accuracy: 8.15%\n",
      "Latent Weights: - Mean Magnitude: 2.51e-02, Max: 4.32e-01, Min: -3.09e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.00e-04, Max: 1.13e-02, Min: -1.13e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.71e-03, Max: 8.78e-03, Min: -8.81e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.84e-03, Max: 8.99e-03, Min: -1.02e-02\n",
      "Latent Weights: - Mean Magnitude: 2.51e-02, Max: 4.26e-01, Min: -3.05e-01\n",
      "Epoch 193, LR: 0.1250, Train Loss: 2.3104, Train Accuracy: 8.18%, Val Loss: 2.3016, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.51e-02, Max: 4.26e-01, Min: -3.05e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.40e-04, Max: 1.62e-02, Min: -1.63e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.49e-04, Max: 1.33e-02, Min: -1.35e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.71e-03, Max: 1.61e-02, Min: -1.09e-02\n",
      "Latent Weights: - Mean Magnitude: 2.53e-02, Max: 4.37e-01, Min: -3.16e-01\n",
      "Epoch 194, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3016, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.53e-02, Max: 4.37e-01, Min: -3.16e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.56e-04, Max: 1.77e-02, Min: -1.77e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.21e-04, Max: 1.33e-02, Min: -1.37e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.76e-03, Max: 1.15e-02, Min: -1.05e-02\n",
      "Latent Weights: - Mean Magnitude: 2.56e-02, Max: 4.48e-01, Min: -3.27e-01\n",
      "Epoch 195, LR: 0.1250, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3016, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.56e-02, Max: 4.48e-01, Min: -3.27e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.71e-04, Max: 1.05e-02, Min: -1.82e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.67e-04, Max: 1.50e-02, Min: -1.88e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.79e-03, Max: 1.03e-02, Min: -1.39e-02\n",
      "Latent Weights: - Mean Magnitude: 2.60e-02, Max: 4.58e-01, Min: -3.37e-01\n",
      "Epoch 196, LR: 0.1250, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3088, Val Accuracy: 8.24%\n",
      "Latent Weights: - Mean Magnitude: 2.60e-02, Max: 4.58e-01, Min: -3.37e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.14e-03, Max: 8.80e-03, Min: -9.24e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 1.50e-03, Max: 9.22e-03, Min: -9.57e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 1.77e-03, Max: 2.51e-02, Min: -2.05e-02\n",
      "Latent Weights: - Mean Magnitude: 2.59e-02, Max: 4.51e-01, Min: -3.39e-01\n",
      "Epoch 197, LR: 0.1250, Train Loss: 2.3075, Train Accuracy: 9.10%, Val Loss: 2.2991, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.59e-02, Max: 4.51e-01, Min: -3.39e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.02e-03, Max: 1.55e-02, Min: -1.60e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.17e-03, Max: 1.16e-02, Min: -1.14e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.71e-03, Max: 3.11e-02, Min: -3.24e-02\n",
      "Latent Weights: - Mean Magnitude: 2.61e-02, Max: 4.54e-01, Min: -3.41e-01\n",
      "Epoch 198, LR: 0.1250, Train Loss: 2.2989, Train Accuracy: 11.50%, Val Loss: 2.3024, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.61e-02, Max: 4.54e-01, Min: -3.41e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.02e-03, Max: 2.00e-02, Min: -1.91e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.53e-04, Max: 1.99e-02, Min: -2.29e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.92e-03, Max: 3.43e-02, Min: -3.52e-02\n",
      "Latent Weights: - Mean Magnitude: 2.62e-02, Max: 4.61e-01, Min: -3.48e-01\n",
      "Epoch 199, LR: 0.1250, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.62e-02, Max: 4.61e-01, Min: -3.48e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.39e-04, Max: 1.46e-02, Min: -1.44e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.03e-03, Max: 1.10e-02, Min: -9.58e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.70e-03, Max: 1.20e-02, Min: -1.27e-02\n",
      "Latent Weights: - Mean Magnitude: 2.65e-02, Max: 4.73e-01, Min: -3.60e-01\n",
      "Epoch 200, LR: 0.1250, Train Loss: 2.3015, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.65e-02, Max: 4.73e-01, Min: -3.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.12e-04, Max: 1.32e-02, Min: -1.32e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.66e-04, Max: 1.31e-02, Min: -1.46e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.64e-03, Max: 1.23e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 2.67e-02, Max: 4.85e-01, Min: -3.72e-01\n",
      "Epoch 201, LR: 0.1250, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3043, Val Accuracy: 10.60%\n",
      "Latent Weights: - Mean Magnitude: 2.67e-02, Max: 4.85e-01, Min: -3.72e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.31e-03, Max: 1.58e-02, Min: -1.61e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.45e-03, Max: 9.16e-03, Min: -1.44e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.76e-02, Min: -1.66e-02\n",
      "Latent Weights: - Mean Magnitude: 2.67e-02, Max: 4.76e-01, Min: -3.67e-01\n",
      "Epoch 202, LR: 0.0625, Train Loss: 2.3046, Train Accuracy: 9.52%, Val Loss: 2.3012, Val Accuracy: 11.44%\n",
      "Latent Weights: - Mean Magnitude: 2.67e-02, Max: 4.76e-01, Min: -3.67e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.74e-04, Max: 1.19e-02, Min: -1.20e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.63e-03, Max: 8.53e-03, Min: -9.11e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.42e-03, Max: 1.57e-02, Min: -1.57e-02\n",
      "Latent Weights: - Mean Magnitude: 2.69e-02, Max: 4.86e-01, Min: -3.77e-01\n",
      "Epoch 203, LR: 0.0625, Train Loss: 2.3006, Train Accuracy: 11.73%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.69e-02, Max: 4.86e-01, Min: -3.77e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.60e-04, Max: 1.62e-02, Min: -1.88e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.62e-04, Max: 1.31e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.71e-03, Max: 1.14e-02, Min: -1.27e-02\n",
      "Latent Weights: - Mean Magnitude: 2.72e-02, Max: 4.98e-01, Min: -3.88e-01\n",
      "Epoch 204, LR: 0.0625, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.72e-02, Max: 4.98e-01, Min: -3.88e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.99e-04, Max: 1.65e-02, Min: -1.58e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.42e-04, Max: 1.42e-02, Min: -1.57e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.24e-02, Min: -1.19e-02\n",
      "Latent Weights: - Mean Magnitude: 2.74e-02, Max: 4.86e-01, Min: -4.00e-01\n",
      "Epoch 205, LR: 0.0625, Train Loss: 2.3016, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.74e-02, Max: 4.86e-01, Min: -4.00e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.19e-04, Max: 4.58e-02, Min: -8.29e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 5.94e-04, Max: 1.43e-02, Min: -1.41e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 2.77e-02, Max: 4.75e-01, Min: -4.12e-01\n",
      "Epoch 206, LR: 0.0625, Train Loss: 2.3012, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.77e-02, Max: 4.75e-01, Min: -4.12e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.63e-04, Max: 1.52e-02, Min: -1.84e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.60e-04, Max: 1.30e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.58e-03, Max: 1.14e-02, Min: -1.54e-02\n",
      "Latent Weights: - Mean Magnitude: 2.79e-02, Max: 4.63e-01, Min: -4.23e-01\n",
      "Epoch 207, LR: 0.0625, Train Loss: 2.3013, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.79e-02, Max: 4.63e-01, Min: -4.23e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.76e-04, Max: 2.23e-02, Min: -1.39e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.77e-04, Max: 1.69e-02, Min: -1.89e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.61e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 2.81e-02, Max: 4.61e-01, Min: -4.35e-01\n",
      "Epoch 208, LR: 0.0625, Train Loss: 2.3012, Train Accuracy: 11.50%, Val Loss: 2.3016, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.81e-02, Max: 4.61e-01, Min: -4.35e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.67e-04, Max: 1.82e-02, Min: -2.19e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.20e-04, Max: 1.58e-02, Min: -1.37e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.17e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 2.84e-02, Max: 4.73e-01, Min: -4.46e-01\n",
      "Epoch 209, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.84e-02, Max: 4.73e-01, Min: -4.46e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.19e-04, Max: 1.70e-02, Min: -1.56e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.84e-04, Max: 1.97e-02, Min: -2.87e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.14e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 2.87e-02, Max: 4.84e-01, Min: -4.58e-01\n",
      "Epoch 210, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.87e-02, Max: 4.84e-01, Min: -4.58e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.46e-04, Max: 1.73e-02, Min: -1.49e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.59e-04, Max: 1.80e-02, Min: -1.54e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.63e-03, Max: 1.18e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 2.89e-02, Max: 4.96e-01, Min: -4.70e-01\n",
      "Epoch 211, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.89e-02, Max: 4.96e-01, Min: -4.70e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.71e-04, Max: 1.09e-02, Min: -6.30e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.32e-04, Max: 1.52e-02, Min: -1.50e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.76e-03, Max: 1.08e-02, Min: -1.08e-02\n",
      "Latent Weights: - Mean Magnitude: 2.92e-02, Max: 5.07e-01, Min: -4.80e-01\n",
      "Epoch 212, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.92e-02, Max: 5.07e-01, Min: -4.80e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.47e-04, Max: 1.23e-02, Min: -1.23e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.74e-04, Max: 1.35e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.84e-03, Max: 1.04e-02, Min: -1.04e-02\n",
      "Latent Weights: - Mean Magnitude: 2.95e-02, Max: 5.17e-01, Min: -4.91e-01\n",
      "Epoch 213, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.95e-02, Max: 5.17e-01, Min: -4.91e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.81e-04, Max: 1.62e-02, Min: -1.62e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.42e-04, Max: 1.35e-02, Min: -1.53e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 3.12e-03, Max: 7.91e-03, Min: -7.91e-03\n",
      "Latent Weights: - Mean Magnitude: 2.98e-02, Max: 5.25e-01, Min: -4.98e-01\n",
      "Epoch 214, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.98e-02, Max: 5.25e-01, Min: -4.98e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.37e-04, Max: 1.94e-02, Min: -1.55e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.31e-04, Max: 2.77e-02, Min: -2.20e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.84e-03, Max: 2.17e-02, Min: -2.20e-02\n",
      "Latent Weights: - Mean Magnitude: 2.96e-02, Max: 5.17e-01, Min: -4.90e-01\n",
      "Epoch 215, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.96e-02, Max: 5.17e-01, Min: -4.90e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.46e-04, Max: 1.74e-02, Min: -1.74e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.16e-04, Max: 3.15e-02, Min: -3.14e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.55e-03, Max: 1.13e-02, Min: -1.13e-02\n",
      "Latent Weights: - Mean Magnitude: 2.98e-02, Max: 5.28e-01, Min: -5.02e-01\n",
      "Epoch 216, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.98e-02, Max: 5.28e-01, Min: -5.02e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.03e-04, Max: 1.50e-02, Min: -1.50e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.63e-04, Max: 1.37e-02, Min: -1.35e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.43e-03, Max: 1.20e-02, Min: -1.20e-02\n",
      "Latent Weights: - Mean Magnitude: 2.97e-02, Max: 5.16e-01, Min: -4.90e-01\n",
      "Epoch 217, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.97e-02, Max: 5.16e-01, Min: -4.90e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.21e-04, Max: 1.52e-02, Min: -1.52e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.78e-04, Max: 1.41e-02, Min: -1.65e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.41e-03, Max: 1.25e-02, Min: -2.13e-02\n",
      "Latent Weights: - Mean Magnitude: 2.99e-02, Max: 5.29e-01, Min: -5.02e-01\n",
      "Epoch 218, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 2.99e-02, Max: 5.29e-01, Min: -5.02e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.45e-04, Max: 1.44e-02, Min: -1.44e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.85e-04, Max: 1.45e-02, Min: -1.04e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 3.05e-03, Max: 8.20e-03, Min: -8.20e-03\n",
      "Latent Weights: - Mean Magnitude: 3.01e-02, Max: 5.35e-01, Min: -5.09e-01\n",
      "Epoch 219, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.01e-02, Max: 5.35e-01, Min: -5.09e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.16e-04, Max: 1.41e-02, Min: -1.41e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.59e-04, Max: 1.64e-02, Min: -1.39e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.77e-03, Max: 9.29e-03, Min: -9.29e-03\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 5.44e-01, Min: -5.18e-01\n",
      "Epoch 220, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 5.44e-01, Min: -5.18e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.47e-04, Max: 1.35e-02, Min: -1.35e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.35e-04, Max: 1.96e-02, Min: -2.65e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.85e-03, Max: 1.03e-02, Min: -8.87e-03\n",
      "Latent Weights: - Mean Magnitude: 3.06e-02, Max: 5.53e-01, Min: -5.26e-01\n",
      "Epoch 221, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.06e-02, Max: 5.53e-01, Min: -5.26e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.00e-04, Max: 1.25e-02, Min: -1.25e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.55e-04, Max: 1.69e-02, Min: -1.73e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.73e-03, Max: 1.12e-02, Min: -1.34e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.41e-01, Min: -5.15e-01\n",
      "Epoch 222, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3005, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.41e-01, Min: -5.15e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.10e-03, Max: 1.08e-02, Min: -1.07e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.08e-03, Max: 1.31e-02, Min: -1.31e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.59e-03, Max: 1.70e-02, Min: -1.82e-02\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 5.41e-01, Min: -5.15e-01\n",
      "Epoch 223, LR: 0.0625, Train Loss: 2.2998, Train Accuracy: 11.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 5.41e-01, Min: -5.15e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.31e-04, Max: 1.56e-02, Min: -1.56e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.97e-04, Max: 1.34e-02, Min: -1.39e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.25e-02, Min: -1.25e-02\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 5.29e-01, Min: -5.02e-01\n",
      "Epoch 224, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3012, Val Accuracy: 11.46%\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 5.29e-01, Min: -5.02e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.77e-04, Max: 1.10e-02, Min: -1.09e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.40e-03, Max: 1.17e-02, Min: -1.10e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.02e-03, Max: 1.79e-02, Min: -2.49e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.33e-01, Min: -5.09e-01\n",
      "Epoch 225, LR: 0.0625, Train Loss: 2.2997, Train Accuracy: 11.77%, Val Loss: 2.3043, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.33e-01, Min: -5.09e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.24e-03, Max: 1.30e-02, Min: -1.30e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.62e-04, Max: 2.57e-02, Min: -1.05e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.51e-03, Max: 1.70e-02, Min: -1.64e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.24e-01, Min: -4.99e-01\n",
      "Epoch 226, LR: 0.0625, Train Loss: 2.3054, Train Accuracy: 9.37%, Val Loss: 2.3003, Val Accuracy: 11.46%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.24e-01, Min: -4.99e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.01e-03, Max: 1.40e-02, Min: -1.28e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.51e-03, Max: 9.54e-03, Min: -1.43e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.27e-03, Max: 1.26e-02, Min: -1.48e-02\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 5.27e-01, Min: -5.02e-01\n",
      "Epoch 227, LR: 0.0625, Train Loss: 2.2998, Train Accuracy: 11.20%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 5.27e-01, Min: -5.02e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.19e-03, Max: 9.18e-03, Min: -8.86e-03\n",
      "Layer 2 Gradients - Mean Magnitude: 6.88e-04, Max: 1.45e-02, Min: -1.40e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.20e-03, Max: 9.48e-03, Min: -3.76e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.19e-01, Min: -4.93e-01\n",
      "Epoch 228, LR: 0.0625, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3046, Val Accuracy: 10.49%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.19e-01, Min: -4.93e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.34e-03, Max: 1.33e-02, Min: -1.17e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.53e-04, Max: 1.44e-02, Min: -1.33e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.58e-03, Max: 1.19e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.07e-01, Min: -4.81e-01\n",
      "Epoch 229, LR: 0.0625, Train Loss: 2.3054, Train Accuracy: 9.35%, Val Loss: 2.3043, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 5.07e-01, Min: -4.81e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.60e-04, Max: 1.88e-02, Min: -1.88e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.71e-04, Max: 1.27e-02, Min: -1.28e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.19e-02, Min: -1.22e-02\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 4.95e-01, Min: -4.69e-01\n",
      "Epoch 230, LR: 0.0625, Train Loss: 2.3048, Train Accuracy: 9.37%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 4.95e-01, Min: -4.69e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.30e-03, Max: 9.75e-03, Min: -1.06e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.56e-04, Max: 1.29e-02, Min: -1.31e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.16e-03, Max: 2.98e-02, Min: -3.00e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.96e-01, Min: -4.71e-01\n",
      "Epoch 231, LR: 0.0625, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3040, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.96e-01, Min: -4.71e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 7.13e-04, Max: 2.17e-02, Min: -1.83e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 9.38e-04, Max: 1.10e-02, Min: -1.10e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 4.85e-01, Min: -4.59e-01\n",
      "Epoch 232, LR: 0.0625, Train Loss: 2.3044, Train Accuracy: 9.37%, Val Loss: 2.3034, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.03e-02, Max: 4.85e-01, Min: -4.59e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.93e-04, Max: 1.89e-02, Min: -1.89e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.69e-04, Max: 1.46e-02, Min: -1.55e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.73e-01, Min: -4.62e-01\n",
      "Epoch 233, LR: 0.0625, Train Loss: 2.3037, Train Accuracy: 9.37%, Val Loss: 2.3032, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.73e-01, Min: -4.62e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.07e-04, Max: 1.54e-02, Min: -1.54e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.18e-04, Max: 1.36e-02, Min: -1.55e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.61e-01, Min: -4.73e-01\n",
      "Epoch 234, LR: 0.0625, Train Loss: 2.3034, Train Accuracy: 9.37%, Val Loss: 2.3031, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.04e-02, Max: 4.61e-01, Min: -4.73e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.21e-04, Max: 1.68e-02, Min: -1.68e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.70e-04, Max: 1.36e-02, Min: -1.34e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.18e-02, Min: -1.18e-02\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 4.50e-01, Min: -4.85e-01\n",
      "Epoch 235, LR: 0.0625, Train Loss: 2.3033, Train Accuracy: 9.38%, Val Loss: 2.3029, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 4.50e-01, Min: -4.85e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.26e-04, Max: 1.69e-02, Min: -1.69e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.68e-04, Max: 1.63e-02, Min: -1.59e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 4.38e-01, Min: -4.97e-01\n",
      "Epoch 236, LR: 0.0625, Train Loss: 2.3030, Train Accuracy: 9.38%, Val Loss: 2.2916, Val Accuracy: 16.99%\n",
      "Latent Weights: - Mean Magnitude: 3.05e-02, Max: 4.38e-01, Min: -4.97e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.21e-03, Max: 1.45e-02, Min: -1.46e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.15e-03, Max: 1.01e-02, Min: -1.01e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.49e-03, Max: 9.47e-03, Min: -9.39e-03\n",
      "Latent Weights: - Mean Magnitude: 3.07e-02, Max: 4.47e-01, Min: -5.02e-01\n",
      "Epoch 237, LR: 0.0625, Train Loss: 2.2920, Train Accuracy: 16.58%, Val Loss: 2.3009, Val Accuracy: 11.54%\n",
      "Latent Weights: - Mean Magnitude: 3.07e-02, Max: 4.47e-01, Min: -5.02e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.95e-04, Max: 1.05e-02, Min: -1.13e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.17e-03, Max: 2.68e-02, Min: -2.71e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 1.71e-03, Max: 2.86e-02, Min: -1.50e-02\n",
      "Latent Weights: - Mean Magnitude: 3.08e-02, Max: 4.61e-01, Min: -5.08e-01\n",
      "Epoch 238, LR: 0.0625, Train Loss: 2.3003, Train Accuracy: 12.05%, Val Loss: 2.3025, Val Accuracy: 11.32%\n",
      "Latent Weights: - Mean Magnitude: 3.08e-02, Max: 4.61e-01, Min: -5.08e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 5.18e-04, Max: 2.18e-02, Min: -1.35e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 8.82e-04, Max: 1.04e-02, Min: -1.04e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.19e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.09e-02, Max: 4.72e-01, Min: -4.96e-01\n",
      "Epoch 239, LR: 0.0625, Train Loss: 2.3025, Train Accuracy: 11.35%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.09e-02, Max: 4.72e-01, Min: -4.96e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.28e-04, Max: 1.75e-02, Min: -1.75e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.36e-04, Max: 1.39e-02, Min: -1.32e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.20e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.10e-02, Max: 4.84e-01, Min: -5.08e-01\n",
      "Epoch 240, LR: 0.0625, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3059, Val Accuracy: 9.39%\n",
      "Latent Weights: - Mean Magnitude: 3.10e-02, Max: 4.84e-01, Min: -5.08e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.29e-04, Max: 1.51e-02, Min: -1.51e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.63e-03, Max: 1.26e-02, Min: -1.15e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.10e-02, Min: -1.20e-02\n",
      "Latent Weights: - Mean Magnitude: 3.09e-02, Max: 4.75e-01, Min: -4.99e-01\n",
      "Epoch 241, LR: 0.0625, Train Loss: 2.3058, Train Accuracy: 8.58%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.09e-02, Max: 4.75e-01, Min: -4.99e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 1.06e-03, Max: 1.04e-02, Min: -1.04e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.35e-03, Max: 1.05e-02, Min: -8.66e-03\n",
      "Layer 3 Gradients - Mean Magnitude: 2.15e-03, Max: 2.56e-02, Min: -2.62e-02\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.79e-01, Min: -5.03e-01\n",
      "Epoch 242, LR: 0.0625, Train Loss: 2.3007, Train Accuracy: 11.50%, Val Loss: 2.3036, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.79e-01, Min: -5.03e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 9.39e-04, Max: 1.14e-02, Min: -1.14e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 6.43e-04, Max: 1.35e-02, Min: -1.35e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.52e-03, Max: 1.41e-02, Min: -2.40e-02\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.69e-01, Min: -5.13e-01\n",
      "Epoch 243, LR: 0.0625, Train Loss: 2.3037, Train Accuracy: 9.37%, Val Loss: 2.3045, Val Accuracy: 9.28%\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.69e-01, Min: -5.13e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.98e-04, Max: 1.41e-02, Min: -1.45e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 1.47e-03, Max: 1.29e-02, Min: -1.34e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.31e-03, Max: 1.92e-02, Min: -1.97e-02\n",
      "Latent Weights: - Mean Magnitude: 3.11e-02, Max: 4.58e-01, Min: -5.19e-01\n",
      "Epoch 244, LR: 0.0625, Train Loss: 2.3049, Train Accuracy: 8.30%, Val Loss: 2.3032, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.11e-02, Max: 4.58e-01, Min: -5.19e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.43e-04, Max: 1.60e-02, Min: -1.60e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.59e-04, Max: 1.87e-02, Min: -1.33e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.63e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.11e-02, Max: 4.46e-01, Min: -5.31e-01\n",
      "Epoch 245, LR: 0.0625, Train Loss: 2.3034, Train Accuracy: 9.37%, Val Loss: 2.3031, Val Accuracy: 10.32%\n",
      "Latent Weights: - Mean Magnitude: 3.11e-02, Max: 4.46e-01, Min: -5.31e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.45e-04, Max: 1.52e-02, Min: -1.52e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.66e-04, Max: 1.67e-02, Min: -1.54e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.62e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.34e-01, Min: -5.43e-01\n",
      "Epoch 246, LR: 0.0625, Train Loss: 2.3032, Train Accuracy: 9.37%, Val Loss: 2.3027, Val Accuracy: 10.09%\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.34e-01, Min: -5.43e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.48e-04, Max: 1.75e-02, Min: -1.75e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.35e-04, Max: 1.64e-02, Min: -1.41e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.23e-01, Min: -5.55e-01\n",
      "Epoch 247, LR: 0.0625, Train Loss: 2.3027, Train Accuracy: 9.97%, Val Loss: 2.3025, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.12e-02, Max: 4.23e-01, Min: -5.55e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.64e-04, Max: 1.74e-02, Min: -1.74e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.56e-04, Max: 2.31e-02, Min: -1.33e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.13e-02, Max: 4.11e-01, Min: -5.66e-01\n",
      "Epoch 248, LR: 0.0625, Train Loss: 2.3025, Train Accuracy: 11.50%, Val Loss: 2.3024, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.13e-02, Max: 4.11e-01, Min: -5.66e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 4.65e-04, Max: 1.57e-02, Min: -1.57e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.49e-04, Max: 1.35e-02, Min: -1.34e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.14e-02, Max: 3.99e-01, Min: -5.78e-01\n",
      "Epoch 249, LR: 0.0625, Train Loss: 2.3023, Train Accuracy: 11.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.14e-02, Max: 3.99e-01, Min: -5.78e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.36e-04, Max: 1.76e-02, Min: -1.76e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.55e-04, Max: 1.71e-02, Min: -1.72e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.15e-02, Max: 3.88e-01, Min: -5.90e-01\n",
      "Epoch 250, LR: 0.0625, Train Loss: 2.3019, Train Accuracy: 11.50%, Val Loss: 2.3022, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.15e-02, Max: 3.88e-01, Min: -5.90e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 6.19e-04, Max: 1.41e-02, Min: -1.41e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.52e-04, Max: 1.77e-02, Min: -1.67e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.16e-02, Max: 3.76e-01, Min: -6.01e-01\n",
      "Epoch 251, LR: 0.0625, Train Loss: 2.3020, Train Accuracy: 11.50%, Val Loss: 2.3021, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.16e-02, Max: 3.76e-01, Min: -6.01e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 2.85e-04, Max: 1.78e-02, Min: -1.78e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.55e-04, Max: 1.28e-02, Min: -1.28e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.18e-02, Max: 3.64e-01, Min: -6.13e-01\n",
      "Epoch 252, LR: 0.0312, Train Loss: 2.3019, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.18e-02, Max: 3.64e-01, Min: -6.13e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.20e-04, Max: 1.76e-02, Min: -1.76e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.62e-04, Max: 1.56e-02, Min: -1.54e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.17e-02, Min: -1.17e-02\n",
      "Latent Weights: - Mean Magnitude: 3.19e-02, Max: 3.53e-01, Min: -6.25e-01\n",
      "Epoch 253, LR: 0.0312, Train Loss: 2.3017, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.19e-02, Max: 3.53e-01, Min: -6.25e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.88e-04, Max: 1.71e-02, Min: -1.71e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.60e-04, Max: 1.69e-02, Min: -1.49e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 3.20e-02, Max: 3.41e-01, Min: -6.36e-01\n",
      "Epoch 254, LR: 0.0312, Train Loss: 2.3016, Train Accuracy: 11.50%, Val Loss: 2.3022, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.20e-02, Max: 3.41e-01, Min: -6.36e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.04e-04, Max: 1.78e-02, Min: -1.78e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 7.73e-04, Max: 1.76e-02, Min: -1.66e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 3.21e-02, Max: 3.37e-01, Min: -6.48e-01\n",
      "Epoch 255, LR: 0.0312, Train Loss: 2.3020, Train Accuracy: 11.50%, Val Loss: 2.3020, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.21e-02, Max: 3.37e-01, Min: -6.48e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.48e-04, Max: 1.74e-02, Min: -1.74e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.71e-04, Max: 1.34e-02, Min: -1.29e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.63e-03, Max: 1.22e-02, Min: -1.19e-02\n",
      "Latent Weights: - Mean Magnitude: 3.22e-02, Max: 3.42e-01, Min: -6.45e-01\n",
      "Epoch 256, LR: 0.0312, Train Loss: 2.3017, Train Accuracy: 11.52%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.22e-02, Max: 3.42e-01, Min: -6.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 3.69e-04, Max: 1.72e-02, Min: -1.72e-02\n",
      "Layer 2 Gradients - Mean Magnitude: 5.37e-04, Max: 2.37e-02, Min: -1.77e-02\n",
      "Layer 3 Gradients - Mean Magnitude: 2.65e-03, Max: 1.22e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 3.23e-02, Max: 3.47e-01, Min: -6.57e-01\n",
      "Epoch 257, LR: 0.0312, Train Loss: 2.3013, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.23e-02, Max: 3.47e-01, Min: -6.57e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.16e-02, Min: -1.16e-02\n",
      "Latent Weights: - Mean Magnitude: 3.24e-02, Max: 3.52e-01, Min: -6.69e-01\n",
      "Epoch 258, LR: 0.0312, Train Loss: 2.3012, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.24e-02, Max: 3.52e-01, Min: -6.69e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 3.25e-02, Max: 3.57e-01, Min: -6.80e-01\n",
      "Epoch 259, LR: 0.0312, Train Loss: 2.3011, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.25e-02, Max: 3.57e-01, Min: -6.80e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.66e-03, Max: 1.15e-02, Min: -1.15e-02\n",
      "Latent Weights: - Mean Magnitude: 3.26e-02, Max: 3.62e-01, Min: -6.92e-01\n",
      "Epoch 260, LR: 0.0312, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.26e-02, Max: 3.62e-01, Min: -6.92e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.14e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 3.27e-02, Max: 3.68e-01, Min: -7.03e-01\n",
      "Epoch 261, LR: 0.0312, Train Loss: 2.3010, Train Accuracy: 11.50%, Val Loss: 2.3016, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.27e-02, Max: 3.68e-01, Min: -7.03e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.67e-03, Max: 1.14e-02, Min: -1.14e-02\n",
      "Latent Weights: - Mean Magnitude: 3.28e-02, Max: 3.73e-01, Min: -7.14e-01\n",
      "Epoch 262, LR: 0.0312, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.28e-02, Max: 3.73e-01, Min: -7.14e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.68e-03, Max: 1.13e-02, Min: -1.13e-02\n",
      "Latent Weights: - Mean Magnitude: 3.29e-02, Max: 3.78e-01, Min: -7.26e-01\n",
      "Epoch 263, LR: 0.0312, Train Loss: 2.3009, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.29e-02, Max: 3.78e-01, Min: -7.26e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.70e-03, Max: 1.11e-02, Min: -1.11e-02\n",
      "Latent Weights: - Mean Magnitude: 3.31e-02, Max: 3.83e-01, Min: -7.37e-01\n",
      "Epoch 264, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.31e-02, Max: 3.83e-01, Min: -7.37e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.73e-03, Max: 1.09e-02, Min: -1.09e-02\n",
      "Latent Weights: - Mean Magnitude: 3.32e-02, Max: 3.89e-01, Min: -7.48e-01\n",
      "Epoch 265, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3017, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.32e-02, Max: 3.89e-01, Min: -7.48e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.79e-03, Max: 1.04e-02, Min: -1.04e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.95e-01, Min: -7.58e-01\n",
      "Epoch 266, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.95e-01, Min: -7.58e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 3.06e-03, Max: 8.62e-03, Min: -8.62e-03\n",
      "Latent Weights: - Mean Magnitude: 3.35e-02, Max: 4.03e-01, Min: -7.55e-01\n",
      "Epoch 267, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3019, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.35e-02, Max: 4.03e-01, Min: -7.55e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 3.08e-03, Max: 8.19e-03, Min: -8.19e-03\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.95e-01, Min: -7.59e-01\n",
      "Epoch 268, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.95e-01, Min: -7.59e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.80e-03, Max: 9.10e-03, Min: -9.10e-03\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.98e-01, Min: -7.50e-01\n",
      "Epoch 269, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.98e-01, Min: -7.50e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.69e-03, Max: 9.57e-03, Min: -9.57e-03\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.59e-01\n",
      "Epoch 270, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.59e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 1.94e-03, Max: 1.31e-02, Min: -1.31e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Epoch 271, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 1.96e-03, Max: 1.32e-02, Min: -1.32e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 272, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.05e-03, Max: 1.39e-02, Min: -1.39e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Epoch 273, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.05e-03, Max: 1.39e-02, Min: -1.39e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 274, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.40e-02, Min: -1.40e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Epoch 275, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.46e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.40e-02, Min: -1.40e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 276, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 277, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 278, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 279, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 280, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 281, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 282, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 283, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 284, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 285, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 286, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 287, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 288, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 289, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 290, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 291, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 292, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 293, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 294, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 295, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 296, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.09e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 297, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 298, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Epoch 299, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n",
      "Latent Weights: - Mean Magnitude: 3.33e-02, Max: 3.95e-01, Min: -7.45e-01\n",
      "Layer 1 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 2 Gradients - Mean Magnitude: 0.00e+00, Max: 0.00e+00, Min: 0.00e+00\n",
      "Layer 3 Gradients - Mean Magnitude: 2.08e-03, Max: 1.41e-02, Min: -1.41e-02\n",
      "Latent Weights: - Mean Magnitude: 3.34e-02, Max: 3.96e-01, Min: -7.60e-01\n",
      "Epoch 300, LR: 0.0312, Train Loss: 2.3008, Train Accuracy: 11.50%, Val Loss: 2.3018, Val Accuracy: 11.35%\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "lr = params_RRAM[\"lr\"] / 25  # Initial learning rate\n",
    "num_epochs = params_RRAM[\"epochs\"]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch == 1:\n",
    "        lr *= 5\n",
    "    elif epoch == 2:\n",
    "        lr *= 5\n",
    "\n",
    "    model_RRAM.train()\n",
    "    outputs = model_RRAM(train_in)\n",
    "    loss = criterion(outputs, train_lab)\n",
    "    loss.backward()\n",
    "    model_RRAM.backprop(lr)\n",
    "\n",
    "    _, train_preds = torch.max(outputs, dim=1)\n",
    "    train_accuracy = (train_preds == train_lab).float().mean().item() * 100\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    model_RRAM.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_RRAM(val_in)\n",
    "        val_loss = criterion(val_outputs, val_lab).item()\n",
    "        _, val_preds = torch.max(val_outputs, dim=1)\n",
    "        val_accuracy = (val_preds == val_lab).float().mean().item() * 100\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {loss.item():.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Learning rate adjustment\n",
    "    if epoch % 50 == 0 and epoch != 0:\n",
    "        lr /= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "786757d6-3ef8-4327-900a-94924d5a1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RRAM.monitor_grads = False\n",
    "model_RRAM.monitor_volts = False\n",
    "model_RRAM.monitor_latents = False\n",
    "model_RRAM.bin_active = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc53685-ceb0-4b1c-a03f-04ca24416013",
   "metadata": {},
   "source": [
    "### Complete Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, LR: 0.0400, Train Loss: 2.3015, Train Accuracy: 11.24%, Test Loss: 2.3013, Test Accuracy: 11.35%\n",
      "Epoch 2, LR: 0.2000, Train Loss: 2.3013, Train Accuracy: 11.24%, Test Loss: 2.3011, Test Accuracy: 11.35%\n",
      "Epoch 3, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 4, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 5, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 6, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 7, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 8, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 9, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3011, Test Accuracy: 11.35%\n",
      "Epoch 10, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 11, LR: 1.0000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 12, LR: 0.5000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n",
      "Epoch 13, LR: 0.5000, Train Loss: 2.3012, Train Accuracy: 11.24%, Test Loss: 2.3010, Test Accuracy: 11.35%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m total_test_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_inputs, test_labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     45\u001b[0m         test_inputs \u001b[38;5;241m=\u001b[39m test_inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m         test_labels \u001b[38;5;241m=\u001b[39m test_labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:170\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 170\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = params_RRAM[\"lr\"]\n",
    "num_epochs = params_RRAM[\"epochs\"]\n",
    "# lr = 0.1\n",
    "# num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch == 0:\n",
    "        lr /= 25\n",
    "    elif epoch <= 2:\n",
    "        lr *= 5\n",
    "\n",
    "    model_RRAM.train()\n",
    "    model_RRAM.to(device)\n",
    "\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_RRAM(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        model_RRAM.backprop(lr)\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        train_accuracy += (predictions == labels).sum().item()\n",
    "        total_samples += inputs.size(0)\n",
    "        \n",
    "\n",
    "    train_loss /= total_samples\n",
    "    train_accuracy = (train_accuracy / total_samples) * 100\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    model_RRAM.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    total_test_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs = test_inputs.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "\n",
    "            test_outputs = model_RRAM(test_inputs)\n",
    "            loss = criterion(test_outputs, test_labels)\n",
    "\n",
    "            test_loss += loss.item() * test_inputs.size(0)\n",
    "            _, test_predictions = torch.max(test_outputs, dim=1)\n",
    "            test_accuracy += (test_predictions == test_labels).sum().item()\n",
    "            total_test_samples += test_inputs.size(0)\n",
    "            \n",
    "\n",
    "    test_loss /= total_test_samples\n",
    "    test_accuracy = (test_accuracy / total_test_samples) * 100\n",
    "\n",
    "    history_RRAM[\"train_loss\"].append(train_loss)\n",
    "    history_RRAM[\"train_accuracy\"].append(train_accuracy)\n",
    "    history_RRAM[\"val_loss\"].append(test_loss)\n",
    "    history_RRAM[\"val_accuracy\"].append(test_accuracy)\n",
    "\n",
    "    if test_accuracy > val_best:\n",
    "        val_best = test_accuracy\n",
    "        torch.save(model_RRAM.state_dict(), f\"Best_model.pth\")\n",
    "        with open(f\"Best_Val_Accuracy.txt\", \"w\") as f: \n",
    "            f.write(f\"{val_best:.6f}\")\n",
    "        with open(f\"Best_Params.txt\", \"w\") as f: \n",
    "            f.write(f\"{params_RRAM}\")\n",
    "        print(f\"Model saved with Validation Accuracy: {val_best:.6f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    if (epoch) % (10) == 0 and epoch != 0:\n",
    "        lr /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_RRAM, num_epochs, \"RRAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb",
   "metadata": {},
   "source": [
    "### Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51271c7c-25b1-4702-9db1-9ae4b805843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0 + (model_RRAM.w > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d477c9e-5678-4d07-a5ac-48f01480c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = test(model_RRAM, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7941df-4678-4955-8a0f-f38b43f6b197",
   "metadata": {},
   "source": [
    "## Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867574d7-3627-49ff-a430-1d658fa4d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "0+1*(model_best.w>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = test(model_best, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce",
   "metadata": {},
   "source": [
    "## PWL Generation\n",
    "\n",
    "Let's assume that we will program the two crossbars with seperate PWLs. That is, during programming, we will cut the Inverting Amplifier stages with a pass transistor and connect the programming lines with a pass transistor. First array has 16 Top PWLs and 8 Bottom PWLs. Second array has 8 Top PWLs and 4 Bottom PWLs. And then once the programming switch is toggled to inference mode, only the 16 Top PWLs are to be changed. Let's also generate a PWL for that too.\n",
    "\n",
    "In the code below, we will first maintain tuples for each PWL that holds what the voltage should be. And then we will write a function that will take there and space pulses of the given voltage that are 100us apart from other and have an ON duration of 100us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_FC1 = [list() for i in range(16)]\n",
    "BL_FC1 = [list() for i in range(8)]\n",
    "WL_FC2 = [list() for i in range(8)]\n",
    "BL_FC2 = [list() for i in range(4)]\n",
    "Mode = []\n",
    "Mode_B = []\n",
    "\n",
    "V_WRITE = 1.5\n",
    "V_READ = 0.1\n",
    "V_mode = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647afda-e1a7-47a7-b634-212ec5527be2",
   "metadata": {},
   "source": [
    "#### Fully Connected Weights 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03334172-89f6-4d73-9461-6ac922bdb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (model_RRAM_best.w1>0).int()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49287afe-8437-40aa-8825-93f2cffe3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_i, i in enumerate(target):\n",
    "    for ind_j, j in enumerate(i):\n",
    "        if j==1: WL_FC1[ind_j].append(V_WRITE)\n",
    "        else: WL_FC1[ind_j].append(V_WRITE/3)\n",
    "    for ind_k in range(len(target)): \n",
    "        if ind_k==ind_i: BL_FC1[ind_i].append(0)\n",
    "        else: BL_FC1[ind_k].append(2*V_WRITE/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77131c-005d-4f06-8a70-f40d267eb67e",
   "metadata": {},
   "source": [
    "#### Fully Connected Weights 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (model_RRAM_best.w2>0).int()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_i, i in enumerate(target):\n",
    "    for ind_j, j in enumerate(i):\n",
    "        if j==1: WL_FC2[ind_j].append(V_WRITE)\n",
    "        else: WL_FC2[ind_j].append(V_WRITE/3)\n",
    "    for ind_k in range(len(target)): \n",
    "        if ind_k==ind_i: BL_FC2[ind_i].append(0)\n",
    "        else: BL_FC2[ind_k].append(2*V_WRITE/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602368f-07a2-4beb-90e3-d782ca717fea",
   "metadata": {},
   "source": [
    "#### Filling Out Programming Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_FC1 = [i + [0,0] for i in WL_FC1]\n",
    "BL_FC1 = [i + [0,0] for i in BL_FC1]\n",
    "while(len(WL_FC2[0]) < len(WL_FC1[0])):\n",
    "    WL_FC2 = [i + [0,] for i in WL_FC2]\n",
    "    BL_FC2 = [i + [0,] for i in BL_FC2]\n",
    "Mode.extend([V_mode]*(len(WL_FC1[0])-1) + [-V_mode])\n",
    "Mode_B.extend([-V_mode]*(len(WL_FC1[0])-1) + [V_mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953198a-a107-428c-9624-3c712086e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WL_FC1[0])\n",
    "print(BL_FC1[0])\n",
    "print(WL_FC2[0])\n",
    "print(BL_FC2[0])\n",
    "print(Mode)\n",
    "print(Mode_B)\n",
    "print(len(WL_FC1[0]), len(BL_FC1[0]), len(WL_FC2[0]), len(BL_FC2[0]), len(Mode), len(Mode_B)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92339f84-e8d6-4280-92af-e5215aa129a0",
   "metadata": {},
   "source": [
    "### Inference: Loading the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_1 = 0.1\n",
    "V_0 = -0.1\n",
    "include_testing = True\n",
    "include_every = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_testing:\n",
    "    for i in val_inputs[::include_every]:\n",
    "        i = i.flatten()\n",
    "        for ind, j in enumerate(i):\n",
    "            WL_FC1[ind].append(V_1 if j==1 else V_0)\n",
    "        BL_FC1 = [i + [0,] for i in BL_FC1]\n",
    "        WL_FC2 = [i + [0,] for i in WL_FC2]\n",
    "        BL_FC2 = [i + [0,] for i in BL_FC2]\n",
    "        Mode = Mode + [-V_mode,]\n",
    "        Mode_B = Mode_B + [V_mode,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c",
   "metadata": {},
   "source": [
    "### PWL Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af5ff-8f34-4472-89fc-e308d98d4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pwl(l):\n",
    "    t = 0\n",
    "    res = \"pwl(time, 0us, 0V\"\n",
    "    for i in l:\n",
    "        res += f\", {t+5}us, {i:.2f}V, {t+100}us, {i:.2f}V, {t+105}us, 0V, {t+200}us, 0V\"\n",
    "        t+=200\n",
    "    res += \")\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54850dbc-1317-44a2-9093-c5a4e048094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwl_data = []\n",
    "\n",
    "for ind, i in enumerate(WL_FC1):\n",
    "    pwl_data.append({\"Signal\": f\"WL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(BL_FC1):\n",
    "    pwl_data.append({\"Signal\": f\"BL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(WL_FC2):\n",
    "    pwl_data.append({\"Signal\": f\"WL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(BL_FC2):\n",
    "    pwl_data.append({\"Signal\": f\"BL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "pwl_data.append({\"Signal\": \"Mode\", \"Index\": \"\", \"PWL\": pwl(Mode)})\n",
    "pwl_data.append({\"Signal\": \"Mode_b\", \"Index\": \"\", \"PWL\": pwl(Mode_B)})\n",
    "\n",
    "pwl_data = pd.DataFrame(pwl_data)\n",
    "pwl_data.to_csv(\"pwl_data.csv\", index=False)\n",
    "pwl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174",
   "metadata": {},
   "source": [
    "#### Testing Accuracy on 160 Images\n",
    "ADS isn't allowing PWLs longer than 160 Images, so let's check software accuracy for the same too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_RRAM_best, val_inputs[::4], val_labels[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_RRAM_best, train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079074f-8781-43af-b52e-fb3581ef8931",
   "metadata": {},
   "source": [
    "## Simulation Data from ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d523a2-f99f-46bb-93e0-fead2768da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "simu = pd.read_csv(\"Testing_160_Images.csv\")\n",
    "simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96e845-0c19-470b-8910-6b45df78022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_units(value):\n",
    "    return float(value.replace('E', 'e').split('V')[0].replace('sec', ''))\n",
    "\n",
    "simu['time'] = simu['time'].apply(remove_units)\n",
    "for col in ['A', 'X', 'V', 'T']:\n",
    "    simu[col] = simu[col].apply(remove_units)\n",
    "simu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223576d6-266c-49bd-aaca-ff3444617f09",
   "metadata": {},
   "source": [
    "We just need one sample every 0.1ms samples of these starting from 2.050ms to 33.850ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stamps = np.arange(2.05e-3, 33.9e-3, 0.2e-3)\n",
    "t_stamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = []\n",
    "window = 0.02e-3\n",
    "\n",
    "for t in t_stamps:\n",
    "    filtered = simu[(simu['time'] >= t - window) & (simu['time'] <= t + window)]\n",
    "    \n",
    "    avg_A = filtered['A'].mean()\n",
    "    avg_X = filtered['X'].mean()\n",
    "    avg_V = filtered['V'].mean()\n",
    "    avg_T = filtered['T'].mean()\n",
    "    \n",
    "    sampled.append({\n",
    "        'Image Index': t,\n",
    "        'A': avg_A,\n",
    "        'X': avg_X,\n",
    "        'V': avg_V,\n",
    "        'T': avg_T\n",
    "    })\n",
    "\n",
    "sampled = pd.DataFrame(sampled)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_column(row):\n",
    "    return row[['A', 'X', 'V', 'T']].idxmax()\n",
    "sampled['Predicted Class'] = sampled.apply(get_max_column, axis=1)\n",
    "sampled.to_csv(\"Sampled_Results.csv\", index=False)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1143c06-5631-4c79-9965-0cb937929706",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ['A']*40 + ['X']*40 + ['V']*40 + ['T']*40\n",
    "correct_predictions = sampled['Predicted Class'] == ground_truth\n",
    "accuracy = correct_predictions.sum() / len(ground_truth)\n",
    "print(accuracy*100,end=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b4552-b0d3-4768-bfe7-9b874959d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3.5))\n",
    "\n",
    "plt.scatter(sampled.index, sampled['A'], color='red', label='A_pred', s=30, marker='o')  # Red dots for A\n",
    "plt.scatter(sampled.index, sampled['X'], color='blue', label='X_pred', s=30, marker='o')  # Blue dots for X\n",
    "plt.scatter(sampled.index, sampled['T'], color='green', label='T_pred', s=30, marker='o')  # Green dots for T\n",
    "plt.scatter(sampled.index, sampled['V'], color='orange', label='V_pred', s=30, marker='o')  # Orange dots for V\n",
    "\n",
    "plt.xlabel('Image Index')\n",
    "plt.ylabel('Predicted Voltages (V)')\n",
    "plt.legend()\n",
    "\n",
    "plt.axvline(x=40, color='gray', linestyle='--', linewidth=2)\n",
    "plt.axvline(x=80, color='gray', linestyle='--', linewidth=2)\n",
    "plt.axvline(x=120, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.text(20, plt.ylim()[1]*(-0.8), 'A', fontsize=15, color='black', ha='center')\n",
    "plt.text(60, plt.ylim()[1]*0.8, 'X', fontsize=15, color='black', ha='center')\n",
    "plt.text(100, plt.ylim()[1]*0.8, 'V', fontsize=15, color='black', ha='center')\n",
    "plt.text(140, plt.ylim()[1]*(-0.8), 'T', fontsize=15, color='black', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
