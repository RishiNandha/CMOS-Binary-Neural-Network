{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141370fc-54a4-4a6b-afcf-a7677dc6dc87",
   "metadata": {},
   "source": [
    "# Soft Binary Neural Network with Recurrent Crossbar Recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508058d8-e23a-4c29-aad7-c2b233d621c9",
   "metadata": {},
   "source": [
    "## Imports and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a70e539-1dc9-4e36-9c9f-18fbdaeede1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torchinfo import summary\n",
    "import ast\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d406d54c-db27-4536-a8c1-f46437f6fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, num_epochs, element):\n",
    "    epochs = range(len(history[list(history.keys())[0]]))\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"blue\")\n",
    "    ax1.plot(epochs, history[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
    "    ax1.set_xlabel(\"Epochs\", fontsize=14)\n",
    "    ax1.set_ylabel(\"Loss\", fontsize=14, color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, history[\"train_accuracy\"], label=\"Train Accuracy\", color=\"green\")\n",
    "    ax2.plot(epochs, history[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"orange\")\n",
    "    ax2.set_ylabel(\"Accuracy (%)\", fontsize=14, color=\"green\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"green\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.title(f\"Training and Validation Metrics for {element}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c658023-75df-4754-a617-a8ba6d08d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, class_names=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = (total_correct / total_samples) * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e8ced-6bb5-445a-9b04-bc268eec917e",
   "metadata": {},
   "source": [
    "### MNIST Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bbad17-7067-4f06-8755-012646ca9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeAndAddNoiseTransform:\n",
    "    def __init__(self, threshold=0.5, noise_std=0.1):\n",
    "        self.threshold = threshold\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = transforms.ToTensor()(img).to(device)\n",
    "        img = (img > self.threshold).float()\n",
    "        noise = torch.randn(img.size(), device=device) * self.noise_std\n",
    "        noisy_img = img + noise\n",
    "        return noisy_img\n",
    "\n",
    "binary_noise_transform = transforms.Compose([\n",
    "    BinarizeAndAddNoiseTransform(threshold=0.5, noise_std=0.2)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=binary_noise_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1000, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b44def-df85-406b-87e8-fbc5b4f7fe7a",
   "metadata": {},
   "source": [
    "## Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391dfb3d-1a2b-42d7-9ff7-e3f0e831d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def tensor_stats(tensor, name=\"Tensor\"):\n",
    "    tensor = tensor.to(device)\n",
    "    mean_magnitude = tensor.abs().mean().item()\n",
    "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
    "\n",
    "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
    "    def __init__(self, G_ON, G_OFF, V_INV, R_INV, V_1, V_0, zeta, initial_factor, monitor_latents = False,\n",
    "                 crossbar=(8,8), input_size=16, recurrence_size=4, output_size=4, int_norm=True, \n",
    "                 hidden_layers=2, monitor_volts=False, monitor_grad=True, dropout=0.2, int_lr=0.01):\n",
    "        super(SoftBinaryRecurrentForwardNetwork, self).__init__()\n",
    "\n",
    "        # Crossbar Weights\n",
    "        self.w = nn.Parameter(torch.empty(crossbar, device=device))\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        self.w.data = initial_factor * self.w\n",
    "\n",
    "        # Circuit Parameters\n",
    "        self.G_ON = torch.tensor(G_ON, device=device)\n",
    "        self.G_OFF = torch.tensor(G_OFF, device=device)\n",
    "        self.V_INV = torch.tensor(V_INV, device=device)\n",
    "        self.R_INV = torch.tensor(R_INV, device=device)\n",
    "        self.V_1 = torch.tensor(V_1, device=device)\n",
    "        self.V_0 = torch.tensor(V_0, device=device)\n",
    "\n",
    "        # Architecture Parameters\n",
    "        self.feedback = recurrence_size\n",
    "        self.data_in = crossbar[0] - recurrence_size\n",
    "        self.output_size = output_size\n",
    "        self.crossbar_in = crossbar[0]\n",
    "        self.crossbar_out = crossbar[1]\n",
    "        self.h_layers = hidden_layers\n",
    "        self.r_passes = input_size // self.data_in\n",
    "\n",
    "        # Training Variables\n",
    "        self.zeta = torch.tensor(zeta, device=device)\n",
    "        self.monitor_volts = monitor_volts\n",
    "        self.monitor_grad = monitor_grad\n",
    "        self.monitor_latents = monitor_latents\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.int_lr = torch.tensor(int_lr, device=device)\n",
    "        self.int_norm = int_norm\n",
    "\n",
    "    def INV_AMP(self, x):\n",
    "        return -self.V_INV * torch.tanh(self.R_INV * x / self.V_INV)\n",
    "\n",
    "    def SOFT_BIN(self, x):\n",
    "        return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
    "\n",
    "    def PREPROCESS(self, img):\n",
    "        return (self.V_1 - self.V_0) * img.view(img.size(0), -1).to(device) + self.V_0\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
    "        img = self.PREPROCESS(img)\n",
    "\n",
    "        # RRAM Soft Binarization\n",
    "        g = self.SOFT_BIN(self.w)\n",
    "\n",
    "        if self.monitor_latents:\n",
    "            tensor_stats(self.w, \"Latent Weights:\")\n",
    "\n",
    "        # Recurrent Forward Layer\n",
    "        feedback = self.PREPROCESS(torch.zeros((img.shape[0], self.feedback), device=device))\n",
    "\n",
    "        for r_pass in range(self.r_passes):\n",
    "            x = torch.cat((feedback, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
    "            x = F.linear(x, g, bias=None)\n",
    "            x = self.INV_AMP(x)\n",
    "            if self.monitor_volts:\n",
    "                tensor_stats(x, f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
    "            feedback = x[:, -self.feedback:]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Hidden Layers as Repeated Passes through the same Crossbar\n",
    "        for h_pass in range(self.h_layers):\n",
    "            x = F.linear(x, g, bias=None)\n",
    "            x = self.INV_AMP(x)\n",
    "            if self.monitor_volts:\n",
    "                tensor_stats(x, f\"Voltages after h_layer {h_pass}\")\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output Classes\n",
    "        return x[:, :self.output_size]\n",
    "\n",
    "    def backprop(self, ext_lr):\n",
    "        with torch.no_grad():\n",
    "            if self.w.grad is not None:\n",
    "                grad = self.w.grad.to(device)\n",
    "                if self.int_norm:\n",
    "                    grad = self.int_lr * grad / torch.norm(grad)\n",
    "                if self.monitor_grad:\n",
    "                    tensor_stats(grad, \"Gradients\")\n",
    "                self.w -= ext_lr * grad\n",
    "                self.w.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a234af2-bd85-4baa-9946-33c31cfb7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_stats(tensor, name=\"Tensor\"):\n",
    "    mean_magnitude = tensor.abs().mean().item()\n",
    "    print(f\"{name} - Mean Magnitude: {mean_magnitude:.2e}, Max: {tensor.max().item():.2e}, Min: {tensor.min().item():.2e}\")\n",
    "    \n",
    "class SoftBinaryRecurrentForwardNetwork(nn.Module):\n",
    "    def __init__(self, G_ON, G_OFF, V_INV, R_INV, V_1, V_0, zeta, initial_factor, \n",
    "                 crossbar=(8,8), input_size=16, recurrence_size=4, output_size=4, int_norm = True,\n",
    "                 hidden_layers=2, monitor_volts=False, monitor_grad=True, dropout=0.2, int_lr = 0.01):\n",
    "        super(SoftBinaryRecurrentForwardNetwork, self).__init__()\n",
    "\n",
    "        # Crossbar Weights\n",
    "        self.w = nn.Parameter(torch.empty(crossbar))\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        self.w.data = initial_factor * self.w\n",
    "        \n",
    "        # Circuit Parameters\n",
    "        self.G_ON = G_ON\n",
    "        self.G_OFF = G_OFF\n",
    "        self.V_INV = V_INV\n",
    "        self.R_INV = R_INV\n",
    "        self.V_1 = V_1\n",
    "        self.V_0 = V_0\n",
    "\n",
    "        # Architecture Parameters\n",
    "        self.feedback = recurrence_size\n",
    "        self.data_in = crossbar[0] - recurrence_size\n",
    "        self.output_size = output_size\n",
    "        self.crossbar_in = crossbar[0]\n",
    "        self.crossbar_out = crossbar[1]\n",
    "        self.h_layers = hidden_layers\n",
    "        self.r_passes = input_size // self.data_in\n",
    "        \n",
    "        # Training Variables\n",
    "        self.zeta = zeta\n",
    "        self.monitor_volts = monitor_volts\n",
    "        self.monitor_grad = monitor_grad\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.int_lr = int_lr\n",
    "        self.int_norm = int_norm\n",
    "\n",
    "    def INV_AMP(self, x):\n",
    "        return -self.V_INV * torch.tanh(self.R_INV * x / self.V_INV)\n",
    "\n",
    "    def SOFT_BIN(self, x):\n",
    "        return ((self.G_ON - self.G_OFF) * torch.sigmoid(x * self.zeta) + self.G_OFF)\n",
    "\n",
    "    def PREPROCESS(self, img):\n",
    "        return (self.V_1 - self.V_0) * img.view(img.size(0), -1) + self.V_0\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Preprocessing: Two States of input (V_ON and V_OFF)\n",
    "        img = self.PREPROCESS(img)\n",
    "\n",
    "        # RRAM Soft Binarization\n",
    "        g = self.SOFT_BIN(self.w).to(img.device)\n",
    "        \n",
    "        if self.monitor_volts:\n",
    "            tensor_stats(self.w, \"Latent Weights:\")\n",
    "            tensor_stats(g, \"Soft Binarized Weights:\")\n",
    "        \n",
    "        # Recurrent Forward Layer\n",
    "        feedback = self.PREPROCESS(torch.zeros((img.shape[0],self.feedback))).to(img.device)\n",
    "        \n",
    "        for r_pass in range(self.r_passes):\n",
    "            x = torch.cat((feedback, img[:, r_pass * self.data_in:(r_pass + 1) * self.data_in]), dim=1)\n",
    "            x = F.linear(x, g, bias=None)\n",
    "            x = self.INV_AMP(x)\n",
    "            if self.monitor_volts: tensor_stats(x,f\"Voltages in Recurrent Stage after pass {r_pass}\")\n",
    "            feedback = x[:,-self.feedback:]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Hidden Layers as Repeated Passes through the same Crossbar\n",
    "        for h_pass in range(self.h_layers):\n",
    "            x = F.linear(x, g, bias=None)\n",
    "            x = self.INV_AMP(x)\n",
    "            if self.monitor_volts: tensor_stats(x,f\"Voltages after h_layer {h_pass}\")\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output Classes\n",
    "        return x[:,:self.output_size]\n",
    "        \n",
    "    def backprop(self, ext_lr):\n",
    "        with torch.no_grad():\n",
    "            if self.w.grad is not None:\n",
    "                grad = self.w.grad\n",
    "                if self.int_norm: grad = self.int_lr*grad/torch.norm(grad)\n",
    "                if self.monitor_grad: tensor_stats(grad, \"Gradients\")\n",
    "                self.w -= ext_lr*grad\n",
    "                self.w.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5f787e-a0d8-41e6-82f3-0ca60515cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c4bf7f2-bb45-43af-a69e-23e931718cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, images, labels, noise_std=0.1):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        noisy_image = image + torch.randn_like(image) * self.noise_std\n",
    "        return noisy_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d51da-8368-4c97-89a2-9fc1374f408b",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d332b5ba-a9e0-4e8a-bff9-3176267bef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RRAM = {\n",
    "    \"G_ON\": 5.5e-5,          # High conductance state\n",
    "    \"G_OFF\": 2.88e-6,        # Low conductance state\n",
    "    \"V_INV\": 0.6,            # Inverter voltage\n",
    "    \"R_INV\": 1e+3,         # Inverter resistance\n",
    "    \"V_1\": 0.1,              # High input voltage\n",
    "    \"V_0\": -0.1,             # Low input voltage\n",
    "    \"zeta\": 1000,               # Sharpness parameter for soft binarization \n",
    "    \"initial_factor\": 0.01,   # Initial weight scaling factor\n",
    "    \"crossbar\": (64, 64),      # Crossbar size (rows, columns)\n",
    "    \"input_size\": 784,        # Input size\n",
    "    \"recurrence_size\": 64-28,    # Feedback size for recurrent connections\n",
    "    \"output_size\": 10,        # Output size\n",
    "    \"hidden_layers\": 0,      # Number of hidden layers \n",
    "    \"monitor_volts\": False,        # check post inverter voltages flag\n",
    "    \"monitor_grad\": False,        # check gradient values\n",
    "    \"monitor_latents\": False,\n",
    "    \"dropout\": 0.1,          # Dropout probability  \n",
    "    \"lr\": 1,            # Training LR\n",
    "    \"epochs\": 300,          # Training Epochs\n",
    "    \"int_lr\": 0.01,           # Internal LR\n",
    "    \"int_norm\": True         # Normalizing Gradient\n",
    "}\n",
    "\n",
    "model_params = {k: v for k, v in params_RRAM.items() if k not in [\"noise_std\", \"batch_size\", \"lr\", \"epochs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a6271e-f7f2-4be1-8a71-b162ad2055e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SoftBinaryRecurrentForwardNetwork        4,096\n",
       "├─Dropout: 1-1                           --\n",
       "=================================================================\n",
       "Total params: 4,096\n",
       "Trainable params: 4,096\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RRAM = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
    "summary(model_RRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282eeb54-9acf-4ce6-b5f0-13e5c60f8614",
   "metadata": {},
   "source": [
    "### Loading Past Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0de620a-e0e4-49cf-863d-721e2680dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.63\n",
      "Parameters: {'G_ON': 5.5e-05, 'G_OFF': 2.88e-06, 'V_INV': 0.6, 'R_INV': 10000.0, 'V_1': 0.1, 'V_0': -0.1, 'zeta': 100, 'initial_factor': 0.001, 'crossbar': (64, 64), 'input_size': 784, 'recurrence_size': 36, 'output_size': 10, 'hidden_layers': 0, 'monitor_volts': False, 'monitor_grad': False, 'dropout': 0.3, 'lr': 1, 'epochs': 15, 'int_lr': 0.01, 'int_norm': True}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(f\"Best_Val_Accuracy_h{model_params['hidden_layers']}.txt\", 'r') as f: val_best = float(f.read())\n",
    "    with open(f\"Best_Params_h{model_params['hidden_layers']}.txt\", 'r') as f: params_best = ast.literal_eval(f.read())\n",
    "\n",
    "    model_best = SoftBinaryRecurrentForwardNetwork(**model_params).to(device)\n",
    "\n",
    "    print(\"Accuracy:\", val_best)\n",
    "    print(\"Parameters:\", params_best)\n",
    "\n",
    "    checkpoint = torch.load(f\"Best_model_h{model_params['hidden_layers']}.pth\")\n",
    "    model_best.load_state_dict(checkpoint)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    val_best = 0\n",
    "    print(\"No Saved Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d1155-be9e-4a7a-9a74-a1d608188350",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75e71bbb-9193-4010-8f9e-70ef9154c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_RRAM = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed1842-f618-4562-8e82-c5355ca39f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with Validation Accuracy: 13.360000\n",
      "Epoch 1, LR: 0.0400, Train Loss: 2.2963, Train Accuracy: 11.87%, Test Loss: 2.2914, Test Accuracy: 13.36%\n",
      "Epoch 2, LR: 0.2000, Train Loss: 2.2913, Train Accuracy: 13.60%, Test Loss: 2.2904, Test Accuracy: 12.73%\n",
      "Epoch 3, LR: 1.0000, Train Loss: 2.2909, Train Accuracy: 11.88%, Test Loss: 2.2906, Test Accuracy: 12.42%\n",
      "Epoch 4, LR: 1.0000, Train Loss: nan, Train Accuracy: 12.08%, Test Loss: nan, Test Accuracy: 9.80%\n"
     ]
    }
   ],
   "source": [
    "lr = params_RRAM[\"lr\"]\n",
    "num_epochs = params_RRAM[\"epochs\"]\n",
    "# lr = 0.1\n",
    "# num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch == 0:\n",
    "        lr /= 25\n",
    "    elif epoch <= 2:\n",
    "        lr *= 5\n",
    "\n",
    "    model_RRAM.train()\n",
    "    model_RRAM.to(device)\n",
    "\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_RRAM(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        model_RRAM.backprop(lr)\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        train_accuracy += (predictions == labels).sum().item()\n",
    "        total_samples += inputs.size(0)\n",
    "\n",
    "    train_loss /= total_samples\n",
    "    train_accuracy = (train_accuracy / total_samples) * 100\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    model_RRAM.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    total_test_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs = test_inputs.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "\n",
    "            test_outputs = model_RRAM(test_inputs)\n",
    "            loss = criterion(test_outputs, test_labels)\n",
    "\n",
    "            test_loss += loss.item() * test_inputs.size(0)\n",
    "            _, test_predictions = torch.max(test_outputs, dim=1)\n",
    "            test_accuracy += (test_predictions == test_labels).sum().item()\n",
    "            total_test_samples += test_inputs.size(0)\n",
    "\n",
    "    test_loss /= total_test_samples\n",
    "    test_accuracy = (test_accuracy / total_test_samples) * 100\n",
    "\n",
    "    history_RRAM[\"train_loss\"].append(train_loss)\n",
    "    history_RRAM[\"train_accuracy\"].append(train_accuracy)\n",
    "    history_RRAM[\"val_loss\"].append(test_loss)\n",
    "    history_RRAM[\"val_accuracy\"].append(test_accuracy)\n",
    "\n",
    "    if test_accuracy > val_best:\n",
    "        val_best = test_accuracy\n",
    "        torch.save(model_RRAM.state_dict(), f\"Best_model_h{model_RRAM.h_layers}.pth\")\n",
    "        with open(f\"Best_Val_Accuracy_h{model_RRAM.h_layers}.txt\", \"w\") as f: \n",
    "            f.write(f\"{val_best:.6f}\")\n",
    "        with open(f\"Best_Params_h{model_RRAM.h_layers}.txt\", \"w\") as f: \n",
    "            f.write(f\"{params_RRAM}\")\n",
    "        print(f\"Model saved with Validation Accuracy: {val_best:.6f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, LR: {lr:.4f}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    if (epoch) % (10) == 0 and epoch != 0:\n",
    "        lr /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a2ef8-94c5-49ca-bd35-3ed75ae2327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_RRAM, num_epochs, \"RRAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e55bc-1bae-4483-a3cf-01cde188dc69",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52e53e-15ed-441f-8412-d94c5d6a0bdb",
   "metadata": {},
   "source": [
    "### Current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51271c7c-25b1-4702-9db1-9ae4b805843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0 + (model_RRAM.w > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d477c9e-5678-4d07-a5ac-48f01480c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = test(model_RRAM, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7941df-4678-4955-8a0f-f38b43f6b197",
   "metadata": {},
   "source": [
    "## Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867574d7-3627-49ff-a430-1d658fa4d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "0+1*(model_best.w>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca56c6-7023-416e-9675-93f1a3c8cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = test(model_best, val_inputs, val_labels, class_names = [\"A\", \"T\", \"V\", \"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad288f0b-0ec9-415d-96cc-a4ecec7aa5ce",
   "metadata": {},
   "source": [
    "## PWL Generation\n",
    "\n",
    "Let's assume that we will program the two crossbars with seperate PWLs. That is, during programming, we will cut the Inverting Amplifier stages with a pass transistor and connect the programming lines with a pass transistor. First array has 16 Top PWLs and 8 Bottom PWLs. Second array has 8 Top PWLs and 4 Bottom PWLs. And then once the programming switch is toggled to inference mode, only the 16 Top PWLs are to be changed. Let's also generate a PWL for that too.\n",
    "\n",
    "In the code below, we will first maintain tuples for each PWL that holds what the voltage should be. And then we will write a function that will take there and space pulses of the given voltage that are 100us apart from other and have an ON duration of 100us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5cebb-fc99-4a00-87a1-e183838c9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_FC1 = [list() for i in range(16)]\n",
    "BL_FC1 = [list() for i in range(8)]\n",
    "WL_FC2 = [list() for i in range(8)]\n",
    "BL_FC2 = [list() for i in range(4)]\n",
    "Mode = []\n",
    "Mode_B = []\n",
    "\n",
    "V_WRITE = 1.5\n",
    "V_READ = 0.1\n",
    "V_mode = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647afda-e1a7-47a7-b634-212ec5527be2",
   "metadata": {},
   "source": [
    "#### Fully Connected Weights 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03334172-89f6-4d73-9461-6ac922bdb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (model_RRAM_best.w1>0).int()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49287afe-8437-40aa-8825-93f2cffe3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_i, i in enumerate(target):\n",
    "    for ind_j, j in enumerate(i):\n",
    "        if j==1: WL_FC1[ind_j].append(V_WRITE)\n",
    "        else: WL_FC1[ind_j].append(V_WRITE/3)\n",
    "    for ind_k in range(len(target)): \n",
    "        if ind_k==ind_i: BL_FC1[ind_i].append(0)\n",
    "        else: BL_FC1[ind_k].append(2*V_WRITE/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77131c-005d-4f06-8a70-f40d267eb67e",
   "metadata": {},
   "source": [
    "#### Fully Connected Weights 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc2b24-ffb0-4470-8eae-3830221cb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (model_RRAM_best.w2>0).int()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ca037-0e2f-49a3-98b3-b2e0b93f8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_i, i in enumerate(target):\n",
    "    for ind_j, j in enumerate(i):\n",
    "        if j==1: WL_FC2[ind_j].append(V_WRITE)\n",
    "        else: WL_FC2[ind_j].append(V_WRITE/3)\n",
    "    for ind_k in range(len(target)): \n",
    "        if ind_k==ind_i: BL_FC2[ind_i].append(0)\n",
    "        else: BL_FC2[ind_k].append(2*V_WRITE/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602368f-07a2-4beb-90e3-d782ca717fea",
   "metadata": {},
   "source": [
    "#### Filling Out Programming Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa24d2-0d95-4ff4-8dfd-5c0800d9de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_FC1 = [i + [0,0] for i in WL_FC1]\n",
    "BL_FC1 = [i + [0,0] for i in BL_FC1]\n",
    "while(len(WL_FC2[0]) < len(WL_FC1[0])):\n",
    "    WL_FC2 = [i + [0,] for i in WL_FC2]\n",
    "    BL_FC2 = [i + [0,] for i in BL_FC2]\n",
    "Mode.extend([V_mode]*(len(WL_FC1[0])-1) + [-V_mode])\n",
    "Mode_B.extend([-V_mode]*(len(WL_FC1[0])-1) + [V_mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953198a-a107-428c-9624-3c712086e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WL_FC1[0])\n",
    "print(BL_FC1[0])\n",
    "print(WL_FC2[0])\n",
    "print(BL_FC2[0])\n",
    "print(Mode)\n",
    "print(Mode_B)\n",
    "print(len(WL_FC1[0]), len(BL_FC1[0]), len(WL_FC2[0]), len(BL_FC2[0]), len(Mode), len(Mode_B)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92339f84-e8d6-4280-92af-e5215aa129a0",
   "metadata": {},
   "source": [
    "### Inference: Loading the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97dacd2-42bb-49f0-8ca9-e0f02ca4cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336c3ab-2181-4ee7-b1c9-0a97a3700248",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_1 = 0.1\n",
    "V_0 = -0.1\n",
    "include_testing = True\n",
    "include_every = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cfba2-3243-4062-9ef6-4cd309622c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_testing:\n",
    "    for i in val_inputs[::include_every]:\n",
    "        i = i.flatten()\n",
    "        for ind, j in enumerate(i):\n",
    "            WL_FC1[ind].append(V_1 if j==1 else V_0)\n",
    "        BL_FC1 = [i + [0,] for i in BL_FC1]\n",
    "        WL_FC2 = [i + [0,] for i in WL_FC2]\n",
    "        BL_FC2 = [i + [0,] for i in BL_FC2]\n",
    "        Mode = Mode + [-V_mode,]\n",
    "        Mode_B = Mode_B + [V_mode,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd97b8-fb1b-4634-9ae4-3a6fe05d0a2c",
   "metadata": {},
   "source": [
    "### PWL Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af5ff-8f34-4472-89fc-e308d98d4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pwl(l):\n",
    "    t = 0\n",
    "    res = \"pwl(time, 0us, 0V\"\n",
    "    for i in l:\n",
    "        res += f\", {t+5}us, {i:.2f}V, {t+100}us, {i:.2f}V, {t+105}us, 0V, {t+200}us, 0V\"\n",
    "        t+=200\n",
    "    res += \")\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54850dbc-1317-44a2-9093-c5a4e048094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwl_data = []\n",
    "\n",
    "for ind, i in enumerate(WL_FC1):\n",
    "    pwl_data.append({\"Signal\": f\"WL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(BL_FC1):\n",
    "    pwl_data.append({\"Signal\": f\"BL_FC1_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(WL_FC2):\n",
    "    pwl_data.append({\"Signal\": f\"WL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "for ind, i in enumerate(BL_FC2):\n",
    "    pwl_data.append({\"Signal\": f\"BL_FC2_{ind}\", \"Index\": ind, \"PWL\": pwl(i)})\n",
    "pwl_data.append({\"Signal\": \"Mode\", \"Index\": \"\", \"PWL\": pwl(Mode)})\n",
    "pwl_data.append({\"Signal\": \"Mode_b\", \"Index\": \"\", \"PWL\": pwl(Mode_B)})\n",
    "\n",
    "pwl_data = pd.DataFrame(pwl_data)\n",
    "pwl_data.to_csv(\"pwl_data.csv\", index=False)\n",
    "pwl_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e13866-8cd8-4b8e-a8d0-a5c69e951174",
   "metadata": {},
   "source": [
    "#### Testing Accuracy on 160 Images\n",
    "ADS isn't allowing PWLs longer than 160 Images, so let's check software accuracy for the same too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e4e97-5ecd-4c41-9035-4a51015d684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_RRAM_best, val_inputs[::4], val_labels[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf44b69-14ac-4fdd-a2b5-b9c2cc361e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_RRAM_best, train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079074f-8781-43af-b52e-fb3581ef8931",
   "metadata": {},
   "source": [
    "## Simulation Data from ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d523a2-f99f-46bb-93e0-fead2768da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "simu = pd.read_csv(\"Testing_160_Images.csv\")\n",
    "simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96e845-0c19-470b-8910-6b45df78022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_units(value):\n",
    "    return float(value.replace('E', 'e').split('V')[0].replace('sec', ''))\n",
    "\n",
    "simu['time'] = simu['time'].apply(remove_units)\n",
    "for col in ['A', 'X', 'V', 'T']:\n",
    "    simu[col] = simu[col].apply(remove_units)\n",
    "simu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223576d6-266c-49bd-aaca-ff3444617f09",
   "metadata": {},
   "source": [
    "We just need one sample every 0.1ms samples of these starting from 2.050ms to 33.850ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d6e19-daa6-481f-8ad2-11a357dc20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stamps = np.arange(2.05e-3, 33.9e-3, 0.2e-3)\n",
    "t_stamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5548dd9-e376-4bd1-b9d2-484f4358f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = []\n",
    "window = 0.02e-3\n",
    "\n",
    "for t in t_stamps:\n",
    "    filtered = simu[(simu['time'] >= t - window) & (simu['time'] <= t + window)]\n",
    "    \n",
    "    avg_A = filtered['A'].mean()\n",
    "    avg_X = filtered['X'].mean()\n",
    "    avg_V = filtered['V'].mean()\n",
    "    avg_T = filtered['T'].mean()\n",
    "    \n",
    "    sampled.append({\n",
    "        'Image Index': t,\n",
    "        'A': avg_A,\n",
    "        'X': avg_X,\n",
    "        'V': avg_V,\n",
    "        'T': avg_T\n",
    "    })\n",
    "\n",
    "sampled = pd.DataFrame(sampled)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096828ea-b6be-4839-8b7d-4e0f5a515a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_column(row):\n",
    "    return row[['A', 'X', 'V', 'T']].idxmax()\n",
    "sampled['Predicted Class'] = sampled.apply(get_max_column, axis=1)\n",
    "sampled.to_csv(\"Sampled_Results.csv\", index=False)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1143c06-5631-4c79-9965-0cb937929706",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ['A']*40 + ['X']*40 + ['V']*40 + ['T']*40\n",
    "correct_predictions = sampled['Predicted Class'] == ground_truth\n",
    "accuracy = correct_predictions.sum() / len(ground_truth)\n",
    "print(accuracy*100,end=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b4552-b0d3-4768-bfe7-9b874959d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3.5))\n",
    "\n",
    "plt.scatter(sampled.index, sampled['A'], color='red', label='A_pred', s=30, marker='o')  # Red dots for A\n",
    "plt.scatter(sampled.index, sampled['X'], color='blue', label='X_pred', s=30, marker='o')  # Blue dots for X\n",
    "plt.scatter(sampled.index, sampled['T'], color='green', label='T_pred', s=30, marker='o')  # Green dots for T\n",
    "plt.scatter(sampled.index, sampled['V'], color='orange', label='V_pred', s=30, marker='o')  # Orange dots for V\n",
    "\n",
    "plt.xlabel('Image Index')\n",
    "plt.ylabel('Predicted Voltages (V)')\n",
    "plt.legend()\n",
    "\n",
    "plt.axvline(x=40, color='gray', linestyle='--', linewidth=2)\n",
    "plt.axvline(x=80, color='gray', linestyle='--', linewidth=2)\n",
    "plt.axvline(x=120, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.text(20, plt.ylim()[1]*(-0.8), 'A', fontsize=15, color='black', ha='center')\n",
    "plt.text(60, plt.ylim()[1]*0.8, 'X', fontsize=15, color='black', ha='center')\n",
    "plt.text(100, plt.ylim()[1]*0.8, 'V', fontsize=15, color='black', ha='center')\n",
    "plt.text(140, plt.ylim()[1]*(-0.8), 'T', fontsize=15, color='black', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f31ef-ad69-472f-9217-bdde6f8ab1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
